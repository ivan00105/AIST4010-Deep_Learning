{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hMATZeC20aiT",
        "outputId": "3ae98ab8-9373-4446-b9cc-438d529f94ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ray[data,serve,train,tune]\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (3.13.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (2.0.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (2023.6.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[data,serve,train,tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette (from ray[data,serve,train,tune])\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (3.9.3)\n",
            "Collecting py-spy>=0.2.0 (from ray[data,serve,train,tune])\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from ray[data,serve,train,tune])\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus (from ray[data,serve,train,tune])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (6.4.0)\n",
            "Collecting watchfiles (from ray[data,serve,train,tune])\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard] (from ray[data,serve,train,tune])\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (2.6.4)\n",
            "Collecting aiohttp-cors (from ray[data,serve,train,tune])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful (from ray[data,serve,train,tune])\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (0.20.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[data,serve,train,tune])\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.62.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (4.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->ray[data,serve,train,tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->ray[data,serve,train,tune]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->ray[data,serve,train,tune]) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,serve,train,tune]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,serve,train,tune]) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,serve,train,tune]) (4.11.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[data,serve,train,tune])\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[data,serve,train,tune]) (4.2.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->ray[data,serve,train,tune]) (3.7.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[data,serve,train,tune]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[data,serve,train,tune]) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[data,serve,train,tune]) (0.18.0)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[data,serve,train,tune])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[data,serve,train,tune]) (1.16.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[data,serve,train,tune]) (2.11.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (2024.2.2)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->ray[data,serve,train,tune]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->ray[data,serve,train,tune]) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.6.0)\n",
            "Installing collected packages: py-spy, opencensus-context, distlib, colorful, websockets, virtualenv, uvloop, tensorboardX, python-dotenv, httptools, h11, watchfiles, uvicorn, starlette, fastapi, aiohttp-cors, ray, opencensus\n",
            "Successfully installed aiohttp-cors-0.7.0 colorful-0.5.6 distlib-0.3.8 fastapi-0.110.1 h11-0.14.0 httptools-0.6.1 opencensus-0.11.4 opencensus-context-0.1.3 py-spy-0.3.14 python-dotenv-1.0.1 ray-2.10.0 starlette-0.37.2 tensorboardX-2.6.2.2 uvicorn-0.29.0 uvloop-0.19.0 virtualenv-20.25.1 watchfiles-0.21.0 websockets-12.0\n",
            "Collecting neuralforecast\n",
            "  Downloading neuralforecast-1.7.1-py3-none-any.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coreforecast>=0.0.6 (from neuralforecast)\n",
            "  Downloading coreforecast-0.0.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.2.1+cu121)\n",
            "Collecting pytorch-lightning>=2.0.0 (from neuralforecast)\n",
            "  Downloading pytorch_lightning-2.2.2-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ray[tune]>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.10.0)\n",
            "Collecting optuna (from neuralforecast)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting utilsforecast>=0.0.25 (from neuralforecast)\n",
            "  Downloading utilsforecast-0.1.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2024.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.13.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.31.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (14.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting alembic>=1.5.0 (from optuna->neuralforecast)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->neuralforecast)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (2.0.29)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->neuralforecast)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->neuralforecast) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=2.0.0->neuralforecast) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->neuralforecast) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->neuralforecast) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->neuralforecast) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (4.0.3)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, lightning-utilities, coreforecast, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, utilsforecast, optuna, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, neuralforecast\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 coreforecast-0.0.8 lightning-utilities-0.11.2 neuralforecast-1.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 pytorch-lightning-2.2.2 torchmetrics-1.3.2 utilsforecast-0.1.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhttps://github.com/Nixtla/neuralforecast/issues/943\\n\\nGo /usr/local/lib/python3.10/dist-packages/neuralforecast/models/tft.py\\n\\nChange\\n\\nself.stat_exog_list = [] if stat_exog_list is None else stat_exog_list\\nself.hist_exog_list = [] if hist_exog_list is None else hist_exog_list\\nself.futr_exog_list = [] if futr_exog_list is None else futr_exog_list\\n\\ninto\\nself.futr_exog_list = list(futr_exog_list) if futr_exog_list is not None else []\\nself.hist_exog_list = list(hist_exog_list) if hist_exog_list is not None else []\\nself.stat_exog_list = list(stat_exog_list) if stat_exog_list is not None else []\\n\\n\\n\\n\\nAlso\\n/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_model.py\\nChange line 55 into:\\n\\nset(temporal_cols.tolist()) & set(list(self.hist_exog_list) + list(self.futr_exog_list))\\n\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " !pip install -U \"ray[data,train,tune,serve]\"\n",
        " !pip install neuralforecast\n",
        "\n",
        "\"\"\"\n",
        "https://github.com/Nixtla/neuralforecast/issues/943\n",
        "\n",
        "Go /usr/local/lib/python3.10/dist-packages/neuralforecast/models/tft.py\n",
        "\n",
        "Change\n",
        "\n",
        " self.stat_exog_list = [] if stat_exog_list is None else stat_exog_list\n",
        " self.hist_exog_list = [] if hist_exog_list is None else hist_exog_list\n",
        " self.futr_exog_list = [] if futr_exog_list is None else futr_exog_list\n",
        "\n",
        "into\n",
        " self.futr_exog_list = list(futr_exog_list) if futr_exog_list is not None else []\n",
        " self.hist_exog_list = list(hist_exog_list) if hist_exog_list is not None else []\n",
        " self.stat_exog_list = list(stat_exog_list) if stat_exog_list is not None else []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Also\n",
        "/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_model.py\n",
        "Change line 55 into:\n",
        "\n",
        "set(temporal_cols.tolist()) & set(list(self.hist_exog_list) + list(self.futr_exog_list))\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx1dHm2z0gNB",
        "outputId": "78e4b52b-577b-4672-861a-2d1bb4a03c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgONzTaI0aiU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from neuralforecast.core import NeuralForecast\n",
        "from neuralforecast.models import TSMixer, TSMixerx, NHITS\n",
        "from neuralforecast.losses.pytorch import MSE, MAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYzFLOep0aiU",
        "outputId": "5acb0e6d-3440-4a8a-aafa-24834c0ff1b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                       ds  unique_id             y\n",
              " 0     2013-04-29 23:59:59       High  1.474880e+02\n",
              " 1     2013-04-30 23:59:59       High  1.469300e+02\n",
              " 2     2013-05-01 23:59:59       High  1.398900e+02\n",
              " 3     2013-05-02 23:59:59       High  1.256000e+02\n",
              " 4     2013-05-03 23:59:59       High  1.081280e+02\n",
              " ...                   ...        ...           ...\n",
              " 17941 2021-07-02 23:59:59  Marketcap  6.354508e+11\n",
              " 17942 2021-07-03 23:59:59  Marketcap  6.499397e+11\n",
              " 17943 2021-07-04 23:59:59  Marketcap  6.615748e+11\n",
              " 17944 2021-07-05 23:59:59  Marketcap  6.326962e+11\n",
              " 17945 2021-07-06 23:59:59  Marketcap  6.418992e+11\n",
              " \n",
              " [17946 rows x 3 columns],\n",
              "                       ds unique_id             y          Open          High  \\\n",
              " 0    2013-04-29 23:59:59     Close    144.539993    134.444000    147.488007   \n",
              " 1    2013-04-30 23:59:59     Close    139.000000    144.000000    146.929993   \n",
              " 2    2013-05-01 23:59:59     Close    116.989998    139.000000    139.889999   \n",
              " 3    2013-05-02 23:59:59     Close    105.209999    116.379997    125.599998   \n",
              " 4    2013-05-03 23:59:59     Close     97.750000    106.250000    108.127998   \n",
              " ...                  ...       ...           ...           ...           ...   \n",
              " 2986 2021-07-02 23:59:59     Close  33897.048590  33549.600177  33939.588699   \n",
              " 2987 2021-07-03 23:59:59     Close  34668.548402  33854.421362  34909.259899   \n",
              " 2988 2021-07-04 23:59:59     Close  35287.779766  34665.564866  35937.567147   \n",
              " 2989 2021-07-05 23:59:59     Close  33746.002456  35284.344430  35284.344430   \n",
              " 2990 2021-07-06 23:59:59     Close  34235.193451  33723.509655  35038.536363   \n",
              " \n",
              "                Low        Volume     Marketcap         Close  \n",
              " 0       134.000000  0.000000e+00  1.603769e+09    144.539993  \n",
              " 1       134.050003  0.000000e+00  1.542813e+09    139.000000  \n",
              " 2       107.720001  0.000000e+00  1.298955e+09    116.989998  \n",
              " 3        92.281898  0.000000e+00  1.168517e+09    105.209999  \n",
              " 4        79.099998  0.000000e+00  1.085995e+09     97.750000  \n",
              " ...            ...           ...           ...           ...  \n",
              " 2986  32770.680780  3.872897e+10  6.354508e+11  33897.048590  \n",
              " 2987  33402.696536  2.438396e+10  6.499397e+11  34668.548402  \n",
              " 2988  34396.477458  2.492431e+10  6.615748e+11  35287.779766  \n",
              " 2989  33213.661034  2.672155e+10  6.326962e+11  33746.002456  \n",
              " 2990  33599.916169  2.650126e+10  6.418992e+11  34235.193451  \n",
              " \n",
              " [2991 rows x 9 columns])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/coin_Bitcoin.csv', parse_dates=['Date'])\n",
        "df_hist = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/coin_Bitcoin.csv', parse_dates=['Date'])\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df_hist['Date'] = pd.to_datetime(df_hist['Date'])\n",
        "df = df.drop(columns=['SNo', 'Name', 'Symbol'])\n",
        "df_hist = df_hist.drop(columns=['SNo', 'Name', 'Symbol'])\n",
        "\n",
        "df.rename(columns={\"Date\":\"ds\"}, inplace=True)\n",
        "df_hist.rename(columns={\"Date\":\"ds\"}, inplace=True)\n",
        "\n",
        "df_hist_copy = df_hist.copy()\n",
        "\n",
        "df_hist = df_hist.drop(columns=['Open', 'High', 'Low', 'Volume', 'Marketcap'])\n",
        "df_hist = df_hist.melt(id_vars=['ds'], var_name='unique_id', value_name='y')\n",
        "\n",
        "df_hist['Open'] = df_hist_copy['Open']\n",
        "df_hist['High'] = df_hist_copy['High']\n",
        "df_hist['Low'] = df_hist_copy['Low']\n",
        "df_hist['Volume'] = df_hist_copy['Volume']\n",
        "df_hist['Marketcap'] = df_hist_copy['Marketcap']\n",
        "df_hist['Close'] = df_hist_copy['Close']\n",
        "\n",
        "df = df.melt(id_vars=['ds'], var_name='unique_id', value_name='y')\n",
        "n_time = len(df.ds.unique())\n",
        "val_size = int(.2 * n_time)\n",
        "test_size = int(.1 * n_time)\n",
        "\n",
        "# df = df.set_index('Date')\n",
        "# df =df.drop(columns=['Name','Symbol'])\n",
        "# df, df.describe(), df[\"y\"].plot()\n",
        "df, df_hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing the TSMixer Usage in the Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvTd8jmM0aiV"
      },
      "outputs": [],
      "source": [
        "horizon = 5\n",
        "input_size = 300\n",
        "models = [\n",
        "          TSMixer(h=horizon,\n",
        "                input_size=input_size,\n",
        "                n_series=6,\n",
        "                max_steps=1000,\n",
        "                val_check_steps=100,\n",
        "                early_stop_patience_steps=5,\n",
        "                scaler_type='standard',\n",
        "                valid_loss=MAE(),\n",
        "                random_seed=12345678,\n",
        "                ),\n",
        "         ]\n",
        "\n",
        "nf = NeuralForecast(models=models,freq=\"1B\")\n",
        "\n",
        "df_hat = nf.cross_validation(df=df,\n",
        "                              val_size=val_size,\n",
        "                              test_size=test_size,\n",
        "                              n_windows=None\n",
        "                              )\n",
        "\n",
        "df_hat = df_hat.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "MkVztWTB0aiV",
        "outputId": "6fef62d0-0488-44bb-e6d4-12d0ef8d3227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TSMixer horizon 5 - MAE: 10194282060.906\n",
            "TSMixer horizon 5 - MSE: 1008118607752888188928.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cfe733f7790>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from neuralforecast.losses.numpy import mse, mae\n",
        "\n",
        "\n",
        "Y_plot = df_hat[df_hat['unique_id']=='Close']\n",
        "cutoffs = df_hat['cutoff'].unique()[::horizon]\n",
        "Y_plot = Y_plot[df_hat['cutoff'].isin(cutoffs)]\n",
        "\n",
        "mae_tsmixer = mae(df_hat['y'], df_hat['TSMixer'])\n",
        "mse_tsmixer = mse(df_hat['y'], df_hat['TSMixer'])\n",
        "print(f'TSMixer horizon {horizon} - MAE: {mae_tsmixer:.3f}')\n",
        "print(f'TSMixer horizon {horizon} - MSE: {mse_tsmixer:.3f}')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(Y_plot['ds'], Y_plot['y'], label='True')\n",
        "plt.plot(Y_plot['ds'], Y_plot['TSMixer'], label='TSMixer')\n",
        "plt.xlabel('Datestamp')\n",
        "plt.ylabel('Close')\n",
        "plt.grid()\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYyRu-Jv0aiV"
      },
      "source": [
        "# Hyperparamerters Tuning for All The Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2da55f14dc0a437393217d20c53686d7",
            "16487311acee4fccb6a25860125e1846",
            "734fb725e3e346269a277b2e1e1110a6",
            "14415c83a38f4455aace4d6b5f57631a",
            "ef59f0614c334de388d1dbfb5a78ad40",
            "c598fb294fa3454faeff04e8e5a1c1c2",
            "bfdf750c48cd4dfcaa211d60446b3d1c",
            "54a454f89eae4132934dd16975e282c4",
            "49ebec869eda402eb08ca11c8ffb6110",
            "f903862487d64139805e0dfbe52ca145",
            "c1a825e9a1c7458fa32d5e6f6345646d",
            "89fde10ce594480480f6183b430f96a9",
            "1904736262054fb99e553e74814a568e",
            "3c875707602d4a83a624eed3be821145",
            "a308d819a7664282a58d0e65654e7b40",
            "ff977f2ee76447d998775909ac5315ad",
            "d00f667624584c39820e44c45547d000",
            "9ba221c0cc47458fa428d83976bcb28e",
            "de8127e5af5446f0a41340f79a9f4093",
            "3d14d424a3364a0f8f8156a60a7d5373",
            "7df6f389645f4c51bae24425a554e937",
            "fe64ee2f2dfa4868b2dc37532f9e3e01",
            "96cfb0c9664641b685c7c20774d0c5ca",
            "11bc24de762a4b4f958bd664c4457abf",
            "3fa3871e5a9540f1aed3676a452e52be",
            "2d4a4728476744da9381dd9c03673ac2",
            "4c1d64ce5d294b75a252224e7c84ed90",
            "b558589adcc34a29ae2e56626f245ab0",
            "a0b1830e6109429faf422115ba502e2e",
            "5b3d164637f04dcdaeb7c7cf192b51f4",
            "6d1430f2047243f68b55802312cea44f",
            "99ff65c9c98545c397294c2e68954402",
            "0e9be86c646140d6806542120810db86",
            "9a2eeaa58dd24a05b7d609e3bb1a2bb2",
            "4d4d2d17d7f94a64838fec097db7e257",
            "e0935d347bb84a1a9eddca2921d0b3a2",
            "a0d240e52e524414aa1c99c11b38cab5",
            "fabf2d3dbf604530ac03b345eed2aa17",
            "6dbf54ba20614cab8469d8f6dc08b10f",
            "248a9c52405b4caa8c0432abcf20e60b",
            "7ca13cc2e0864ea1954c1e3a0a0e1f38",
            "dd188090396e478fb97c13c794003085",
            "acfd92eb62d241f28978cbe0ec9c1e6e",
            "e97d782bdfeb440491448bf3f224f71d",
            "28b2a575b3c445e7ad2a9e1767834f19",
            "7211dc11c5654e198a30a93a5f7e8cde",
            "99e86865a30f472f86faf1f10c5d2453",
            "560b1a3533ee45f9aa4a5ad3dd731d77",
            "c60d681f07fa4cef9c4d98982d6c3363",
            "828b69e1cc3c4182b2ecc06c1aba71c0",
            "03ec87dec3f945abb70e865657139d99",
            "424879471988468395f4b3c436a2d38d",
            "f9b6c25fb19443e4903cc809b0e61c2b",
            "910d27c8e79345559a55cc198a3ca627",
            "fc19db9f545b4f85ac249946c39305df",
            "8e6ab6d506b44556a7167a8d9e1fb4db",
            "f71c0d756bd646c892bb1b8db854191c",
            "c41680fda2f446eca453c748a382fde5",
            "ba9b59151532432d8013ad6b6bc9a49d",
            "9403863cd9324593a344c1795a05f332",
            "a2cfe707ac1b458eb2fab8e5dcfce656",
            "c3c0f129be1244758a542eaafd792b3b",
            "ef63e5226ed14c909186ff0e9bf57813",
            "7c828918797d470b92b6d27454e27659",
            "7e2a96d723bb458291a82d06991be8fb",
            "c1f09f7a8d014f2182046e0ad2b97a9d",
            "86898c8037dd444d9ae70d1ac948abf5",
            "0a7bf938b9094a8289b0f918a632c2ae",
            "b6a236757b7f46c7ba3ae9eae27d2454",
            "93c55be65eff41b786c7b48c3da35a5c",
            "9f896233b1b24abc95508b5cdeb445a9",
            "37399682634648c382ab395941c5a9a4",
            "f475abd6e69343fab625f4cd9ce4cf51",
            "4a7671f093c1412db740ee2f6c45ce17",
            "fbe73cbbe27641f284f54e159a188b9f",
            "1d846d1029ff47848f6a07f39b237edf",
            "5cb9fbee65c14e2eb300fa86c9034dc5",
            "a8072c4d95444ddfa631c7da81cdcae5",
            "2921b4e0b0cf426ea272e72e287bcec4",
            "80d2456c79254c64ae52ec228835ede5",
            "5909522787004abca779581282006e7b",
            "991c0a26bb5e4ec3b9e1dd55d717a264",
            "3d759a4fc9fe4f6b97349c1d4c619363",
            "fdcaf8601ac74fbf967567c94b401f65",
            "585b588e976f492aba8f9a4ec36195ae",
            "2f3f595794bb4df2b098c48a91abebdb",
            "3cba65e025154b0caa7f2ff6093862be",
            "20d6fa072b1545a3b2b9e85b0ea2d1b3",
            "29d3389e4973405ab5f12145742e991e",
            "bca14345673c42cd9397081c1395497a",
            "e1de86e5a1ed41f981fa01ba3e131d3c",
            "749c5eaefa1843919661b84f40fc57aa",
            "f30674e2ae4f450995c7da77a4db8cb4",
            "90ac560e7ae74b8ebc656a778d68a355",
            "edb2c71856b8430e8b3f17502762e41d",
            "a5c7375f105246ebb6082ae087c7abd3",
            "26717562be6c41cda806e5ca45b67e05",
            "caeedf4048d74ef08a94e036e61196d2",
            "efb5354d8e1b4b518c800ac79ed92aba",
            "f09978559b214939aa9f9023e92c4a2a",
            "a0ff3998b9f743179e1d69b2f4069f70",
            "f7018ff10b7e4d219db4a5d92beabac7",
            "01c0258d0be244f59ac78a4b52a40ce9",
            "925ab74e6da74e67b4a2e0e990aef422",
            "5a27d834d1394d0197d5cca2f7455a71",
            "9dd5107d5bef415ab1b20ce33bbbb684",
            "05f87bf5978c4a08826e92a58fd81602",
            "efc0e32ff44f41eda8971273b8a59905",
            "4f2fa71e5264449b89d2b2b3f9937905",
            "7bfafc935af9491e9f897adb8ec90b02",
            "18e69d6698d9473d84b5c051b3578731",
            "d58801668ea74c6c87774e1dd348362d",
            "901e6d1d2572496e8291a15db6a9841a",
            "a40057fe9eca49e292489bf26a34fc67",
            "e9155b59d10741bcb764ed18fad52ff5",
            "fe53fca4332444a49d08f88141ba7911",
            "7ec02028674641c1ae444c4ae1b49af5",
            "4c628ed35b264f88b15b51595f07cac8",
            "8f5a04f6779345d9ad0fdba6973ed396",
            "905a1a2bb5ff4a81aace76ad18c4e624",
            "c7a45efbaa1c4564a6ef6b99f1f761fd",
            "9a688c6040e340e8912a5b98b3f8a082",
            "5fa461376eeb4c3a96c2f29168e8b91e",
            "18267b0f10d047dea212da683cb60122",
            "d1c9bf3606da4b00af7e68f45375c9ea",
            "cef40e6ce6104b7d98c15de106a6db8b",
            "c9d8fe37a98e44828070a3e520e0ab39",
            "d54507794f40428fbb052757d79d8eb9",
            "dc3a3853768f4172a4c907c5e66ff278",
            "c7292b7c981b41478109befb78b9503f",
            "244b08b3a47c4e799e4a4e72a5587031",
            "2832d58105744a9db3c91b114ec27ead",
            "94ecb5285f8b4daa858a36548d17ce24",
            "af07c5909cd34da988508e3da4690d79",
            "8c84716f10bf44d2a8851b36b2bda630",
            "2b5859bae48b4d29807d6fb6db116164",
            "f2b0553f5aee4c14a88609a3c9bbae29",
            "def05d4afa6543f0a7a98d9aaa6a13f4",
            "59f8a2b5e30e4788bc8a1ca8dc173f7c",
            "0d87d95890854bbc90db37b2e8733152",
            "6deaf7be1e8e45648f151fdc6048bcfe",
            "80e6c8d964d147169f17bea79e8ed11e",
            "943ed872d8c942eca0e38ed2f94c0e4b",
            "83052c10943f40eca294160d2c0a74e4",
            "fdb8ff8f88694cbeb2b0dc926f80cbfa",
            "53118e1332d340a2846eb4f43cdcc651",
            "866cbf66d95d40f981c6f16d64fdc2ee",
            "0f4579a3222c404b8ceea69844f904fb",
            "60fabf94c96d4828aee35da5b83efe38",
            "61be583f9d8a46a9bc1aa5999045b598",
            "98e610b376ba492b84b7038375737854",
            "9ed17e6eafcc4988b579c958ddf7089b",
            "6626124e4dcc4fc18a69154a2a47e1ce",
            "c7d1010e3f534c64ac9fd6eb009a2b69",
            "b7071d1d108743a88a5a2f5b499ad907",
            "b15631e4b5a243c7a146b89db317046a",
            "725ce44d7b6d4c3eb2db9afc15ba43c2",
            "35ae544d591a4b6a9514c9f77678a382",
            "8f507054eb4243d5b6a720de750ef5d5",
            "06459e421d064d71887b77cd3a08ac47",
            "4e53e62f358541ecb670674aa8722686",
            "b6ae7a272e28437fb8df1fad199843c5",
            "5985885d001b4ddfb650b5a83fae62aa",
            "d80299d5e9ab4b3b9b52a4452cc5fc12",
            "3c65d0d66aa148cdbb1b7d75abd33184",
            "6edd5e812a744663800139af707923dd",
            "c8d54cd4279c4248917ffbc6615aabc5",
            "0efabcaa90f248fda543b46c76977ba3",
            "da957921a1fc49cbbc2c97de54119436",
            "27679796363742db811e5539149a3b81",
            "b3a9998617d943558dd8ae1ca0307b80",
            "c9ba12a351754d92b8259f16e1d46a21",
            "e0a7649d328343d5ab8ad921ef22f621",
            "ac276a1b8ad34a3f92d4b8d2a282ae9f",
            "a60c8547772f4dac819436e0d7dd9b54",
            "3d572eb78c3b4bfe9c2cdd19bb2bb0bb",
            "4f465cee6db7449dbf3ae185b5100ff4",
            "b37bfb9315204c5aa9d0117c12558818",
            "b72cec6baa8547fb9b8eab9d475d7959",
            "a3ae553d48004c2ca3d8c4c22557bce7",
            "c4b6f13e10884b6bb85ccd10f8ef2725",
            "3fc9b122eb1045d3be60f091414d8aaf",
            "9c5ea2f30d37428183c790f5dd66d5d9",
            "234ccc43194344109b9d67a6d0cfb054",
            "742b84f46b1d49d5b4b670de816061fe",
            "09f3466c17d6452696052e90117446cc",
            "b0824bbe5edd423f8f07edc44bf17ed3",
            "590d52c54d384e3dab3d64de9c2b1e68",
            "bd78a12011f2488c89904dbf3ce7ad52",
            "178c1f9180a04894868ec23758d80953",
            "eaa88f098e044ebfb37eaa0e69500b50",
            "153986e96841451c93b60248f2b285be",
            "b68ff467f8c444f9b588713eacd6b7ec",
            "2fbe924419fb45688951bbc25c182e6b",
            "5a09d36e9916468b911970627d51714d",
            "40d4a56348c742a599f1cd2b7164cd90",
            "33c94829601346e1b2882afddfcf44eb",
            "61a64adecd8c4693ba79a01bc775579c",
            "e3292a4360654913a995b32cc5618b50",
            "5fa9840537ad4d3e8765feb6dfe82b6c",
            "14df87c7082d4ae490c2439473cfe2f2",
            "8fca995a7d1c44c6a7c00537b38a89df",
            "8cadf25f287a42a48dccd939c398da98",
            "75605b0830494d88b730aad04bfd1388",
            "c814793272e24febb3d1eed1161fc4e9",
            "b9148c9fc52a425aa33b534c60b7aefc",
            "4053f5f90a5f487889063f13520bbb96",
            "e15d9f560f4a4439b5844f988144efae",
            "9710008f90d24d0abbec776c40f0d911",
            "f235ed60fb024bb28d474e0844de6dc5",
            "4cca7fd00604480da1f7472a0336f10d",
            "b4c4a79fb0c942ccbd5fad79795616f4",
            "9e02565c94b1463b88039d3cdea2ea46",
            "468faca8d58e417696ac24a8d01289bf",
            "2694e5b3d20b4cb6a1ad8cf4e6d009f3",
            "8e3326f74d10465b970a87b0d0bbd343",
            "f88fd6543de54e049d7dc34204f860ed",
            "7351c01db076435f91cc08b5d6ca5ed0",
            "8c51aa9adba54dc892ad27b4a28fcbb3",
            "c34714fc159d4c05bf8d950e661ec8ca",
            "a7a09645618d489e91e8cc9f378f5711",
            "369d1e19491d435d80576b423ffb2f10",
            "b76660900afe497f8939f5fb38585888",
            "dc30dbabe8b3423c9344824a45582176",
            "f92e035cd1dd4e56933f628f76dfd7d9",
            "472f8a80cd8e4f3aa4c07d1a0ef8ce24",
            "ab9ef85eba744c26a74d843735647d23",
            "45cdd59829a34c5b9b330358747ac571",
            "0ad70785c37e41eca3e039f140eb9662",
            "bf63b6a2692e4c29b975354b7e9645fd",
            "7f54ef2c798b47efafe1b36e54f05fb2",
            "fb9032148b5a42479ce2b15cc7e43115",
            "7cb44a2904db4e2f93600c0481548bb9",
            "5db9b537c624470584b643aa37e9ddfa",
            "61e43b4243f6407e8c6a9caf9a82c5ec",
            "5721536c88b7442790eb3ccea33208b8",
            "2df14cda66d4410aafb03c3dd82dfeac",
            "f851de7d640b4b318f41a0f4bcea1e26",
            "b3cf5bf63d304c97a42cce7d034b3345",
            "a8e51e52c43d46aca03975e59453c648",
            "26dc641655c242c788f321da2045a526",
            "9ec4bd8dab764fb1b4789ac5cf13ef7f",
            "29bf837d68144d8e8eb826fd7b49ddcb",
            "27c8c91c01f24872b8237f72605192af",
            "4487f430654946fa9d2a42085a82446f",
            "2741a2e820a240ce9cb0e634dd7ccb7e",
            "f4dbfa859f0b4923bf768d01eb1483dc",
            "21596f8530654b65b80549efdf076b27",
            "7fc36ba62d0a4b329308438b5f7cd956",
            "bde38cecf5b9413792be89ef1628ca64",
            "336c1523c65944c79779037f4c07e1e2",
            "a767ae701f4c41f0ae0c54b07359b685",
            "38de685e8f844c9ca7ae6afaf5933009",
            "e74ddcf88c2442109405e57a799884f1",
            "5ff44a0257114af28eb339785b543f7f",
            "8d10ca5cf9984c77af16d7c4102bda66",
            "0392aed543b445bcb66b90a2577a29e9",
            "a9247581c195466eb939cb63d9815a9d",
            "c243f7261cb64f72ab2e542fcc2201d6",
            "f4e9a150cc814cad9fb4f25dc12c50ec",
            "c13e2c8213bd421c80c98d8f647cd743",
            "b6da8637f6c34f12ab896f092e76dd58",
            "76dfc5e3bce24d18858c5b6105926169",
            "e87970266d334b84836d87d528eb3d96",
            "f6a1bd38861c4e3ea5bb0735fad458b3",
            "69ed4177475e4e86b6f79cf209441c33",
            "6a30be8b77df4ad0aa32af1bf67ff5c1",
            "fb27d7c4fb4b4eeea890790487947930",
            "6764d8d739484907886629b42ba4e3bf",
            "8aaae3a447384f41aa05b2bbdeeda43a",
            "a21ec122a4ca4a62ba0633a8b70b4bea",
            "fd6ffd0e51624bb9b50741a3270c799a",
            "330e130fcd7947828ae247ad6f57939c",
            "fd09370a659741648d135fda8e0e0321",
            "1edc3b3e658b4bbe85e2ed2ad28493fa",
            "93042eaa33404375ac99b95ee0e7f549",
            "d7b3545c608247309e28eede5b9b5f17",
            "7f8db368217e4023aa98ea90257cee2b",
            "862584a872794d3b8cdae90781030b27",
            "1a22c48c7e4e4fbba1799998ef1f6269",
            "730e40e695bf4a49b8baa703627980b1",
            "d0850cd4fc1e45f68d3c900f88733b8d",
            "dbafce3eb5c64fd8baad140fc1a7a907",
            "600ab214cab342ba987ffb7f1f96447e",
            "9d66d6340086471a9f883963a9d636be",
            "69d7d9944c764722bd3555eb7a055a60",
            "0a140332c0764fef98a300fd6c54d057",
            "67c4f5be243b4ff69667a36649e564ec",
            "ccbaa8ef204a4fbe9098842ef7717ff6",
            "82d5478a31f846819368c15e6a8ac16e",
            "4f35946222964c8e8f91bfee6c7bf64e",
            "e95af02a6f72430f94036d95f855f053",
            "a02538b89fc94a8687e972e34de862c2",
            "8e6f19c4db344495bfcf9fad1047447c",
            "62cbf39333ba4b7198fd62361e0511df",
            "ceb76150cad04b76bf0851c198a23c71",
            "e307566bdcf34df395ae9c8ac690f623",
            "63494692fc354b04a8d269a0bb666a56",
            "797c39d609fc489c98cfc992e43005d2",
            "06d3176fc3184a09b97f89cb36a99c0c",
            "1838634f5c0b4554a3dccb3fc889478c",
            "08a18304fc1f4f1b8595381981d5006e",
            "f7974f94d49d48e6963d0d66e18b4e3e",
            "4dc0c3788f10444eb1a088d3c813973b",
            "a6a17a042ccc4587a6762cd409719539",
            "76b593bed29948898776d16bb92198c2",
            "d6bfe2f318dc4f02a9bc1c677bfa0ecb",
            "808601e8d8bb418a862546fb12c20d70",
            "5d5a07512d00481f955b3c87c892770f",
            "f3ae9078b6af43cda8ddbc57e619ab82",
            "b1fd15489f9641eb9e256be00c680370",
            "b77b64a217f64fe38792cf7dfbdf06e9",
            "63536c34a61344b99536d0f29191a823",
            "a05948a8c7164921a6f7b54c61809d3c",
            "315aed6536ae418093ec5f8f9deb95b4",
            "0b10a8a343de4707b701b235b12cdf03",
            "8398dc3c32584a689d5101da34bce8bf",
            "784b93aa7a714cdf8920153b4e02be64",
            "b3a1f7ba909c414a8812912f27323fef",
            "48a90e910cb1465c984ed916c3dea0f1",
            "53a0ebfc26f94540adf398b634a3cbba",
            "de02f0211cde4193827e0f21501365af",
            "2a099d1dcf3b4c3fa47a83878d15d63b",
            "03d47cd6dfe0404d92c2579cbe57189d",
            "1fcb6c8a4ca741b3bf044100d4d16b3a",
            "8367cfedbfc648df8b3b0627c14332a1",
            "b4cbe703a5324064988166f521bb95c3",
            "7d7d4d0aeb324aa8a8498dbcda28494d",
            "29fa1e8d0c2d4039b84aa140798f7d7f",
            "2d80fe25601d42f086d5445a4bb13f7f",
            "7715a83e0bf54c7ba69c139366c0b5a3",
            "5f164c6d87544c718588913312260173",
            "eaf1fb87bc6f46eb973504035f262d8f",
            "1fb34c34a3024169858017da48f50675",
            "439badf400f444f6bd2f934a3d329e08",
            "bf821fca3c6947cd96cb48dcc1c07873",
            "a3e55e1af1c74facb9d9aba0d91c3a1a",
            "4ee99e8e0e55441599e6d5b520ca38d7",
            "ca8b3c07531e4644851247c2d19d5828",
            "b7ea4c80e99c4c3e8853158efc1507af",
            "944b2f39224d4f19b737dce9f8534026",
            "6259321f98884886b95e431a43896461",
            "2dceac5e3f804d46bffa43138937fa29",
            "6213c97e6256433ab3bdb80668f90bb8",
            "c61e8fe425934c44ada1746bd80e6c9a",
            "dcb4090a99684c8ca7fcb3ae588fffd2",
            "4660413d43b34a638179efa0d937768e",
            "de3cbd9cf06746a88fd1096bbc790313",
            "50f8b469487242989b68a28d4a5b2a92",
            "c1954bd01c954f9ea3f4c4087d6cf72a",
            "e0a1c89884594605b70943fb7c9b6f81",
            "51b23169f4a943a8a02292646ed5a92f",
            "884e4b212b94415e8a1edf40889cc3d2",
            "ea1e5528647e4368b691506a588fd3d7",
            "7774e5a7ba6f459794dba792f587d09b",
            "4f64956bac0a4adeaf906099a0d4967d",
            "6fb4a408966b4a4ba31a6e1319827ba5",
            "b9e8caec156942269c3b22259ff0b310",
            "7136946b70bf4718a17a70a88631b136",
            "47450da0f1b442be96063d203780ed11",
            "bc4cf71ddbf148c382110e3a3c974c53",
            "b0a21911fbc044878bd2921bba0dd38b",
            "ab93933f7a844dbbabdbfc83c739042b",
            "380b45d6faa94335b4eec61f281cbe61",
            "a6438971840d44b1906122c69019d69e",
            "1fd9ba496bca4a28a951b03aad04cd70",
            "d1bb9d9efae94b45943752acbb036b30",
            "6fdc77b6b0814d04a2d1e2cbc66f06f8",
            "5fd5db257dce49e3b1f241ef3ea9ad13",
            "ac4b0544b2264fb18ad8f39e1cd6cae5",
            "418df34098364a79b5b79abfc79df558",
            "e9cf9e7d360d47219535e5d6220f9697",
            "6aca17b7da9c414b9fc1f60a5c1b0c90",
            "6e42d5c165a644eebe8399e9e9053b20",
            "165dbfc2a6ea4a44bd790132e6dfd0eb",
            "14c40ec992bd40de94632eab31afe895",
            "2bd94e82d7e54cf9b35230360e9196a4",
            "9b6b4ca2b8f34eb0975e0481116f78ce",
            "63a39cd4cf2e4eeabb8621b06600456b",
            "4114a7ef656c4eadb22beab53dedf911",
            "20c6db04a7c64c1a84eecafed7632c79",
            "ce12a43e1023423586a6d9331c658781",
            "3931e9ba6c8b4c8da9dd6451f2fb1ebb",
            "220028e6fa83441eb886e50753b99ce3",
            "d9dc446f73614c2eb831ec0a761f939e",
            "996b2692601143ff84db735baf1c52c8",
            "089e2a876b604830b09cf574e1c15058",
            "8aff5a3bb541412c9f5d8ee25e3897ea",
            "feb39a00e9634d2e8a62a922523994e7",
            "1810e9efc4d74f1eae286129cb485115",
            "9530810832cf413a8d3059b7dd834b99",
            "76a23162de3247e880e28af6ce3522c3",
            "2eb514b7b7894c28b5a4eb10717700d1",
            "ed82fe31a434473c999108f174559351",
            "c948a5237ac74651a9307569a05c3c95",
            "75c4e3a8d14c4ddabae2f8f8e2e58e38",
            "23c44ebcad244fa18ec3d6897600968d",
            "646e19c5ca4a4035922a5f4dcf3a8b0c",
            "151ef0c93a1a438c80cecb7e579c3bc5",
            "93718e94a846405ab6b7da0c7ec8d402",
            "c89569f61eab4f6993f48dba53473b2a",
            "c07b322a7ffc41c983099879e302e4a4",
            "54db724c799d406c81fe4b5e9c23d8f8",
            "c4794f0316094b31964f49c4199c690b",
            "89ff8fbb64e84600baea748215525e9e",
            "c47abe7a16d3451bbe367da4c3c1beb0",
            "1afd6a8292d44193bebf7e2c30e07ad5",
            "b9deb334bf524c6faa5bf064a4e9fe93",
            "86fccb9d34d04290b636b9ffa424f951",
            "061e647c50a24bc08357c69de8f09354",
            "9a27ee8a202e4bb2afd31a6692020ffc",
            "0cbfde68abe64cc98bd2f1a7b297bd32",
            "8f29d27e054945f39dd56de5d4ee289d",
            "480316054bdd4de6ac8ce41fd1f8878c",
            "375a0ec91b004d3aa211aec683338b66",
            "417108b53a8d4de6a99407d21abd76c3",
            "43de3ff5f5f04af491d2d16bad0d4a47",
            "0243f6e217064362890ad570a2e2d3e9",
            "36c90458ff3e4e30a831b5833a8ee040",
            "f62ea21bec114fad99a0973514658c45",
            "2637d0594e6d428f9280f63bf15b0a7c",
            "cd8e4da88dc14e468be8481024c07780",
            "d3b055d443384b7a954eb0404a0aa354",
            "b69e0a7e36114aea8e37d95b52d11959",
            "942f0383a4f54dd3807a13b77ccbe6d6",
            "3b4f7dbe8a184e2ea20e710028440057",
            "900d57413de0498389f1353184a1ddd2",
            "4e3a4adefd2d4a63ab7c4f46e01e9e9f",
            "af72acd7bfe24c93b18231d223eb169b"
          ]
        },
        "id": "GoSB3C080aiX",
        "outputId": "f3bb928b-6fa5-4282-90db-c5eed33fd736"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "2024-04-15 11:31:13,669\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2024-04-15_11-31-13   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator                   |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 10                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2024-04-15_11-31-13\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/driver_artifacts`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=40992)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_bb45e6f6_1_batch_size=16,early_stop_patience_steps=5,h=5,hidden_size=64,hist_exog_list=Close_Open_High_Low_Volume_Mark_2024-04-15_11-31-13/lightning_logs\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 2024-04-15 11:31:24.124780: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 2024-04-15 11:31:24.124828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 2024-04-15 11:31:24.126169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 2024-04-15 11:31:25.353929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 4 | embedding               | TFTEmbedding             | 1.0 K \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 83.8 K\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 284 K \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 64.8 K\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 8 | output_adapter          | Linear                   | 65    \n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 434 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 434 K     Total params\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m 1.738     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=40992)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=0, train_loss_step=3.340]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 20.60it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.340]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.77it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 24.19it/s, v_num=0, train_loss_step=3.370, train_loss_epoch=3.370]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 22.53it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 25.28it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 25.49it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.190]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 25.11it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 24.60it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 23.00it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 23.93it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 21.02it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 16.74it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=3.170]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600]        \n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 24.69it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]        \n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 25.00it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 22.02it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]\n",
            "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 18.24it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 21.37it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.600]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.26it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=4.02e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=4.02e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=4.02e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=4.02e+5]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=4.02e+5]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=4.02e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=4.02e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=4.02e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 18.21it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=4.02e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=4.02e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=4.02e+5]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 21.53it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=4.02e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=4.02e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=4.02e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 19.19it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=4.02e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=4.02e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=4.02e+5]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=4.02e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=4.02e+5]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=4.02e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=4.02e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 23.91it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=4.02e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=4.02e+5]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 21.15it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=4.02e+5]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=4.02e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=4.02e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=4.02e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=4.02e+5]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 25.15it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=4.02e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=4.02e+5]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=4.02e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=4.02e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=4.02e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 21.72it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=4.02e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=4.02e+5]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=4.02e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=4.02e+5]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=4.02e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=4.02e+5]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 23.08it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=4.02e+5]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=4.02e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=4.02e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=4.02e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=4.02e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 25.73it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=4.02e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=4.02e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 24.12it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=4.02e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=4.02e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=4.02e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=4.02e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=4.02e+5]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 23.09it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=4.02e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=4.02e+5]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=4.02e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=4.02e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=4.02e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 25.47it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=4.02e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=4.02e+5]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 21.79it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=4.02e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=4.02e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=4.02e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=4.02e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.630, valid_loss=4.02e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.12it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=3.45e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=3.45e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=3.45e+5]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 24.70it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=3.45e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=3.45e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=3.45e+5]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=3.45e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.45e+5]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.45e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 21.96it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=3.45e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=3.45e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=3.45e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=3.45e+5]\n",
            "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.45e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.45e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 23.10it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=3.45e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.45e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=3.45e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=3.45e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=3.45e+5]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 22.76it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=3.45e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=3.45e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.45e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.45e+5]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.45e+5]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 24.90it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=3.45e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.45e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=3.45e+5]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.140, valid_loss=3.45e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=3.45e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 25.79it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=3.45e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=3.45e+5]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 22.92it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=3.45e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.45e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=3.45e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=3.45e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=3.45e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=3.45e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 22.91it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=3.45e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=3.45e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.45e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=3.45e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=3.45e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 25.09it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=3.45e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.45e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 21.69it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.45e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=3.45e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=3.45e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=3.45e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=3.45e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=3.45e+5]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 25.78it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.45e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=3.45e+5]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 22.83it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=3.45e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.45e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=3.45e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=3.45e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.45e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=3.45e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=3.45e+5]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 19.68it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=3.45e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=3.45e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.45e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=1.950, valid_loss=3.45e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.57it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.28e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=3.28e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=3.28e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=3.28e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.28e+5]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.28e+5]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.28e+5]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.28e+5]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 21.95it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.28e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.28e+5]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=3.28e+5]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=3.28e+5]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 22.75it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=3.28e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.28e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=3.28e+5]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.28e+5]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.230, valid_loss=3.28e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.28e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=3.28e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=3.28e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=3.28e+5]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=3.28e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=3.28e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.28e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.28e+5]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.140, valid_loss=3.28e+5]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=3.28e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.28e+5]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=3.28e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=3.28e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.28e+5]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 17.31it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.28e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=3.28e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=3.28e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=3.28e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=3.28e+5]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.28e+5]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.28e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=3.28e+5]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=3.28e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=3.28e+5]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 24.75it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.28e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.28e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.28e+5]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=3.28e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.28e+5]\n",
            "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 21.71it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=3.28e+5]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=3.28e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=3.28e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.28e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=3.28e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 25.59it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.28e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.28e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=3.28e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.28e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.28e+5]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.28e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.28e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.200, valid_loss=3.28e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.28e+5]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 23.77it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.28e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.28e+5]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 22.01it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.28e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=3.28e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.28e+5]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.28e+5]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.28e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.28e+5]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 23.62it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.28e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.28e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.160, valid_loss=3.28e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.28it/s]\u001b[A\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 20.80it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.25e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=3.25e+5]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 22.96it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.25e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.25e+5]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=3.25e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=3.25e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.25e+5]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 20.27it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.25e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=3.25e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=3.25e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.25e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=3.25e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 24.40it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.25e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=3.25e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.25e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=3.25e+5]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.25e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.25e+5]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 23.38it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.25e+5]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.120, valid_loss=3.25e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.25e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 23.43it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.25e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=3.25e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=3.25e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=3.25e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.25e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.530, valid_loss=3.25e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.25e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 25.42it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.25e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.25e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.25e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.25e+5]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 23.82it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.25e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.25e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=3.25e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=3.25e+5]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.25e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 24.34it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=3.25e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.25e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.25e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.25e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=3.25e+5]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 22.64it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=3.25e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.25e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 23.72it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.25e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.25e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=3.25e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=3.25e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 16.82it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.320, valid_loss=3.25e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=3.25e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 25.01it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.25e+5]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=3.25e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=3.25e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.25e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=3.25e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 23.42it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=3.25e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=3.25e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 24.79it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=3.25e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=3.25e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.25e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=3.25e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 23.62it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.25e+5]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.25e+5]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=3.25e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.25e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 24.83it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.25e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.25e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.25e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 25.13it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=3.25e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=3.25e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.110, valid_loss=3.25e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.91it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=3.23e+5]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=3.23e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.23e+5]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.23e+5]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00, 25.78it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.23e+5]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.23e+5]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00, 21.96it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=3.23e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=3.23e+5]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=3.23e+5]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=3.23e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.23e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=3.23e+5]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 22.33it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.23e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.23e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.23e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=3.23e+5]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=3.23e+5]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.23e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=3.23e+5]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=3.23e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=3.23e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=1.950, valid_loss=3.23e+5]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=3.23e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=3.23e+5]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=3.23e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=3.23e+5]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.23e+5]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00, 21.82it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=3.23e+5]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=3.23e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.23e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 18.26it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.23e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 16.02it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.190, valid_loss=3.23e+5]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.23e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.23e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=3.23e+5]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.23e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.23e+5]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=3.23e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=3.23e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=3.23e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.23e+5]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=3.23e+5]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00, 20.40it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.23e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=3.23e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.23e+5]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.23e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.23e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.23e+5]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=3.23e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.23e+5]        \n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.23e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.23e+5]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.23e+5]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=3.23e+5]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 23.57it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=3.23e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.23e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 25.41it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.23e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=3.23e+5]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00, 23.47it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=3.23e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.23e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=3.23e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.23e+5]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.23e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.23e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00, 24.73it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=3.23e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.23e+5]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=3.23e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=2.230, valid_loss=3.23e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.52it/s]\u001b[A\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.24e+5]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.24e+5]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=3.24e+5]\n",
            "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 21.76it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=3.24e+5]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.24e+5]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=3.24e+5]\n",
            "Epoch 611: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=3.24e+5]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=3.24e+5]\n",
            "Epoch 613: 100%|██████████| 1/1 [00:00<00:00, 21.75it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.24e+5]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.24e+5]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.24e+5]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.24e+5]\n",
            "Epoch 620: 100%|██████████| 1/1 [00:00<00:00, 24.85it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=3.24e+5]\n",
            "Epoch 620: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.24e+5]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.24e+5]\n",
            "Epoch 622: 100%|██████████| 1/1 [00:00<00:00, 25.24it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=3.24e+5]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.24e+5]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=3.24e+5]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.24e+5]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.24e+5]\n",
            "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 22.44it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=3.24e+5]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.24e+5]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=3.24e+5]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=3.24e+5]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.24e+5]\n",
            "Epoch 640: 100%|██████████| 1/1 [00:00<00:00, 25.22it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.24e+5]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=3.24e+5]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.24e+5]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.24e+5]\n",
            "Epoch 647: 100%|██████████| 1/1 [00:00<00:00, 24.49it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.24e+5]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=3.24e+5]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.24e+5]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=3.24e+5]\n",
            "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 25.18it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.24e+5]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.24e+5]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.24e+5]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=3.24e+5]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.24e+5]\n",
            "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 20.80it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.24e+5]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=3.24e+5]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=3.24e+5]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.24e+5]\n",
            "Epoch 670: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=2.000, valid_loss=3.24e+5]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.24e+5]\n",
            "Epoch 672: 100%|██████████| 1/1 [00:00<00:00, 24.21it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.24e+5]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.24e+5]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.24e+5]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.24e+5]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00, 25.38it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=3.24e+5]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=3.24e+5]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=3.24e+5]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.24e+5]\n",
            "Epoch 681: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.24e+5]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.24e+5]\n",
            "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 24.61it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=3.24e+5]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.24e+5]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.24e+5]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.24e+5]\n",
            "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.24e+5]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.24e+5]\n",
            "Epoch 692: 100%|██████████| 1/1 [00:00<00:00, 22.04it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.24e+5]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.24e+5]\n",
            "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 22.23it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.24e+5]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.24e+5]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.24e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.140, valid_loss=3.24e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.69it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.4e+5]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=3.4e+5]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=3.4e+5]\n",
            "Epoch 706: 100%|██████████| 1/1 [00:00<00:00, 24.19it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=3.4e+5]\n",
            "Epoch 706: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.4e+5]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.4e+5]\n",
            "Epoch 708: 100%|██████████| 1/1 [00:00<00:00, 22.52it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.4e+5]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.4e+5]\n",
            "Epoch 710: 100%|██████████| 1/1 [00:00<00:00, 22.48it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.4e+5]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.4e+5]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.4e+5]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.4e+5]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 24.57it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.4e+5]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=3.4e+5]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=3.4e+5]\n",
            "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 25.51it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=3.4e+5]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.4e+5]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.4e+5]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.4e+5]\n",
            "Epoch 726: 100%|██████████| 1/1 [00:00<00:00, 23.97it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.4e+5]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=3.4e+5]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=3.4e+5]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.4e+5]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.4e+5]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 22.36it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.4e+5]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=3.4e+5]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.4e+5]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.4e+5]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.4e+5]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.4e+5]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.4e+5]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=3.4e+5]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.4e+5]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=3.4e+5]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=3.4e+5]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.4e+5]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=3.4e+5]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.4e+5]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.4e+5]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=3.4e+5]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 19.40it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.4e+5]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.940, valid_loss=3.4e+5]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.4e+5]\n",
            "Epoch 764: 100%|██████████| 1/1 [00:00<00:00, 22.03it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.4e+5]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.4e+5]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=3.4e+5]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.4e+5]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.4e+5]\n",
            "Epoch 772: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.4e+5]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.4e+5]        \n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.4e+5]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.4e+5]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.4e+5]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.4e+5]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 20.53it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.4e+5]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=3.4e+5]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.4e+5]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.4e+5]\n",
            "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.4e+5]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.4e+5]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.4e+5]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.4e+5]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.4e+5]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.4e+5]\n",
            "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 21.29it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.4e+5]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.4e+5]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=3.4e+5]\n",
            "Epoch 798: 100%|██████████| 1/1 [00:00<00:00, 19.33it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=3.4e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.930, valid_loss=3.4e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.56it/s]\u001b[A\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.930, valid_loss=3.61e+5]\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=3.61e+5]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=3.61e+5]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=3.61e+5]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.61e+5]\n",
            "Epoch 804: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.61e+5]\n",
            "Epoch 804: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.61e+5]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.61e+5]        \n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.61e+5]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=3.61e+5]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=3.61e+5]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.61e+5]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 21.73it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.61e+5]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.61e+5]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.61e+5]        \n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.61e+5]\n",
            "Epoch 815: 100%|██████████| 1/1 [00:00<00:00, 22.45it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.61e+5]\n",
            "Epoch 815: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.61e+5]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=3.61e+5]\n",
            "Epoch 817: 100%|██████████| 1/1 [00:00<00:00, 24.94it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.61e+5]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.61e+5]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.61e+5]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=3.61e+5]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.61e+5]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.61e+5]\n",
            "Epoch 826: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.61e+5]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.61e+5]        \n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.61e+5]\n",
            "Epoch 828: 100%|██████████| 1/1 [00:00<00:00, 24.04it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=3.61e+5]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.61e+5]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.61e+5]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.61e+5]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.61e+5]\n",
            "Epoch 837: 100%|██████████| 1/1 [00:00<00:00, 21.49it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.61e+5]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.61e+5]\n",
            "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 23.61it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.61e+5]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=3.61e+5]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.61e+5]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.61e+5]\n",
            "Epoch 846: 100%|██████████| 1/1 [00:00<00:00, 16.82it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=3.61e+5]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=3.61e+5]\n",
            "Epoch 848: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.61e+5]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.61e+5]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=3.61e+5]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.61e+5]\n",
            "Epoch 855: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.61e+5]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.61e+5]\n",
            "Epoch 857: 100%|██████████| 1/1 [00:00<00:00, 20.75it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.61e+5]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.61e+5]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00, 23.29it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=3.61e+5]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.61e+5]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.61e+5]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.61e+5]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.61e+5]\n",
            "Epoch 868: 100%|██████████| 1/1 [00:00<00:00, 24.94it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=3.61e+5]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.61e+5]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.61e+5]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.61e+5]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.61e+5]\n",
            "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 22.16it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.61e+5]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.61e+5]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.61e+5]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.61e+5]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=3.61e+5]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.61e+5]\n",
            "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 22.65it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.61e+5]\n",
            "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=3.61e+5]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=3.61e+5]\n",
            "Epoch 890: 100%|██████████| 1/1 [00:00<00:00, 25.80it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.61e+5]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.61e+5]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.61e+5]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.61e+5]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.61e+5]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=3.61e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=2.000, valid_loss=3.61e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.37it/s]\u001b[A\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.75e+5]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.75e+5]\n",
            "Epoch 902: 100%|██████████| 1/1 [00:00<00:00, 18.84it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.75e+5]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=3.75e+5]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=3.75e+5]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.75e+5]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=3.75e+5]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 25.55it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=3.75e+5]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.75e+5]\n",
            "Epoch 913: 100%|██████████| 1/1 [00:00<00:00, 20.06it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.75e+5]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=3.75e+5]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.75e+5]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=3.75e+5]\n",
            "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 21.62it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.75e+5]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.75e+5]\n",
            "Epoch 922: 100%|██████████| 1/1 [00:00<00:00, 25.86it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.75e+5]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.75e+5]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.75e+5]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.75e+5]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.75e+5]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=3.75e+5]\n",
            "Epoch 933: 100%|██████████| 1/1 [00:00<00:00, 25.29it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=3.75e+5]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.75e+5]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.75e+5]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.75e+5]\n",
            "Epoch 940: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.75e+5]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.75e+5]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.75e+5]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.75e+5]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=3.75e+5]\n",
            "Epoch 949: 100%|██████████| 1/1 [00:00<00:00, 21.13it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.75e+5]\n",
            "Epoch 949: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.610, valid_loss=3.75e+5]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.75e+5]\n",
            "Epoch 951: 100%|██████████| 1/1 [00:00<00:00, 24.71it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=3.75e+5]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.75e+5]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.75e+5]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.75e+5]\n",
            "Epoch 958: 100%|██████████| 1/1 [00:00<00:00, 25.40it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.75e+5]\n",
            "Epoch 958: 100%|██████████| 1/1 [00:00<00:00, 17.30it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.75e+5]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.75e+5]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.75e+5]\n",
            "Epoch 960: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.75e+5]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.75e+5]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.75e+5]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.75e+5]\n",
            "Epoch 967: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.75e+5]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=3.75e+5]\n",
            "Epoch 969: 100%|██████████| 1/1 [00:00<00:00, 19.09it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.75e+5]\n",
            "Epoch 969: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.800, valid_loss=3.75e+5]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=3.75e+5]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.75e+5]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.75e+5]\n",
            "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.75e+5]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=3.75e+5]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=3.75e+5]\n",
            "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 21.87it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.75e+5]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.75e+5]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.75e+5]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.75e+5]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.75e+5]\n",
            "Epoch 985: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.75e+5]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.75e+5]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.75e+5]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=3.75e+5]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.75e+5]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.75e+5]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.75e+5]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=3.75e+5]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=3.75e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=40992)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "2024-04-15 11:32:31,595\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=3.75e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.620, valid_loss=3.75e+5]\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.75it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=40992)\u001b[0m \r                                                                      \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.620, valid_loss=4e+5]   \rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=4e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=4e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41369)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_52c50480_2_batch_size=16,early_stop_patience_steps=5,h=5,hidden_size=64,hist_exog_list=Close_Open_High_Low_Volume_Mark_2024-04-15_11-31-22/lightning_logs\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 2024-04-15 11:32:41.007880: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 2024-04-15 11:32:41.007930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 2024-04-15 11:32:41.009298: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 2024-04-15 11:32:42.190661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 4 | embedding               | TFTEmbedding             | 1.0 K \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 83.8 K\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 284 K \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 64.8 K\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 8 | output_adapter          | Linear                   | 65    \n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 434 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 434 K     Total params\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m 1.738     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41369)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=0, train_loss_step=3.340]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.63it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 19.82it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 21.57it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 19.83it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.060]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 24.44it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 25.29it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 23.01it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 17.31it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=1.920]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.92it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=3.51e+5]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 22.77it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.51e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=3.51e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.51e+5]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.51e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 23.25it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=3.51e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.51e+5]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 24.05it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.51e+5]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 24.37it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=3.51e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=3.51e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=3.51e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=3.51e+5]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.710, valid_loss=3.51e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=3.51e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 25.64it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.51e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.51e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 23.06it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.51e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=3.51e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.51e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=3.51e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.51e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.51e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 23.13it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.51e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.600, valid_loss=3.51e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=3.51e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 23.51it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.51e+5]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.51e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.51e+5]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.51e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.51e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.51e+5]\n",
            "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 24.14it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.51e+5]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.51e+5]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.51e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=3.51e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.51e+5]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 22.85it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.51e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.51e+5]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.51e+5]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.51e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.51e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.51e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.51e+5]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 21.96it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.51e+5]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 25.48it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.51e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.51e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.51e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.51e+5]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.51e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.51e+5]        \n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.51e+5]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 18.77it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.51e+5]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.51e+5]        \n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.51e+5]\n",
            "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 23.10it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.51e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.51e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.51e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.51e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 17.10it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.430, valid_loss=3.51e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.51e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 22.06it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.51e+5]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.51e+5]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.51e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.51e+5]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 22.60it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.51e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.51e+5]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 24.91it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.51e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.51e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.51e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.330, valid_loss=3.51e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.58it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.69e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 22.19it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.69e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.69e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.69e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.69e+5]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.69e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.69e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 23.10it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.69e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 24.90it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.69e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.69e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.69e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.69e+5]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.69e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.69e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.69e+5]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 18.40it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.69e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=3.69e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=3.69e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.69e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.69e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 20.90it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=3.69e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=3.69e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.69e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=3.69e+5]        \n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=3.69e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=3.69e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=3.69e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=3.69e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=3.69e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=3.69e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=3.69e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=3.69e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=3.69e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=3.69e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=3.69e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.880, valid_loss=3.69e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=3.69e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=3.69e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 22.01it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=3.69e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=3.69e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=3.69e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=3.69e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=3.69e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=3.69e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 21.75it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=3.69e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=3.69e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=3.69e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=3.69e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=3.69e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=3.69e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=3.69e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=3.69e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=3.69e+5]\n",
            "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 17.53it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=3.69e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=3.69e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=3.69e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=3.69e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 18.03it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=3.69e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=3.69e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=3.69e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=3.69e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=3.69e+5]        \n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=3.69e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 22.62it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=3.69e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=3.69e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 23.85it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=3.69e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=3.69e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=3.69e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=3.69e+5]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 25.28it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=3.69e+5]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 17.19it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.674, valid_loss=3.69e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=3.69e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.601, valid_loss=3.69e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.45it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=4.16e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=4.16e+5]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=4.16e+5]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=4.16e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=4.16e+5]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=4.16e+5]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=4.16e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=4.16e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=4.16e+5]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 21.59it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=4.16e+5]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=4.16e+5]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 23.52it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=4.16e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=4.16e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=4.16e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=4.16e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=4.16e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 23.96it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=4.16e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=4.16e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=4.16e+5]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 24.86it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=4.16e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=4.16e+5]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 23.08it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=4.16e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=4.16e+5]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=4.16e+5]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=4.16e+5]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 21.99it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=4.16e+5]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.547, valid_loss=4.16e+5]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=4.16e+5]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 24.56it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=4.16e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=4.16e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=4.16e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=4.16e+5]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=4.16e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=4.16e+5]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 21.58it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=4.16e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=4.16e+5]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=4.16e+5]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=4.16e+5]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=4.16e+5]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 25.49it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=4.16e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=4.16e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=4.16e+5]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=4.16e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=4.16e+5]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=4.16e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=4.16e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=4.16e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=4.16e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=4.16e+5]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 24.21it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=4.16e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=4.16e+5]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 25.04it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=4.16e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=4.16e+5]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=4.16e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=4.16e+5]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=4.16e+5]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=4.16e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 22.90it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=4.16e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=4.16e+5]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=4.16e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=4.16e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=4.16e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=4.16e+5]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=4.16e+5]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=4.16e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=4.16e+5]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 24.88it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=4.16e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=4.16e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=4.16e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.442, valid_loss=4.16e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.98it/s]\u001b[A\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=4.63e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=4.63e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=4.63e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.479, valid_loss=4.63e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=4.63e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=4.63e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 19.49it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=4.63e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=4.63e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=4.63e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=4.63e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=4.63e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 25.43it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=4.63e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=4.63e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=4.63e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=4.63e+5]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 23.22it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=4.63e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=4.63e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=4.63e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=4.63e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=4.63e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=4.63e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=4.63e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 22.43it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=4.63e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=4.63e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=4.63e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 25.45it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=4.63e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=4.63e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=4.63e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=4.63e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=4.63e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=4.63e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=4.63e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=4.63e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=4.63e+5]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=4.63e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=4.63e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=4.63e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=4.63e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.349, valid_loss=4.63e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=4.63e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=4.63e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=4.63e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=4.63e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=4.63e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=4.63e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=4.63e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=4.63e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=4.63e+5]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 19.14it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=4.63e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=4.63e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=4.63e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=4.63e+5]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=4.63e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=4.63e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 21.22it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=4.63e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.347, valid_loss=4.63e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=4.63e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=4.63e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=4.63e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=4.63e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 22.11it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=4.63e+5]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=4.63e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=4.63e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=4.63e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=4.63e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 20.50it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=4.63e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=4.63e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.369, valid_loss=4.63e+5]\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.52it/s]\u001b[A\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=4.8e+5]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=4.8e+5]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=4.8e+5]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=4.8e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=4.8e+5]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=4.8e+5]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=4.8e+5]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 20.55it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=4.8e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=4.8e+5]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=4.8e+5]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=4.8e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=4.8e+5]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 24.55it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=4.8e+5]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=4.8e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=4.8e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=4.8e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00, 25.15it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=4.8e+5]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=4.8e+5]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 20.63it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=4.8e+5]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=4.8e+5]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=4.8e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=4.8e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 24.47it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=4.8e+5]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=4.8e+5]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00, 24.04it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=4.8e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=4.8e+5]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=4.8e+5]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=4.8e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 24.96it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=4.8e+5]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=4.8e+5]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 21.39it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=4.8e+5]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=4.8e+5]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=4.8e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=4.8e+5]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=4.8e+5]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=4.8e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=4.8e+5]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=4.8e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=4.8e+5]        \n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=4.8e+5]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00, 24.35it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=4.8e+5]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=4.8e+5]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=4.8e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=4.8e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=4.8e+5]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 21.91it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=4.8e+5]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 16.96it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.325, valid_loss=4.8e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=4.8e+5]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00, 23.99it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=4.8e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=4.8e+5]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 24.04it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=4.8e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=4.8e+5]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=4.8e+5]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=4.8e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=4.8e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 25.07it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=4.8e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=4.8e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=4.8e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=4.8e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=4.8e+5]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00, 23.76it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=4.8e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=4.8e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00, 22.40it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=4.8e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.277, valid_loss=4.8e+5]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=4.8e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00, 24.66it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=4.8e+5]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=4.8e+5]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 23.86it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=4.8e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:33:23,063\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.282, valid_loss=4.8e+5]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=4.8e+5]\rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=4.8e+5]        \rEpoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=4.8e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 24.89it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=4.8e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.274, valid_loss=4.8e+5]\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.57it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41369)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.274, valid_loss=5.04e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=5.04e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=5.04e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41631)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_38ea469e_3_batch_size=32,early_stop_patience_steps=5,h=5,hidden_size=128,hist_exog_list=Close_Open_High_Low_Volume_Mar_2024-04-15_11-32-39/lightning_logs\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 2024-04-15 11:33:32.437461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 2024-04-15 11:33:32.437515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 2024-04-15 11:33:32.439034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 2024-04-15 11:33:33.640334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 4 | embedding               | TFTEmbedding             | 2.0 K \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 331 K \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 1.1 M \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 256 K \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 8 | output_adapter          | Linear                   | 129   \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 1.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 1.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m 6.834     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41631)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.570]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 10.27it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 12.09it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=2.130]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]\n",
            "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.090]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=2.110]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 11.34it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.090]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]\n",
            "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]        \n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 11.42it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=1.910]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.92it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=4.71e+5]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=4.71e+5]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=4.71e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=4.71e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=4.71e+5]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=4.71e+5]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=4.71e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=4.71e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=4.71e+5]\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=4.71e+5]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.71e+5]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.71e+5]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=4.71e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=4.71e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=4.71e+5]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=4.71e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=4.71e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=4.71e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=4.71e+5]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=4.71e+5]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=4.71e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.71e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=4.71e+5]\n",
            "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=4.71e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=4.71e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=4.71e+5]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=4.71e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=4.71e+5]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=4.71e+5]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=4.71e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=4.71e+5]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=4.71e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=4.71e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=4.71e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=4.71e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=4.71e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=4.71e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=4.71e+5]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=4.71e+5]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=4.71e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=4.71e+5]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=4.71e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=4.71e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=4.71e+5]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=4.71e+5]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.71e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.71e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=4.71e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=4.71e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=4.71e+5]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=4.71e+5]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=4.71e+5]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=4.71e+5]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=4.71e+5]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.770, valid_loss=4.71e+5]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=4.71e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.71e+5]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.71e+5]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=4.71e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=4.71e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=4.71e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=4.71e+5]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=4.71e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=4.71e+5]\n",
            "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=4.71e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=4.71e+5]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=4.71e+5]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=4.71e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=4.71e+5]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=4.71e+5]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=4.71e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=4.71e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=4.71e+5]\n",
            "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=4.71e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=4.71e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=4.71e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=4.71e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=4.71e+5]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=4.71e+5]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.71e+5]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.71e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=4.71e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.71e+5]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.71e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=4.71e+5]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.71e+5]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.71e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=4.71e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.71e+5]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.71e+5]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=4.71e+5]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.71e+5]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.71e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=4.71e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=4.71e+5]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=4.71e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=4.71e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.71e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.71e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.71e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=4.71e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=4.71e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=4.71e+5]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=4.71e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=4.71e+5]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=4.71e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=4.71e+5]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=4.71e+5]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=4.71e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=4.71e+5]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=4.71e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=4.71e+5]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=4.71e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=4.71e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.71e+5]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.71e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=4.71e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=4.71e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=4.71e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=4.71e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=4.71e+5]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=4.71e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=4.71e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=4.71e+5]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=4.71e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=4.71e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.71e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.71e+5]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.71e+5]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.71e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=4.71e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=4.71e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=4.71e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.970, valid_loss=4.71e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.89it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.82e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.82e+5]\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.82e+5]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=3.82e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.82e+5]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.82e+5]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.82e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=3.82e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.82e+5]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.82e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.82e+5]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.82e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.82e+5]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.82e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.82e+5]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=3.82e+5]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.82e+5]\n",
            "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.82e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.82e+5]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.82e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=3.82e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.82e+5]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.82e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.82e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.82e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.82e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.82e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.82e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.82e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.82e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.82e+5]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.82e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.82e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.82e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.82e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.82e+5]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.82e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.82e+5]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.82e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.82e+5]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.82e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.82e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.82e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.82e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.82e+5]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.82e+5]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.82e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.82e+5]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.82e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.82e+5]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.82e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.82e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.82e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.82e+5]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.82e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.82e+5]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.82e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=3.82e+5]\n",
            "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.82e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.82e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.82e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=3.82e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.82e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.82e+5]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.82e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.82e+5]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.82e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.82e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.82e+5]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.82e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.82e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.82e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.82e+5]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.82e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.82e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.82e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.82e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.82e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.82e+5]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.82e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.82e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.82e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.82e+5]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.82e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.82e+5]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.82e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.82e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.82e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.82e+5]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.82e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.82e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.82e+5]\n",
            "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.82e+5]\n",
            "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.680, valid_loss=3.82e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.82e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.82e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.82e+5]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.82e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.82e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.82e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.82e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.82e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.82e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.82e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.82e+5]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.82e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.82e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=3.82e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.82e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.82e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.82e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.82e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.470, valid_loss=3.82e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.07it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.08e+5]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.08e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.08e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=3.08e+5]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 10.71it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.08e+5]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.08e+5]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.08e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.08e+5]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.08e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.08e+5]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.08e+5]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.08e+5]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.08e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.08e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.08e+5]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.08e+5]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.08e+5]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.08e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]        \n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.08e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.08e+5]\n",
            "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.08e+5]\n",
            "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 11.61it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.08e+5]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.08e+5]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.08e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.08e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.08e+5]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.08e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.08e+5]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.08e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.08e+5]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.08e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.08e+5]\n",
            "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.08e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.08e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=3.08e+5]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.08e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.520, valid_loss=3.08e+5]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.08e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 11.22it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.08e+5]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=3.08e+5]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.620, valid_loss=3.08e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.71it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.99e+5]\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.99e+5]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=2.99e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.99e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.99e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.99e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.99e+5]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.99e+5]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.99e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.99e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 10.00it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=2.99e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.99e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.99e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.99e+5]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.99e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.99e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.99e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 11.64it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.99e+5]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.99e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.99e+5]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.99e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=2.99e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.99e+5]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.99e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=2.99e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.99e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.99e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=2.99e+5]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.99e+5]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.99e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=2.99e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=2.99e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=2.99e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=2.99e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.99e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=2.99e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=2.99e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.99e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.99e+5]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.99e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.99e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.99e+5]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.99e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=2.99e+5]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=2.99e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.99e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.99e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=2.99e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.99e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=2.99e+5]\n",
            "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=2.99e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.99e+5]\n",
            "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.99e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=2.99e+5]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.99e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.99e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.99e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.99e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=2.99e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.240, valid_loss=2.99e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.99e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.99e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=2.99e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.99e+5]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.99e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.99e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.99e+5]\n",
            "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.99e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.99e+5]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.99e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=2.99e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.99e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.99e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=2.99e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.99e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.99e+5]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.99e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.99e+5]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.99e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 11.27it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.99e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=2.99e+5]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=2.99e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.99e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=2.99e+5]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=2.99e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.99e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.99e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.99e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=2.99e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=2.99e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.99e+5]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.99e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.99e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.99e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.99e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=2.99e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=2.99e+5]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.99e+5]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=2.99e+5]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=2.99e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=2.99e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=2.99e+5]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=2.99e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.99e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.99e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=2.99e+5]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.99e+5]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.99e+5]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.99e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.99e+5]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.99e+5]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.300, valid_loss=2.99e+5]\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 22.87it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.98e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.98e+5]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.98e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.98e+5]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.98e+5]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00, 11.47it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.98e+5]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=2.98e+5]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.98e+5]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.98e+5]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.98e+5]\n",
            "Epoch 511: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.98e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.98e+5]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.98e+5]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.98e+5]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.98e+5]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.98e+5]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.98e+5]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.98e+5]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.98e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=2.98e+5]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=2.98e+5]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=2.98e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 519: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.98e+5]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.98e+5]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.98e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.98e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 524: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.98e+5]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.98e+5]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.98e+5]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.98e+5]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.98e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.98e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.98e+5]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.98e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.98e+5]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.98e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.98e+5]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.98e+5]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.98e+5]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.98e+5]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 539: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.98e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.98e+5]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.98e+5]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.98e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.98e+5]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.98e+5]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.98e+5]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.98e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.98e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.98e+5]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=2.98e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=2.98e+5]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.98e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.98e+5]\n",
            "Epoch 551: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.98e+5]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=2.98e+5]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=2.98e+5]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.98e+5]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.98e+5]\n",
            "Epoch 555: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.98e+5]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=2.98e+5]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=2.98e+5]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=2.98e+5]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.98e+5]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=2.98e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.98e+5]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.98e+5]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=2.98e+5]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=2.98e+5]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.98e+5]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.98e+5]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=2.98e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.98e+5]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.98e+5]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.330, valid_loss=2.98e+5]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=2.98e+5]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=2.98e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.98e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.98e+5]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=2.98e+5]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.98e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.98e+5]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.98e+5]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.98e+5]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.98e+5]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00, 10.98it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.98e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.98e+5]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=2.98e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.98e+5]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.98e+5]\n",
            "Epoch 584: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.98e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.98e+5]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=2.98e+5]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=2.98e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.98e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=2.98e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.98e+5]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=2.98e+5]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=2.98e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.98e+5]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.98e+5]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.98e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.98e+5]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=2.98e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=2.98e+5]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=2.98e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=2.98e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=2.98e+5]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.98e+5]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=2.98e+5]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=2.98e+5]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=2.98e+5]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.98e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.180, valid_loss=2.98e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.26it/s]\u001b[A\n",
            "Epoch 600: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.02e+5]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.02e+5]\n",
            "Epoch 601: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.02e+5]\n",
            "Epoch 602: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 603: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]        \n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.02e+5]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.02e+5]\n",
            "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.02e+5]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.02e+5]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.02e+5]\n",
            "Epoch 610: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.02e+5]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.02e+5]\n",
            "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.02e+5]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.02e+5]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 614: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 615: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 616: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 616: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 617: 100%|██████████| 1/1 [00:00<00:00, 10.76it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 619: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 621: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.02e+5]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.02e+5]\n",
            "Epoch 623: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.02e+5]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.02e+5]\n",
            "Epoch 627: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.02e+5]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 629: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 629: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.02e+5]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.02e+5]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 631: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 632: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.02e+5]\n",
            "Epoch 634: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.02e+5]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 638: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.02e+5]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 640: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.02e+5]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.02e+5]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 644: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 645: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.02e+5]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 646: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]        \n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 647: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 649: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.02e+5]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.02e+5]\n",
            "Epoch 651: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.02e+5]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 653: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 654: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 654: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.02e+5]\n",
            "Epoch 655: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.02e+5]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 656: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.02e+5]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.02e+5]\n",
            "Epoch 658: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.02e+5]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.02e+5]\n",
            "Epoch 659: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.02e+5]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 660: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.02e+5]\n",
            "Epoch 662: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.02e+5]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.02e+5]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.02e+5]\n",
            "Epoch 664: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.02e+5]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.02e+5]\n",
            "Epoch 665: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.02e+5]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.02e+5]\n",
            "Epoch 669: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.02e+5]\n",
            "Epoch 669: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 670: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 672: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 674: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.02e+5]\n",
            "Epoch 675: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.02e+5]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.02e+5]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.02e+5]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.02e+5]\n",
            "Epoch 681: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.02e+5]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.02e+5]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 685: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.02e+5]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.02e+5]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.02e+5]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.02e+5]\n",
            "Epoch 687: 100%|██████████| 1/1 [00:00<00:00, 11.64it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.02e+5]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.02e+5]\n",
            "Epoch 688: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.02e+5]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.02e+5]\n",
            "Epoch 689: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 691: 100%|██████████| 1/1 [00:00<00:00, 10.36it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 692: 100%|██████████| 1/1 [00:00<00:00, 11.47it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 696: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 697: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.02e+5]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 698: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.02e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.630, valid_loss=3.02e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.98it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Epoch 700: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 701: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.02e+5]\n",
            "Epoch 702: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.02e+5]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 704: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.02e+5]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 706: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 708: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.02e+5]\n",
            "Epoch 710: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.02e+5]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.02e+5]\n",
            "Epoch 712: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.02e+5]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.02e+5]\n",
            "Epoch 714: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.02e+5]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 715: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.02e+5]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.02e+5]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.02e+5]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.02e+5]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.02e+5]\n",
            "Epoch 724: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.02e+5]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.02e+5]\n",
            "Epoch 725: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.02e+5]\n",
            "Epoch 726: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.02e+5]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 727: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 727: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.02e+5]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.02e+5]\n",
            "Epoch 730: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.02e+5]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.02e+5]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]        \n",
            "Epoch 732: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=3.02e+5]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.02e+5]\n",
            "Epoch 734: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.02e+5]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.02e+5]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.02e+5]\n",
            "Epoch 736: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.02e+5]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.02e+5]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 738: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.02e+5]\n",
            "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.02e+5]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.02e+5]\n",
            "Epoch 742: 100%|██████████| 1/1 [00:00<00:00, 11.06it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.02e+5]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.02e+5]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.02e+5]\n",
            "Epoch 744: 100%|██████████| 1/1 [00:00<00:00, 11.22it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.02e+5]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 746: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.02e+5]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 749: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 750: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.02e+5]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.02e+5]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.02e+5]\n",
            "Epoch 752: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.100, valid_loss=3.02e+5]\n",
            "Epoch 752: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 753: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 754: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.02e+5]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 755: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 756: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 757: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 758: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 759: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 759: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 760: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 761: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.02e+5]\n",
            "Epoch 763: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.02e+5]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.02e+5]\n",
            "Epoch 764: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.02e+5]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.02e+5]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.02e+5]\n",
            "Epoch 766: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.02e+5]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.02e+5]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.02e+5]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.02e+5]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.02e+5]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.02e+5]\n",
            "Epoch 770: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.02e+5]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.02e+5]\n",
            "Epoch 772: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.02e+5]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.02e+5]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 776: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.02e+5]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.02e+5]\n",
            "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.02e+5]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 780: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.02e+5]\n",
            "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.02e+5]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 782: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.02e+5]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 784: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.02e+5]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.02e+5]\n",
            "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 11.97it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.02e+5]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.02e+5]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.02e+5]\n",
            "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.02e+5]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.02e+5]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=3.02e+5]\n",
            "Epoch 789: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=3.02e+5]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.02e+5]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.02e+5]\n",
            "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.02e+5]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.02e+5]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.02e+5]\n",
            "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.02e+5]\n",
            "Epoch 794: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.02e+5]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 795: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.02e+5]\n",
            "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.02e+5]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 797: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.02e+5]\n",
            "Epoch 798: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.02e+5]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.02e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.02e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.150, valid_loss=3.02e+5]\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.69it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.08e+5]\n",
            "Epoch 802: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 805: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.08e+5]\n",
            "Epoch 807: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.08e+5]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 809: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.08e+5]\n",
            "Epoch 811: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.08e+5]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 814: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 815: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 817: 100%|██████████| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 818: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 819: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 819: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 820: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 821: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 822: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 11.97it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 826: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 828: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 829: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 830: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.08e+5]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 833: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.08e+5]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 836: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 837: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 838: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 838: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.08e+5]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.08e+5]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 840: 100%|██████████| 1/1 [00:00<00:00, 10.48it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 840: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 840: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 841: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 842: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 846: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 848: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 849: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 849: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 850: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.08e+5]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 851: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 851: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 852: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 856: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 858: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 860: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.08e+5]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 862: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 864: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 865: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 866: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.08e+5]\n",
            "Epoch 867: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.08e+5]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.08e+5]\n",
            "Epoch 871: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.08e+5]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 873: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.08e+5]\n",
            "Epoch 875: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.08e+5]\n",
            "Epoch 876: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.08e+5]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 880: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.08e+5]\n",
            "Epoch 882: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.08e+5]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 884: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 887: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 11.28it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 890: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 891: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 892: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 893: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 895: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.08e+5]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.08e+5]\n",
            "Epoch 897: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.08e+5]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.400, valid_loss=3.08e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.27it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.08e+5]\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.08e+5]\n",
            "Epoch 901: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 902: 100%|██████████| 1/1 [00:00<00:00, 12.09it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 902: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 903: 100%|██████████| 1/1 [00:00<00:00, 10.36it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 904: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 907: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.08e+5]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 912: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 913: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 913: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 914: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 915: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 916: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 918: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 920: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.08e+5]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 922: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 923: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 925: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 925: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 926: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 927: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 927: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.08e+5]\n",
            "Epoch 928: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.08e+5]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 929: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 930: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 931: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.08e+5]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 933: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 933: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 934: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.08e+5]\n",
            "Epoch 935: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.110, valid_loss=3.08e+5]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.08e+5]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 937: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 939: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.08e+5]\n",
            "Epoch 939: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 941: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.08e+5]\n",
            "Epoch 943: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.08e+5]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 945: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 947: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.08e+5]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 949: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.08e+5]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 951: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 952: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.08e+5]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 954: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 955: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 955: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.08e+5]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 957: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.08e+5]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 960: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.08e+5]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 961: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 963: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 964: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.08e+5]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 965: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 965: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 966: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.08e+5]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.08e+5]\n",
            "Epoch 968: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.08e+5]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.08e+5]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.08e+5]\n",
            "Epoch 970: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.08e+5]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.08e+5]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 972: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.08e+5]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.08e+5]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.08e+5]\n",
            "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.08e+5]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.08e+5]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 976: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.08e+5]\n",
            "Epoch 977: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.08e+5]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 978: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.08e+5]\n",
            "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 12.33it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.08e+5]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 980: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 980: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.08e+5]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.08e+5]\n",
            "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.08e+5]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 11.97it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.08e+5]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 984: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 985: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.08e+5]\n",
            "Epoch 986: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.08e+5]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 987: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.08e+5]\n",
            "Epoch 987: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 988: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.08e+5]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 989: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 990: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.08e+5]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.08e+5]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 992: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.08e+5]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.08e+5]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 994: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.08e+5]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.08e+5]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.08e+5]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.08e+5]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.08e+5]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.08e+5]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.08e+5]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.050, valid_loss=3.08e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.57it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:36:22,859\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=41631)\u001b[0m \r                                                                      \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.050, valid_loss=3.06e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.06e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.06e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=42454)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_a9ebfeb2_4_batch_size=32,early_stop_patience_steps=5,h=5,hidden_size=64,hist_exog_list=Close_Open_High_Low_Volume_Mark_2024-04-15_11-33-30/lightning_logs\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 2024-04-15 11:36:32.667460: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 2024-04-15 11:36:32.667514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 2024-04-15 11:36:32.668831: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 2024-04-15 11:36:33.891164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 4 | embedding               | TFTEmbedding             | 1.0 K \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 83.8 K\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 284 K \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 64.8 K\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 8 | output_adapter          | Linear                   | 65    \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 434 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 434 K     Total params\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m 1.738     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=42454)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.990]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.366]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.229]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203]\n",
            "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174]\n",
            "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.191]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.12it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.01e+5]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.01e+5]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=4.01e+5]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=4.01e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=4.01e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=4.01e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=4.01e+5]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=4.01e+5]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.01e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.01e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=4.01e+5]\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=4.01e+5]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=4.01e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=4.01e+5]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.01e+5]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.01e+5]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=4.01e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=4.01e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=4.01e+5]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=4.01e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.01e+5]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.01e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.01e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.01e+5]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=4.01e+5]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=4.01e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=4.01e+5]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=4.01e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.01e+5]\n",
            "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.01e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.01e+5]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.01e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.01e+5]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.01e+5]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=4.01e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=4.01e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.01e+5]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.01e+5]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.01e+5]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.01e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.01e+5]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.01e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.01e+5]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.01e+5]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.01e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.01e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.01e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.01e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=4.01e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=4.01e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.01e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.01e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.01e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.01e+5]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=4.01e+5]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=4.01e+5]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=4.01e+5]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=4.01e+5]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=4.01e+5]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=4.01e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=4.01e+5]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=4.01e+5]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.01e+5]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.01e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=4.01e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=4.01e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=4.01e+5]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=4.01e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=4.01e+5]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=4.01e+5]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=4.01e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=4.01e+5]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=4.01e+5]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=4.01e+5]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.01e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.01e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=4.01e+5]\n",
            "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=4.01e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=4.01e+5]\n",
            "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=4.01e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=4.01e+5]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=4.01e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=4.01e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=4.01e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=4.01e+5]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=4.01e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=4.01e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=4.01e+5]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=4.01e+5]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=4.01e+5]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.01e+5]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.01e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=4.01e+5]\n",
            "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=4.01e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.01e+5]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.01e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=4.01e+5]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=4.01e+5]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.01e+5]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.01e+5]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.01e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.01e+5]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.01e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.01e+5]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=4.01e+5]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=4.01e+5]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.01e+5]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.01e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=4.01e+5]\n",
            "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=4.01e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=4.01e+5]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=4.01e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.01e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.01e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=4.01e+5]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=4.01e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.01e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.01e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.01e+5]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.01e+5]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=4.01e+5]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=4.01e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=4.01e+5]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=4.01e+5]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.01e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=4.01e+5]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=4.01e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=4.01e+5]\n",
            "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=4.01e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=4.01e+5]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=4.01e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.01e+5]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.01e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=4.01e+5]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=4.01e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=4.01e+5]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=4.01e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=4.01e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=4.01e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=4.01e+5]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=4.01e+5]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=4.01e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=4.01e+5]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=4.01e+5]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=4.01e+5]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=4.01e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=4.01e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=4.01e+5]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=4.01e+5]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.01e+5]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.01e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=4.01e+5]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=4.01e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=4.01e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=4.01e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=4.01e+5]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=4.01e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=4.01e+5]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=4.01e+5]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=4.01e+5]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=4.01e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.01e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.01e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=4.01e+5]\n",
            "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=4.01e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=4.01e+5]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=4.01e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=4.01e+5]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=4.01e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=4.01e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=4.01e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.150, valid_loss=4.01e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=8.75e+5]\n",
            "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=8.75e+5]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=8.75e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=8.75e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=8.75e+5]\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=8.75e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=8.75e+5]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=8.75e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=8.75e+5]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=8.75e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=8.75e+5]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=8.75e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=8.75e+5]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=8.75e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=8.75e+5]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=8.75e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=8.75e+5]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=8.75e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=8.75e+5]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=8.75e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=8.75e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=8.75e+5]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=8.75e+5]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=8.75e+5]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=8.75e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=8.75e+5]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=8.75e+5]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=8.75e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=8.75e+5]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=8.75e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=8.75e+5]\n",
            "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=8.75e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=8.75e+5]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=8.75e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=8.75e+5]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=8.75e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=8.75e+5]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=8.75e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=8.75e+5]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=8.75e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=8.75e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=8.75e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=8.75e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=8.75e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=8.75e+5]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=8.75e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=8.75e+5]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=8.75e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=8.75e+5]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=8.75e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=8.75e+5]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=8.75e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=8.75e+5]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=8.75e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=8.75e+5]\n",
            "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=8.75e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=8.75e+5]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=8.75e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=8.75e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=8.75e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=8.75e+5]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=8.75e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=8.75e+5]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=8.75e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=8.75e+5]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=8.75e+5]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=8.75e+5]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=8.75e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=8.75e+5]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=8.75e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=8.75e+5]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=8.75e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=8.75e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=8.75e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=8.75e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=8.75e+5]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=8.75e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=8.75e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=8.75e+5]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=8.75e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=8.75e+5]\n",
            "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=8.75e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=8.75e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=8.75e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=8.75e+5]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=8.75e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=8.75e+5]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=8.75e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=8.75e+5]\n",
            "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=8.75e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=8.75e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=8.75e+5]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=8.75e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=8.75e+5]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=8.75e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.111, valid_loss=8.75e+5]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=8.75e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=8.75e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0993, train_loss_epoch=0.0993, valid_loss=8.75e+5]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0993, train_loss_epoch=0.0993, valid_loss=8.75e+5]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=8.75e+5] \n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=8.75e+5]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=8.75e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=8.75e+5]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=8.75e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=8.75e+5]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=8.75e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=8.75e+5]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=8.75e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=8.75e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=8.75e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0994, train_loss_epoch=0.0994, valid_loss=8.75e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=0, train_loss_step=0.0994, train_loss_epoch=0.0994, valid_loss=8.75e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=8.75e+5]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=8.75e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=8.75e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=8.75e+5]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=8.75e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0976, train_loss_epoch=0.0976, valid_loss=8.75e+5]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.0976, train_loss_epoch=0.0976, valid_loss=8.75e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0976, train_loss_epoch=0.0976, valid_loss=8.75e+5]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0976, train_loss_epoch=0.0976, valid_loss=8.75e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=8.75e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=8.75e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=8.75e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=8.75e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=8.75e+5]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=8.75e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=8.75e+5]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=8.75e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=8.75e+5]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=8.75e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0934, train_loss_epoch=0.0934, valid_loss=8.75e+5]\n",
            "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.0934, train_loss_epoch=0.0934, valid_loss=8.75e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0975, train_loss_epoch=0.0975, valid_loss=8.75e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0975, train_loss_epoch=0.0975, valid_loss=8.75e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=8.75e+5]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=8.75e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0903, train_loss_epoch=0.0903, valid_loss=8.75e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.0903, train_loss_epoch=0.0903, valid_loss=8.75e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0929, train_loss_epoch=0.0929, valid_loss=8.75e+5]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0929, train_loss_epoch=0.0929, valid_loss=8.75e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0904, train_loss_epoch=0.0904, valid_loss=8.75e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0904, train_loss_epoch=0.0904, valid_loss=8.75e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=8.75e+5]\n",
            "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=8.75e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0994, train_loss_epoch=0.0994, valid_loss=8.75e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.0994, train_loss_epoch=0.0994, valid_loss=8.75e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0843, valid_loss=8.75e+5]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0843, valid_loss=8.75e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=8.75e+5]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=8.75e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=8.75e+5]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=8.75e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=8.75e+5]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=8.75e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=8.75e+5]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=8.75e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=8.75e+5]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.0936, train_loss_epoch=0.0936, valid_loss=8.75e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0952, train_loss_epoch=0.0952, valid_loss=8.75e+5]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0952, train_loss_epoch=0.0952, valid_loss=8.75e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0881, train_loss_epoch=0.0881, valid_loss=8.75e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.0881, train_loss_epoch=0.0881, valid_loss=8.75e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=0, train_loss_step=0.0969, train_loss_epoch=0.0881, valid_loss=8.75e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0969, train_loss_epoch=0.0969, valid_loss=1.08e+6]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=0, train_loss_step=0.0969, train_loss_epoch=0.0969, valid_loss=1.08e+6]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0868, train_loss_epoch=0.0868, valid_loss=1.08e+6]\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0868, train_loss_epoch=0.0868, valid_loss=1.08e+6]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=1.08e+6]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=1.08e+6]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=1.08e+6]\n",
            "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=1.08e+6]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0841, train_loss_epoch=0.0841, valid_loss=1.08e+6]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.0841, train_loss_epoch=0.0841, valid_loss=1.08e+6]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=1.08e+6]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=1.08e+6]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0844, train_loss_epoch=0.0844, valid_loss=1.08e+6]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.0844, train_loss_epoch=0.0844, valid_loss=1.08e+6]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0969, train_loss_epoch=0.0969, valid_loss=1.08e+6]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.0969, train_loss_epoch=0.0969, valid_loss=1.08e+6]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0851, train_loss_epoch=0.0851, valid_loss=1.08e+6]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=0, train_loss_step=0.0851, train_loss_epoch=0.0851, valid_loss=1.08e+6]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0778, train_loss_epoch=0.0778, valid_loss=1.08e+6]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.0778, train_loss_epoch=0.0778, valid_loss=1.08e+6]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0844, train_loss_epoch=0.0844, valid_loss=1.08e+6]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.0844, train_loss_epoch=0.0844, valid_loss=1.08e+6]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=1.08e+6]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=1.08e+6]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0836, train_loss_epoch=0.0836, valid_loss=1.08e+6]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.0836, train_loss_epoch=0.0836, valid_loss=1.08e+6]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=1.08e+6]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=1.08e+6]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=1.08e+6]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=1.08e+6]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=1.08e+6]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=1.08e+6]\n",
            "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=1.08e+6]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=1.08e+6]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=1.08e+6]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=1.08e+6]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=1.08e+6]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=1.08e+6]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=1.08e+6]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=1.08e+6]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=1.08e+6]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.080, train_loss_epoch=0.080, valid_loss=1.08e+6]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.080, train_loss_epoch=0.080, valid_loss=1.08e+6]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=1.08e+6]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=1.08e+6]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=1.08e+6]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=1.08e+6]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=1.08e+6]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=1.08e+6]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0841, train_loss_epoch=0.0841, valid_loss=1.08e+6]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.0841, train_loss_epoch=0.0841, valid_loss=1.08e+6]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0717, train_loss_epoch=0.0717, valid_loss=1.08e+6]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.0717, train_loss_epoch=0.0717, valid_loss=1.08e+6]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=1.08e+6]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=1.08e+6]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=1.08e+6]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=1.08e+6]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=1.08e+6]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=1.08e+6]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=1.08e+6]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=1.08e+6]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=1.08e+6]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=1.08e+6]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=1.08e+6]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=1.08e+6]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0686, train_loss_epoch=0.0686, valid_loss=1.08e+6]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.0686, train_loss_epoch=0.0686, valid_loss=1.08e+6]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=1.08e+6]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=1.08e+6]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0724, train_loss_epoch=0.0724, valid_loss=1.08e+6]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0724, train_loss_epoch=0.0724, valid_loss=1.08e+6]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=1.08e+6]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=1.08e+6]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=1.08e+6]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=1.08e+6]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0694, train_loss_epoch=0.0694, valid_loss=1.08e+6]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0694, train_loss_epoch=0.0694, valid_loss=1.08e+6]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=1.08e+6]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=1.08e+6]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=1.08e+6]\n",
            "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=1.08e+6]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=1.08e+6]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=1.08e+6]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=1.08e+6]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=1.08e+6]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=1.08e+6]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=1.08e+6]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=1.08e+6]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=1.08e+6]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=1.08e+6]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=1.08e+6]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=1.08e+6]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=1.08e+6]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0716, train_loss_epoch=0.0716, valid_loss=1.08e+6]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.0716, train_loss_epoch=0.0716, valid_loss=1.08e+6]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0862, train_loss_epoch=0.0862, valid_loss=1.08e+6]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.0862, train_loss_epoch=0.0862, valid_loss=1.08e+6]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0842, train_loss_epoch=0.0842, valid_loss=1.08e+6]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.0842, train_loss_epoch=0.0842, valid_loss=1.08e+6]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0759, train_loss_epoch=0.0759, valid_loss=1.08e+6]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.0759, train_loss_epoch=0.0759, valid_loss=1.08e+6]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=1.08e+6]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=1.08e+6]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=1.08e+6]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=1.08e+6]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=1.08e+6]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=1.08e+6]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=1.08e+6]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=1.08e+6]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0725, train_loss_epoch=0.0725, valid_loss=1.08e+6]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0725, train_loss_epoch=0.0725, valid_loss=1.08e+6]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=1.08e+6]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=1.08e+6]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=1.08e+6]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=1.08e+6]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=1.08e+6]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=1.08e+6]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0742, valid_loss=1.08e+6]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0742, valid_loss=1.08e+6]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=1.08e+6]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=1.08e+6]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=1.08e+6]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=1.08e+6]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=1.08e+6]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=1.08e+6]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=1.08e+6]\n",
            "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=1.08e+6]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=1.08e+6]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=1.08e+6]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0802, train_loss_epoch=0.0802, valid_loss=1.08e+6]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0802, train_loss_epoch=0.0802, valid_loss=1.08e+6]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=1.08e+6]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=1.08e+6]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=1.08e+6]\n",
            "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=1.08e+6]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=1.08e+6]\n",
            "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=1.08e+6]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=1.08e+6]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=1.08e+6]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=1.08e+6]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=1.08e+6]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=1.08e+6]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=1.08e+6]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=1.08e+6]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=1.08e+6]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=1.08e+6]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=1.08e+6]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=1.08e+6]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=1.08e+6]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=1.08e+6]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=1.08e+6]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=1.08e+6]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=1.08e+6]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=1.08e+6]\n",
            "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=1.08e+6]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=1.08e+6]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=1.08e+6]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=1.08e+6]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=1.08e+6]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0559, train_loss_epoch=0.0559, valid_loss=1.08e+6]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.0559, train_loss_epoch=0.0559, valid_loss=1.08e+6]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=1.08e+6]\n",
            "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=1.08e+6]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=1.08e+6]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=1.08e+6]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=1.08e+6]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=1.08e+6]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=1.08e+6]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=1.08e+6]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=1.08e+6]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=1.08e+6]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=1.08e+6]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=1.08e+6]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=1.08e+6]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=1.08e+6]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=1.08e+6]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=1.08e+6]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=1.08e+6]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=1.08e+6]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0595, valid_loss=1.08e+6]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=1.08e+6]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=1.08e+6]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0557, train_loss_epoch=0.0557, valid_loss=1.08e+6]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=0, train_loss_step=0.0557, train_loss_epoch=0.0557, valid_loss=1.08e+6]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=1.08e+6]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=1.08e+6]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=1.08e+6]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=1.08e+6]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=1.08e+6]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=1.08e+6]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=1.08e+6]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=1.08e+6]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=1.08e+6]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=1.08e+6]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=1.08e+6]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=1.08e+6]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=1.08e+6]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=1.08e+6]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=1.08e+6]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=1.08e+6]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=1.08e+6]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=1.08e+6]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0532, valid_loss=1.08e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=9.91e+5]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=9.91e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=9.91e+5]\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=9.91e+5]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=9.91e+5]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=9.91e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=9.91e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=9.91e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=9.91e+5]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=9.91e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=9.91e+5]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=9.91e+5]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=9.91e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=9.91e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=9.91e+5]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=9.91e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=9.91e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=9.91e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=9.91e+5]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=9.91e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=9.91e+5]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=9.91e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=9.91e+5]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=9.91e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=9.91e+5]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=9.91e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=9.91e+5]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=9.91e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=9.91e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=9.91e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=9.91e+5]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=9.91e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=9.91e+5]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=9.91e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=9.91e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=9.91e+5]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=9.91e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=9.91e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=9.91e+5]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=9.91e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=9.91e+5]\n",
            "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=9.91e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=9.91e+5]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=9.91e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=9.91e+5]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=9.91e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=9.91e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=9.91e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=9.91e+5]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=9.91e+5]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=9.91e+5]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=9.91e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=9.91e+5]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=9.91e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=9.91e+5]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=9.91e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=9.91e+5]\n",
            "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=9.91e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=9.91e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=9.91e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=9.91e+5]\n",
            "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=9.91e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=9.91e+5]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=9.91e+5]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=9.91e+5]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=9.91e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=9.91e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=9.91e+5]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=9.91e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=9.91e+5]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=9.91e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=9.91e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=9.91e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=9.91e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=9.91e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=9.91e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=9.91e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=9.91e+5]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=9.91e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=9.91e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=9.91e+5]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=9.91e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=9.91e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=9.91e+5]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=9.91e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=9.91e+5]\n",
            "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=9.91e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=9.91e+5]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=9.91e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=9.91e+5]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=9.91e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=9.91e+5]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=9.91e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=9.91e+5]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=9.91e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=9.91e+5]\n",
            "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=9.91e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=9.91e+5]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=9.91e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=9.91e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=9.91e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0543, train_loss_epoch=0.0543, valid_loss=9.91e+5]\n",
            "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0543, train_loss_epoch=0.0543, valid_loss=9.91e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=9.91e+5]\n",
            "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=9.91e+5]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=9.91e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=9.91e+5]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=9.91e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=9.91e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=9.91e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=9.91e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=9.91e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=9.91e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=9.91e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=9.91e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=9.91e+5]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=9.91e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=9.91e+5]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=9.91e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=9.91e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=9.91e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=9.91e+5]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=9.91e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=9.91e+5]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=9.91e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=9.91e+5]\n",
            "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=9.91e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0437, train_loss_epoch=0.0437, valid_loss=9.91e+5]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.0437, train_loss_epoch=0.0437, valid_loss=9.91e+5]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=9.91e+5]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=9.91e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=9.91e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=9.91e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476, valid_loss=9.91e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476, valid_loss=9.91e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476, valid_loss=9.91e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=9.91e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=9.91e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=9.91e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=9.91e+5]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=9.91e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=9.91e+5]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=9.91e+5]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=9.91e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.91e+5]\n",
            "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.91e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=9.91e+5]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=9.91e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=9.91e+5]\n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=9.91e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=9.91e+5]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=9.91e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=9.91e+5]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=9.91e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=9.91e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=9.91e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=9.91e+5]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=9.91e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.91e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.91e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419, valid_loss=9.91e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419, valid_loss=9.91e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0419, valid_loss=9.91e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426, valid_loss=9.91e+5]        \n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426, valid_loss=9.91e+5]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426, valid_loss=9.91e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=9.91e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=9.91e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=9.91e+5]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=9.91e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0434, train_loss_epoch=0.0434, valid_loss=9.91e+5]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0434, train_loss_epoch=0.0434, valid_loss=9.91e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402, valid_loss=9.91e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402, valid_loss=9.91e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456, valid_loss=9.91e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456, valid_loss=9.91e+5]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=9.91e+5]\n",
            "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=9.91e+5]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=9.91e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=9.91e+5]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=9.91e+5]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=9.91e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=9.91e+5]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=9.91e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=9.91e+5]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=9.91e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=9.91e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=9.91e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=9.91e+5]\n",
            "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=9.91e+5]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=9.91e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=9.91e+5]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=9.91e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419, valid_loss=9.91e+5]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419, valid_loss=9.91e+5]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=9.91e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=9.91e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.043, valid_loss=9.91e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=1.11e+6]\n",
            "Epoch 500: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=1.11e+6]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=1.11e+6]\n",
            "Epoch 501: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=1.11e+6]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0437, train_loss_epoch=0.0437, valid_loss=1.11e+6]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.0437, train_loss_epoch=0.0437, valid_loss=1.11e+6]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=1.11e+6]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=1.11e+6]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=1.11e+6]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=1.11e+6]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=1.11e+6]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=1.11e+6]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=1.11e+6]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=1.11e+6]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=1.11e+6]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=1.11e+6]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=1.11e+6]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=1.11e+6]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=1.11e+6]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=1.11e+6]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=1.11e+6]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=1.11e+6]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=1.11e+6]\n",
            "Epoch 511: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=1.11e+6]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=1.11e+6]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=1.11e+6]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=1.11e+6]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=1.11e+6]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432, valid_loss=1.11e+6]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432, valid_loss=1.11e+6]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=1.11e+6]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=1.11e+6]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=1.11e+6]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=1.11e+6]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=1.11e+6]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=1.11e+6]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=1.11e+6]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=1.11e+6]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=1.11e+6]\n",
            "Epoch 519: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=1.11e+6]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=1.11e+6]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=1.11e+6]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=1.11e+6]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=1.11e+6]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=1.11e+6]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=1.11e+6]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=1.11e+6]\n",
            "Epoch 523: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=1.11e+6]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=1.11e+6]\n",
            "Epoch 524: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=1.11e+6]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=1.11e+6]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=1.11e+6]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=1.11e+6]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=1.11e+6]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=1.11e+6]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=1.11e+6]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=1.11e+6]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=1.11e+6]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=1.11e+6]\n",
            "Epoch 529: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=1.11e+6]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=1.11e+6]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=1.11e+6]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=1.11e+6]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=1.11e+6]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=1.11e+6]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=1.11e+6]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=1.11e+6]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=1.11e+6]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=1.11e+6]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=1.11e+6]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=1.11e+6]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=1.11e+6]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=1.11e+6]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=1.11e+6]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=1.11e+6]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=1.11e+6]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=1.11e+6]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=1.11e+6]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=1.11e+6]\n",
            "Epoch 539: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=1.11e+6]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=1.11e+6]\n",
            "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=1.11e+6]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=1.11e+6]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=1.11e+6]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=1.11e+6]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=1.11e+6]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=1.11e+6]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=1.11e+6]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=1.11e+6]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=1.11e+6]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=1.11e+6]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=1.11e+6]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=1.11e+6]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=1.11e+6]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=1.11e+6]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=1.11e+6]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=1.11e+6]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=1.11e+6]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=1.11e+6]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=1.11e+6]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=1.11e+6]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=1.11e+6]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=1.11e+6]\n",
            "Epoch 551: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=1.11e+6]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=1.11e+6]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=1.11e+6]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=1.11e+6]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=1.11e+6]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=1.11e+6]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=1.11e+6]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=1.11e+6]\n",
            "Epoch 555: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=1.11e+6]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=1.11e+6]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=1.11e+6]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=1.11e+6]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=1.11e+6]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=1.11e+6]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=1.11e+6]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.034, valid_loss=1.11e+6]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=1.11e+6]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=1.11e+6]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=1.11e+6]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=1.11e+6]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=1.11e+6]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=1.11e+6]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.11e+6]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.11e+6]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=1.11e+6]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=1.11e+6]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=1.11e+6]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=1.11e+6]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=1.11e+6]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=1.11e+6]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=1.11e+6]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=1.11e+6]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.11e+6]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=1.11e+6]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=1.11e+6]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=1.11e+6]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=1.11e+6]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=1.11e+6]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=1.11e+6]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=1.11e+6]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=1.11e+6]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=1.11e+6]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=1.11e+6]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=1.11e+6]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=1.11e+6]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=1.11e+6]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=1.11e+6]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=1.11e+6]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=1.11e+6]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=1.11e+6]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=1.11e+6]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=1.11e+6]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=1.11e+6]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=1.11e+6]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=1.11e+6]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=1.11e+6]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 584: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=1.11e+6]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=1.11e+6]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=1.11e+6]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=1.11e+6]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.11e+6]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=1.11e+6]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=1.11e+6]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=1.11e+6]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=1.11e+6]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=1.11e+6]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=1.11e+6]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=1.11e+6]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.11e+6]\n",
            "Epoch 591: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=1.11e+6]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=1.11e+6]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=1.11e+6]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=1.11e+6]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=1.11e+6]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=1.11e+6]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=1.11e+6]\n",
            "Epoch 595: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=1.11e+6]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=1.11e+6]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=1.11e+6]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=1.11e+6]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=1.11e+6]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=1.11e+6]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=1.11e+6]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=1.11e+6]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:40:28,803\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0302, valid_loss=1.11e+6]\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=42454)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0302, valid_loss=9.94e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=9.94e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=9.94e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=43566)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_f09e612b_5_batch_size=16,early_stop_patience_steps=5,h=5,hidden_size=128,hist_exog_list=Close_Open_High_Low_Volume_Mar_2024-04-15_11-36-31/lightning_logs\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 2024-04-15 11:40:38.679691: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 2024-04-15 11:40:38.679750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 2024-04-15 11:40:38.681105: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 2024-04-15 11:40:39.918399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 4 | embedding               | TFTEmbedding             | 2.0 K \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 331 K \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 1.1 M \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 256 K \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 8 | output_adapter          | Linear                   | 129   \n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 1.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 1.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m 6.834     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=43566)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.422]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381]\n",
            "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.351]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306]\n",
            "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304]\n",
            "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289]\n",
            "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.273]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.45e+5]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.45e+5]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.45e+5]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.45e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.45e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.45e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.45e+5]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.45e+5]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.45e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.45e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.45e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.45e+5]\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.45e+5]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.45e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.45e+5]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.45e+5]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.45e+5]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.45e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.45e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.45e+5]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.45e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.45e+5]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.45e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.45e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.45e+5]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.45e+5]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.45e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.45e+5]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.45e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=3.45e+5]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=3.45e+5]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.45e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.45e+5]\n",
            "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.45e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.45e+5]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.45e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.45e+5]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.45e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.45e+5]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.45e+5]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.45e+5]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.45e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.45e+5]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.45e+5]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.45e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.45e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.45e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.45e+5]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.45e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.45e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.45e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.45e+5]\n",
            "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.45e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.45e+5]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.45e+5]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.45e+5]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.45e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.45e+5]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.45e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=3.45e+5]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=3.45e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.45e+5]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.45e+5]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=3.45e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=3.45e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=3.45e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=3.45e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=3.45e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=3.45e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.45e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.45e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.45e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.45e+5]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.45e+5]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.45e+5]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.45e+5]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.45e+5]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.45e+5]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.45e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=3.45e+5]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=3.45e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.45e+5]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.45e+5]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.45e+5]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.45e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.45e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.45e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.45e+5]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.45e+5]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=3.45e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=3.45e+5]\n",
            "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=3.45e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.45e+5]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.45e+5]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.45e+5]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.45e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.45e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.45e+5]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.45e+5]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.45e+5]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.45e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.45e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.45e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.45e+5]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.45e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.45e+5]\n",
            "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.45e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=3.45e+5]\n",
            "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=3.45e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.45e+5]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.45e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.45e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.45e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.45e+5]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.45e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.45e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.45e+5]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.45e+5]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.45e+5]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.45e+5]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.45e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.45e+5]\n",
            "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.45e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=3.45e+5]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=3.45e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.45e+5]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.45e+5]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.45e+5]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.45e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.45e+5]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.45e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.45e+5]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.45e+5]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.45e+5]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.45e+5]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.45e+5]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.45e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.45e+5]\n",
            "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.45e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.45e+5]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.45e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.45e+5]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.45e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.45e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.45e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.45e+5]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.45e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.45e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.45e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.45e+5]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.45e+5]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.45e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.45e+5]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.45e+5]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.45e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.45e+5]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.45e+5]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.45e+5]\n",
            "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.45e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.45e+5]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.45e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.45e+5]\n",
            "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.45e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.45e+5]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.45e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.45e+5]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.45e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.45e+5]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.45e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.45e+5]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.45e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.45e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.45e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.45e+5]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.45e+5]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.45e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.45e+5]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.45e+5]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.45e+5]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.45e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.45e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.45e+5]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.45e+5]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.45e+5]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.45e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.45e+5]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.45e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.45e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.45e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.45e+5]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.45e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.45e+5]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.45e+5]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.45e+5]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.45e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.45e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.45e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.165, valid_loss=3.45e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=3.45e+5]\n",
            "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=3.45e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.45e+5]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.45e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.45e+5]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.45e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.45e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.45e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.165, valid_loss=3.45e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=6.45e+5]\n",
            "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=6.45e+5]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=6.45e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=6.45e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=6.45e+5]\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=6.45e+5]\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=6.45e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=6.45e+5]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=6.45e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=6.45e+5]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=6.45e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=6.45e+5]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=6.45e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=6.45e+5]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=6.45e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=6.45e+5]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=6.45e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=6.45e+5]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=6.45e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=6.45e+5]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=6.45e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=6.45e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=6.45e+5]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=6.45e+5]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=6.45e+5]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=6.45e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=6.45e+5]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=6.45e+5]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=6.45e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=6.45e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=6.45e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=6.45e+5]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=6.45e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=6.45e+5]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=6.45e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=6.45e+5]\n",
            "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=6.45e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=6.45e+5]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=6.45e+5]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=6.45e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=6.45e+5]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=6.45e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=6.45e+5]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=6.45e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=6.45e+5]\n",
            "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=6.45e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=6.45e+5]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=6.45e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=6.45e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=6.45e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=6.45e+5]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=6.45e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=6.45e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=6.45e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.153, valid_loss=6.45e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=6.45e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=6.45e+5]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=6.45e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=6.45e+5]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=6.45e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=6.45e+5]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=6.45e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=6.45e+5]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=6.45e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=6.45e+5]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=6.45e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=6.45e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=6.45e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=6.45e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=6.45e+5]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=6.45e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=6.45e+5]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=6.45e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=6.45e+5]\n",
            "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=6.45e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=6.45e+5]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=6.45e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=6.45e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=6.45e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=6.45e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=6.45e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.123, valid_loss=6.45e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=6.45e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=6.45e+5]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=6.45e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=6.45e+5]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=6.45e+5]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=6.45e+5]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=6.45e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=6.45e+5]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=6.45e+5]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=6.45e+5]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=6.45e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=6.45e+5]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=6.45e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=6.45e+5]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=6.45e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=6.45e+5]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=6.45e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=6.45e+5]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=6.45e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=6.45e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=6.45e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=6.45e+5]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=6.45e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=6.45e+5]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=6.45e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=6.45e+5]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=6.45e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=6.45e+5]\n",
            "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=6.45e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=6.45e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=6.45e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=6.45e+5]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=6.45e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=6.45e+5]\n",
            "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=6.45e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=6.45e+5]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=6.45e+5]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.117, valid_loss=6.45e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=6.45e+5]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=6.45e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=6.45e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=6.45e+5]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=6.45e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=6.45e+5]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=6.45e+5]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=6.45e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=6.45e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0993, train_loss_epoch=0.0993, valid_loss=6.45e+5]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0993, train_loss_epoch=0.0993, valid_loss=6.45e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=6.45e+5]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=6.45e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0999, train_loss_epoch=0.0999, valid_loss=6.45e+5]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0999, train_loss_epoch=0.0999, valid_loss=6.45e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=6.45e+5]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=6.45e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=6.45e+5]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=6.45e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0968, train_loss_epoch=0.0968, valid_loss=6.45e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.0968, train_loss_epoch=0.0968, valid_loss=6.45e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.0968, valid_loss=6.45e+5] \n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=6.45e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=6.45e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=6.45e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=6.45e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=6.45e+5]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=6.45e+5]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=6.45e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=6.45e+5]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=6.45e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=6.45e+5]\n",
            "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=6.45e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=6.45e+5]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=6.45e+5]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.0912, train_loss_epoch=0.0912, valid_loss=6.45e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0912, train_loss_epoch=0.0912, valid_loss=6.45e+5]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0912, train_loss_epoch=0.0912, valid_loss=6.45e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=6.45e+5]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=6.45e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=6.45e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=6.45e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=6.45e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=6.45e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0967, train_loss_epoch=0.0967, valid_loss=6.45e+5]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0967, train_loss_epoch=0.0967, valid_loss=6.45e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=6.45e+5]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=6.45e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=6.45e+5]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=6.45e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=6.45e+5]\n",
            "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=6.45e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=6.45e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=6.45e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0975, train_loss_epoch=0.0975, valid_loss=6.45e+5]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0975, train_loss_epoch=0.0975, valid_loss=6.45e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0917, train_loss_epoch=0.0917, valid_loss=6.45e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0917, train_loss_epoch=0.0917, valid_loss=6.45e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=6.45e+5]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=6.45e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0862, train_loss_epoch=0.0862, valid_loss=6.45e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.0862, train_loss_epoch=0.0862, valid_loss=6.45e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=6.45e+5]\n",
            "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=6.45e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=6.45e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=6.45e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=6.45e+5]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=6.45e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0881, train_loss_epoch=0.0881, valid_loss=6.45e+5]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0881, train_loss_epoch=0.0881, valid_loss=6.45e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=6.45e+5]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=6.45e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=6.45e+5]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=6.45e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=6.45e+5]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=6.45e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=6.45e+5]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=6.45e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0843, valid_loss=6.45e+5]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0843, valid_loss=6.45e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0848, train_loss_epoch=0.0848, valid_loss=6.45e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.0848, train_loss_epoch=0.0848, valid_loss=6.45e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0848, valid_loss=6.45e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=7.29e+5]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=7.29e+5]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=7.29e+5]\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=7.29e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0809, train_loss_epoch=0.0809, valid_loss=7.29e+5]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.0809, train_loss_epoch=0.0809, valid_loss=7.29e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0765, train_loss_epoch=0.0765, valid_loss=7.29e+5]\n",
            "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.0765, train_loss_epoch=0.0765, valid_loss=7.29e+5]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=7.29e+5]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=7.29e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=7.29e+5]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=7.29e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=7.29e+5]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=7.29e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0813, train_loss_epoch=0.0813, valid_loss=7.29e+5]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.0813, train_loss_epoch=0.0813, valid_loss=7.29e+5]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=7.29e+5]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=7.29e+5]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=7.29e+5]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=7.29e+5]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=7.29e+5]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=7.29e+5]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0785, train_loss_epoch=0.0785, valid_loss=7.29e+5]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0785, train_loss_epoch=0.0785, valid_loss=7.29e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=7.29e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=7.29e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=7.29e+5]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=7.29e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=7.29e+5]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=7.29e+5]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726, valid_loss=7.29e+5]\n",
            "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726, valid_loss=7.29e+5]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=7.29e+5]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.0818, train_loss_epoch=0.0818, valid_loss=7.29e+5]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=7.29e+5]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=7.29e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=7.29e+5]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=7.29e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0765, train_loss_epoch=0.0765, valid_loss=7.29e+5]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0765, train_loss_epoch=0.0765, valid_loss=7.29e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.072, train_loss_epoch=0.072, valid_loss=7.29e+5]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.072, train_loss_epoch=0.072, valid_loss=7.29e+5]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=7.29e+5]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=7.29e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=7.29e+5]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=7.29e+5]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=7.29e+5]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=7.29e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=7.29e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=7.29e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=7.29e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=7.29e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=7.29e+5]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=7.29e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=7.29e+5]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=7.29e+5]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=7.29e+5]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=7.29e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=7.29e+5]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=7.29e+5]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=7.29e+5]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=7.29e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=7.29e+5]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=7.29e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=7.29e+5]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=7.29e+5]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=7.29e+5]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=7.29e+5]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=7.29e+5]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=7.29e+5]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=7.29e+5]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=7.29e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=7.29e+5]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=7.29e+5]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=7.29e+5]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=7.29e+5]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=7.29e+5]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=7.29e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=7.29e+5]\n",
            "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=7.29e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=7.29e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=0, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=7.29e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=7.29e+5]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=7.29e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=7.29e+5]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=7.29e+5]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=7.29e+5]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=7.29e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679, valid_loss=7.29e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679, valid_loss=7.29e+5]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=7.29e+5]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=7.29e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=7.29e+5]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=7.29e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=7.29e+5]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=7.29e+5]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=7.29e+5]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=7.29e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=7.29e+5]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=7.29e+5]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=7.29e+5]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=7.29e+5]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=7.29e+5]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=7.29e+5]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=7.29e+5]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=7.29e+5]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=7.29e+5]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=7.29e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=7.29e+5]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=7.29e+5]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=7.29e+5]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=7.29e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=7.29e+5]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=7.29e+5]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=7.29e+5]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.061, train_loss_epoch=0.061, valid_loss=7.29e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=7.29e+5]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606, valid_loss=7.29e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=7.29e+5]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=7.29e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=7.29e+5]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596, valid_loss=7.29e+5]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=7.29e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=7.29e+5]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=7.29e+5]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=7.29e+5]\n",
            "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=7.29e+5]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=7.29e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=7.29e+5]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0584, train_loss_epoch=0.0584, valid_loss=7.29e+5]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0584, train_loss_epoch=0.0584, valid_loss=7.29e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0591, train_loss_epoch=0.0591, valid_loss=7.29e+5]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0591, train_loss_epoch=0.0591, valid_loss=7.29e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=7.29e+5]\n",
            "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=7.29e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=7.29e+5]\n",
            "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=7.29e+5]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=7.29e+5]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=7.29e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=7.29e+5]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=7.29e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0591, train_loss_epoch=0.0591, valid_loss=7.29e+5]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.0591, train_loss_epoch=0.0591, valid_loss=7.29e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=7.29e+5]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=7.29e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=7.29e+5]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=7.29e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=7.29e+5]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=7.29e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=7.29e+5]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=0, train_loss_step=0.0615, train_loss_epoch=0.0615, valid_loss=7.29e+5]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=7.29e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=7.29e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=7.29e+5]\n",
            "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=7.29e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=7.29e+5]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=7.29e+5]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=7.29e+5]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=7.29e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=7.29e+5]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=7.29e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=7.29e+5]\n",
            "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=7.29e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=7.29e+5]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=7.29e+5]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=7.29e+5]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=7.29e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=7.29e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=7.29e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=7.29e+5]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=7.29e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=7.29e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=7.29e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=7.29e+5]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=7.29e+5]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.0586, train_loss_epoch=0.0586, valid_loss=7.29e+5]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=7.29e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=7.29e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0555, train_loss_epoch=0.0555, valid_loss=7.29e+5]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0555, train_loss_epoch=0.0555, valid_loss=7.29e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=7.29e+5]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=7.29e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=7.29e+5]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=7.29e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=7.29e+5]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=7.29e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=7.29e+5]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594, valid_loss=7.29e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=7.29e+5]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=7.29e+5]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=7.29e+5]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=7.29e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=7.29e+5]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058, valid_loss=7.29e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=7.29e+5]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=7.29e+5]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0558, train_loss_epoch=0.0558, valid_loss=7.29e+5]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.0558, train_loss_epoch=0.0558, valid_loss=7.29e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=7.29e+5]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=7.29e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=7.29e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=7.29e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0551, valid_loss=7.29e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=8.27e+5]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=8.27e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0557, train_loss_epoch=0.0557, valid_loss=8.27e+5]\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.0557, train_loss_epoch=0.0557, valid_loss=8.27e+5]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=8.27e+5]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=8.27e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=8.27e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.0576, train_loss_epoch=0.0576, valid_loss=8.27e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=8.27e+5]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=8.27e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=8.27e+5]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=8.27e+5]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=8.27e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=8.27e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=8.27e+5]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=8.27e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=8.27e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=8.27e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=8.27e+5]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=8.27e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=8.27e+5]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=8.27e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=8.27e+5]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=8.27e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0523, train_loss_epoch=0.0523, valid_loss=8.27e+5]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0523, train_loss_epoch=0.0523, valid_loss=8.27e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=8.27e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482, valid_loss=8.27e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=8.27e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=8.27e+5]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=8.27e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=8.27e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=8.27e+5]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=8.27e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=8.27e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=8.27e+5]\n",
            "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=8.27e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=8.27e+5]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=8.27e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=8.27e+5]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=8.27e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=8.27e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=8.27e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=8.27e+5]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.0585, train_loss_epoch=0.0585, valid_loss=8.27e+5]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0534, train_loss_epoch=0.0534, valid_loss=8.27e+5]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.0534, train_loss_epoch=0.0534, valid_loss=8.27e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529, valid_loss=8.27e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=8.27e+5]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=8.27e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=8.27e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=8.27e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=8.27e+5]\n",
            "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=8.27e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=8.27e+5]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=8.27e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=8.27e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551, valid_loss=8.27e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=8.27e+5]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=8.27e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=8.27e+5]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=8.27e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=8.27e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=8.27e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=8.27e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=8.27e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=8.27e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=8.27e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=8.27e+5]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=8.27e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=8.27e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=8.27e+5]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0493, train_loss_epoch=0.0493, valid_loss=8.27e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0493, train_loss_epoch=0.0493, valid_loss=8.27e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=8.27e+5]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=8.27e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=8.27e+5]\n",
            "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=8.27e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0556, train_loss_epoch=0.0556, valid_loss=8.27e+5]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0556, train_loss_epoch=0.0556, valid_loss=8.27e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=8.27e+5]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=8.27e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=8.27e+5]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=8.27e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048, valid_loss=8.27e+5]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048, valid_loss=8.27e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=8.27e+5]\n",
            "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=8.27e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=8.27e+5]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=8.27e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=8.27e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=8.27e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=8.27e+5]\n",
            "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=8.27e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=8.27e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=8.27e+5]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=8.27e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=8.27e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=8.27e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=8.27e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=8.27e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496, valid_loss=8.27e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=8.27e+5]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479, valid_loss=8.27e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=8.27e+5]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=8.27e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=8.27e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=8.27e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=8.27e+5]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=8.27e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=8.27e+5]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=8.27e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=8.27e+5]\n",
            "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=8.27e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=8.27e+5]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=8.27e+5]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=8.27e+5]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=8.27e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=8.27e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=8.27e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=8.27e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=8.27e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=8.27e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=8.27e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478, valid_loss=8.27e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478, valid_loss=8.27e+5]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=8.27e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=8.27e+5]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=8.27e+5]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=8.27e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=8.27e+5]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=8.27e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=8.27e+5]\n",
            "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=8.27e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494, valid_loss=8.27e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455, valid_loss=8.27e+5]\n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455, valid_loss=8.27e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=8.27e+5]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=8.27e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=8.27e+5]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=8.27e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=8.27e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055, valid_loss=8.27e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=8.27e+5]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=8.27e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=8.27e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=8.27e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=8.27e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=8.27e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=8.27e+5]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=8.27e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=8.27e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=8.27e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=8.27e+5]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501, valid_loss=8.27e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=8.27e+5]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=8.27e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=8.27e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047, valid_loss=8.27e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=8.27e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=8.27e+5]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=8.27e+5]\n",
            "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=8.27e+5]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=8.27e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0448, train_loss_epoch=0.0448, valid_loss=8.27e+5]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=8.27e+5]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=8.27e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=8.27e+5]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=8.27e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=8.27e+5]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=8.27e+5]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0447, valid_loss=8.27e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=8.27e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=8.27e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=8.27e+5]\n",
            "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=8.27e+5]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=8.27e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=8.27e+5]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=8.27e+5]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=8.27e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=8.27e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0457, valid_loss=8.27e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.01e+5]\n",
            "Epoch 500: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.01e+5]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=9.01e+5]\n",
            "Epoch 501: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=9.01e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=9.01e+5]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=9.01e+5]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=9.01e+5]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=9.01e+5]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0427, train_loss_epoch=0.0427, valid_loss=9.01e+5]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.0427, train_loss_epoch=0.0427, valid_loss=9.01e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=9.01e+5]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=9.01e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=9.01e+5]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=9.01e+5]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=9.01e+5]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=9.01e+5]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0464, valid_loss=9.01e+5]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=9.01e+5]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=9.01e+5]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.01e+5]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.01e+5]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=9.01e+5]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=9.01e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=9.01e+5]\n",
            "Epoch 511: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=9.01e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=9.01e+5]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=9.01e+5]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=9.01e+5]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=9.01e+5]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.01e+5]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.01e+5]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=9.01e+5]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=9.01e+5]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=9.01e+5]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=9.01e+5]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=9.01e+5]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=9.01e+5]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=9.01e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 519: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0425, train_loss_epoch=0.0425, valid_loss=9.01e+5]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.0425, train_loss_epoch=0.0425, valid_loss=9.01e+5]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446, valid_loss=9.01e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446, valid_loss=9.01e+5]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446, valid_loss=9.01e+5]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=9.01e+5]\n",
            "Epoch 523: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=9.01e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=9.01e+5]\n",
            "Epoch 524: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=9.01e+5]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=9.01e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=9.01e+5]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=9.01e+5]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=9.01e+5]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=9.01e+5]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=9.01e+5]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=9.01e+5]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408, valid_loss=9.01e+5]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=9.01e+5]\n",
            "Epoch 529: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=9.01e+5]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=9.01e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=9.01e+5]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=9.01e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=9.01e+5]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=9.01e+5]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=9.01e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=9.01e+5]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=9.01e+5]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=9.01e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=9.01e+5]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=9.01e+5]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=9.01e+5]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=9.01e+5]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=9.01e+5]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=9.01e+5]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=9.01e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=9.01e+5]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=9.01e+5]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=9.01e+5]\n",
            "Epoch 539: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=9.01e+5]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=9.01e+5]\n",
            "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=9.01e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=9.01e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=9.01e+5]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432, valid_loss=9.01e+5]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432, valid_loss=9.01e+5]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=9.01e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=9.01e+5]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=9.01e+5]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=9.01e+5]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=9.01e+5]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=9.01e+5]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=9.01e+5]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=9.01e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=9.01e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=9.01e+5]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=9.01e+5]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.01e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.01e+5]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=9.01e+5]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=9.01e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=9.01e+5]\n",
            "Epoch 551: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=9.01e+5]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=9.01e+5]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=9.01e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=9.01e+5]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=9.01e+5]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=9.01e+5]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=9.01e+5]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=9.01e+5]\n",
            "Epoch 555: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=9.01e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=9.01e+5]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=9.01e+5]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=9.01e+5]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=9.01e+5]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=9.01e+5]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=9.01e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=9.01e+5]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=9.01e+5]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=9.01e+5]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=9.01e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=9.01e+5]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=9.01e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=9.01e+5]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=9.01e+5]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=9.01e+5]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=9.01e+5]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=9.01e+5]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=9.01e+5]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=9.01e+5]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=9.01e+5]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=9.01e+5]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=9.01e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=9.01e+5]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=9.01e+5]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=9.01e+5]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=9.01e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=9.01e+5]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=9.01e+5]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402, valid_loss=9.01e+5]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402, valid_loss=9.01e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=9.01e+5]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=9.01e+5]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=9.01e+5]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=9.01e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=9.01e+5]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=9.01e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=9.01e+5]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=9.01e+5]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=9.01e+5]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=9.01e+5]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=9.01e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=9.01e+5]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=9.01e+5]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=9.01e+5]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=9.01e+5]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=9.01e+5]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=9.01e+5]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=9.01e+5]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=9.01e+5]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=9.01e+5]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=9.01e+5]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=9.01e+5]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=9.01e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=9.01e+5]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=9.01e+5]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=9.01e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=9.01e+5]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=9.01e+5]\n",
            "Epoch 584: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=9.01e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=9.01e+5]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=9.01e+5]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.01e+5]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=9.01e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=9.01e+5]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=9.01e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=9.01e+5]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=9.01e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=9.01e+5]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=9.01e+5]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=9.01e+5]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=9.01e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=9.01e+5]\n",
            "Epoch 591: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=9.01e+5]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=9.01e+5]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=9.01e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=9.01e+5]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=9.01e+5]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=9.01e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=9.01e+5]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=9.01e+5]\n",
            "Epoch 595: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=9.01e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=9.01e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=9.01e+5]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.01e+5]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=9.01e+5]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=9.01e+5]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=9.01e+5]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=9.01e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=9.01e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0403, valid_loss=9.01e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=43566)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s]\u001b[A\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=9.14e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:45:15,029\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_4c2ae2b2_6_batch_size=32,early_stop_patience_steps=5,h=5,hidden_size=128,hist_exog_list=Close_Open_High_Low_Volume_Mar_2024-04-15_11-40-37/lightning_logs\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 2024-04-15 11:45:24.023415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 2024-04-15 11:45:24.023463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 2024-04-15 11:45:24.024809: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 2024-04-15 11:45:25.211067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 4 | embedding               | TFTEmbedding             | 2.0 K \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 331 K \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 1.1 M \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 256 K \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 8 | output_adapter          | Linear                   | 129   \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 1.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 1.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m 6.834     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=44851)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.292]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209]\n",
            "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.207]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.196]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.36e+5]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.36e+5]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.36e+5]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.36e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.36e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.36e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.36e+5]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.36e+5]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.36e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.36e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.36e+5]\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.36e+5]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.36e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.36e+5]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.36e+5]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.36e+5]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.36e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.36e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.36e+5]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.36e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.36e+5]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.36e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.36e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.36e+5]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.36e+5]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.36e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.36e+5]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.36e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.36e+5]\n",
            "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.36e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.36e+5]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.36e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.36e+5]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.36e+5]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.36e+5]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.36e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.36e+5]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.36e+5]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.36e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.36e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.36e+5]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.36e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.36e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.36e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.36e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.36e+5]\n",
            "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.36e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.36e+5]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.36e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.36e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.36e+5]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.36e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.36e+5]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.36e+5]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.36e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.36e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.36e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.36e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.36e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.36e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.36e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.36e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.36e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.36e+5]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.36e+5]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.36e+5]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.36e+5]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.36e+5]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.36e+5]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.36e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.36e+5]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.36e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=3.36e+5]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=3.36e+5]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.36e+5]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.36e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.36e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.36e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=3.36e+5]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=3.36e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=3.36e+5]\n",
            "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=3.36e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=3.36e+5]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=3.36e+5]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.36e+5]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.36e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=3.36e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=3.36e+5]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.36e+5]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.36e+5]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.36e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.36e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.36e+5]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.36e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.36e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.36e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.36e+5]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.36e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=3.36e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=3.36e+5]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.36e+5]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.36e+5]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=3.36e+5]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=3.36e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.36e+5]\n",
            "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.36e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=3.36e+5]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=3.36e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.36e+5]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.36e+5]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=3.36e+5]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=3.36e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=3.36e+5]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=3.36e+5]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=3.36e+5]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=3.36e+5]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=3.36e+5]\n",
            "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=3.36e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=3.36e+5]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=3.36e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=3.36e+5]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=3.36e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=3.36e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=3.36e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=3.36e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=3.36e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=3.36e+5]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=3.36e+5]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.36e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.36e+5]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=3.36e+5]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=3.36e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=3.36e+5]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=3.36e+5]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=3.36e+5]\n",
            "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=3.36e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.36e+5]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.36e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=3.36e+5]\n",
            "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=3.36e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.36e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=3.36e+5]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=3.36e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=3.36e+5]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=3.36e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=3.36e+5]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=3.36e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.36e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.36e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=3.36e+5]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=3.36e+5]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=3.36e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=3.36e+5]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=3.36e+5]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=3.36e+5]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=3.36e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=3.36e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=3.36e+5]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=3.36e+5]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=3.36e+5]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=3.36e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=3.36e+5]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=3.36e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=3.36e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=3.36e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.36e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=3.36e+5]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=3.36e+5]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=3.36e+5]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=3.36e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=3.36e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=3.36e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=3.36e+5]\n",
            "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=3.36e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=3.36e+5]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=3.36e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=3.36e+5]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=3.36e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=3.36e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=3.36e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.122, valid_loss=3.36e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=3.85e+5]\n",
            "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=3.85e+5]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=3.85e+5]\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=3.85e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=3.85e+5]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=3.85e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=3.85e+5]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=3.85e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=3.85e+5]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=3.85e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=3.85e+5]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=3.85e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=3.85e+5]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=3.85e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=3.85e+5]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=3.85e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=3.85e+5]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=3.85e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.85e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=3.85e+5]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.85e+5]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.85e+5]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.85e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.85e+5]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=3.85e+5]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=3.85e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.85e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.85e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.85e+5]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.85e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=3.85e+5]\n",
            "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=3.85e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=3.85e+5]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=3.85e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=3.85e+5]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=3.85e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=3.85e+5]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=3.85e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=3.85e+5]\n",
            "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=3.85e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=3.85e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=3.85e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=3.85e+5]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=3.85e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=3.85e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=3.85e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.85e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=3.85e+5]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=3.85e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=3.85e+5]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=3.85e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=3.85e+5]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=3.85e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=3.85e+5]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=3.85e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=3.85e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=3.85e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0996, train_loss_epoch=0.0996, valid_loss=3.85e+5]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0996, train_loss_epoch=0.0996, valid_loss=3.85e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0964, train_loss_epoch=0.0964, valid_loss=3.85e+5]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0964, train_loss_epoch=0.0964, valid_loss=3.85e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=3.85e+5]\n",
            "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=3.85e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0985, train_loss_epoch=0.0985, valid_loss=3.85e+5]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0985, train_loss_epoch=0.0985, valid_loss=3.85e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=3.85e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=3.85e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=3.85e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=3.85e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=3.85e+5]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0962, train_loss_epoch=0.0962, valid_loss=3.85e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=3.85e+5]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=3.85e+5]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0954, train_loss_epoch=0.0954, valid_loss=3.85e+5]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0954, train_loss_epoch=0.0954, valid_loss=3.85e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=3.85e+5]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=3.85e+5]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0885, train_loss_epoch=0.0885, valid_loss=3.85e+5]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.0885, train_loss_epoch=0.0885, valid_loss=3.85e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0865, train_loss_epoch=0.0865, valid_loss=3.85e+5]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0865, train_loss_epoch=0.0865, valid_loss=3.85e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=3.85e+5]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=3.85e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=3.85e+5]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=3.85e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0778, train_loss_epoch=0.0778, valid_loss=3.85e+5]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0778, train_loss_epoch=0.0778, valid_loss=3.85e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=3.85e+5]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=3.85e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=3.85e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=3.85e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=3.85e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=3.85e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0867, train_loss_epoch=0.0867, valid_loss=3.85e+5]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0867, train_loss_epoch=0.0867, valid_loss=3.85e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=3.85e+5]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=3.85e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=3.85e+5]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=3.85e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=3.85e+5]\n",
            "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=3.85e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=3.85e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=3.85e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=3.85e+5]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=3.85e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=3.85e+5]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=3.85e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=3.85e+5]\n",
            "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=3.85e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0747, train_loss_epoch=0.0747, valid_loss=3.85e+5]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0747, train_loss_epoch=0.0747, valid_loss=3.85e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0728, train_loss_epoch=0.0728, valid_loss=3.85e+5]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0728, train_loss_epoch=0.0728, valid_loss=3.85e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=3.85e+5]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=3.85e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=3.85e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=3.85e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=3.85e+5]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=3.85e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=3.85e+5]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=3.85e+5]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=3.85e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=3.85e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=3.85e+5]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=3.85e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719, valid_loss=3.85e+5]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719, valid_loss=3.85e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0705, train_loss_epoch=0.0705, valid_loss=3.85e+5]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0705, train_loss_epoch=0.0705, valid_loss=3.85e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0759, train_loss_epoch=0.0759, valid_loss=3.85e+5]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0759, train_loss_epoch=0.0759, valid_loss=3.85e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=3.85e+5]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=3.85e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=3.85e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=3.85e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0908, train_loss_epoch=0.0908, valid_loss=3.85e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0908, train_loss_epoch=0.0908, valid_loss=3.85e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0906, train_loss_epoch=0.0906, valid_loss=3.85e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0906, train_loss_epoch=0.0906, valid_loss=3.85e+5]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0739, train_loss_epoch=0.0739, valid_loss=3.85e+5]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0739, train_loss_epoch=0.0739, valid_loss=3.85e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=3.85e+5]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=3.85e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=3.85e+5]\n",
            "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=3.85e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=3.85e+5]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=3.85e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0837, train_loss_epoch=0.0837, valid_loss=3.85e+5]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0837, train_loss_epoch=0.0837, valid_loss=3.85e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=3.85e+5]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=3.85e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=3.85e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=3.85e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=3.85e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.086, train_loss_epoch=0.086, valid_loss=3.85e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=3.85e+5]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=3.85e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0691, train_loss_epoch=0.0691, valid_loss=3.85e+5]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0691, train_loss_epoch=0.0691, valid_loss=3.85e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0971, train_loss_epoch=0.0971, valid_loss=3.85e+5]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0971, train_loss_epoch=0.0971, valid_loss=3.85e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=3.85e+5]\n",
            "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=3.85e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0858, train_loss_epoch=0.0858, valid_loss=3.85e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0858, train_loss_epoch=0.0858, valid_loss=3.85e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0764, train_loss_epoch=0.0764, valid_loss=3.85e+5]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0764, train_loss_epoch=0.0764, valid_loss=3.85e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0728, train_loss_epoch=0.0728, valid_loss=3.85e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0728, train_loss_epoch=0.0728, valid_loss=3.85e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=3.85e+5]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=3.85e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=3.85e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=3.85e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=3.85e+5]\n",
            "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=3.85e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=3.85e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=3.85e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=3.85e+5]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=3.85e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=3.85e+5]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=3.85e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=3.85e+5]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=3.85e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=3.85e+5]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=3.85e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=3.85e+5]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=3.85e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=3.85e+5]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=3.85e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=3.85e+5]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=3.85e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=3.85e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=3.85e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=0.0675, train_loss_epoch=0.0649, valid_loss=3.85e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0675, train_loss_epoch=0.0675, valid_loss=6.1e+5]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0675, train_loss_epoch=0.0675, valid_loss=6.1e+5]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=6.1e+5]\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=6.1e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0591, train_loss_epoch=0.0591, valid_loss=6.1e+5]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0591, train_loss_epoch=0.0591, valid_loss=6.1e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=6.1e+5]\n",
            "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0604, train_loss_epoch=0.0604, valid_loss=6.1e+5]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=6.1e+5]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=6.1e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=6.1e+5]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=6.1e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=6.1e+5]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=6.1e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=6.1e+5]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=6.1e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=6.1e+5]        \n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=6.1e+5]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0589, train_loss_epoch=0.0589, valid_loss=6.1e+5]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=6.1e+5]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541, valid_loss=6.1e+5]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=6.1e+5]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=6.1e+5]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=6.1e+5]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=6.1e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=6.1e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0545, train_loss_epoch=0.0545, valid_loss=6.1e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0524, train_loss_epoch=0.0524, valid_loss=6.1e+5]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0524, train_loss_epoch=0.0524, valid_loss=6.1e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=6.1e+5]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=6.1e+5]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=6.1e+5]\n",
            "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516, valid_loss=6.1e+5]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=6.1e+5]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=6.1e+5]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=6.1e+5]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=6.1e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=6.1e+5]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497, valid_loss=6.1e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=6.1e+5]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=6.1e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=6.1e+5]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=6.1e+5]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=6.1e+5]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508, valid_loss=6.1e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=6.1e+5]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=6.1e+5]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=6.1e+5]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=6.1e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=6.1e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=6.1e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=6.1e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=6.1e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=6.1e+5]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=6.1e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=6.1e+5]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=6.1e+5]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=6.1e+5]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=6.1e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=6.1e+5]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=6.1e+5]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0523, train_loss_epoch=0.0523, valid_loss=6.1e+5]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0523, train_loss_epoch=0.0523, valid_loss=6.1e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=6.1e+5]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=6.1e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=6.1e+5]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=6.1e+5]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=6.1e+5]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=6.1e+5]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=6.1e+5]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=6.1e+5]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=6.1e+5]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=6.1e+5]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=6.1e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=6.1e+5]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=6.1e+5]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=6.1e+5]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=6.1e+5]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=6.1e+5]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442, valid_loss=6.1e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=6.1e+5]\n",
            "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=6.1e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=6.1e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=6.1e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455, valid_loss=6.1e+5]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455, valid_loss=6.1e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=6.1e+5]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435, valid_loss=6.1e+5]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=6.1e+5]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.046, train_loss_epoch=0.046, valid_loss=6.1e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=6.1e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=6.1e+5]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=6.1e+5]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=6.1e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=6.1e+5]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=6.1e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=6.1e+5]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457, valid_loss=6.1e+5]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=6.1e+5]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=6.1e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=6.1e+5]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=6.1e+5]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=6.1e+5]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=6.1e+5]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502, valid_loss=6.1e+5]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502, valid_loss=6.1e+5]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=6.1e+5]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=6.1e+5]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=6.1e+5]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=6.1e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=6.1e+5]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=6.1e+5]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=6.1e+5]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461, valid_loss=6.1e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=6.1e+5]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=6.1e+5]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=6.1e+5]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=6.1e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=6.1e+5]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=6.1e+5]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=6.1e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=6.1e+5]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=6.1e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=6.1e+5]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=6.1e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=6.1e+5]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=6.1e+5]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446, valid_loss=6.1e+5]\n",
            "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446, valid_loss=6.1e+5]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=6.1e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=6.1e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=6.1e+5]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=6.1e+5]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438, valid_loss=6.1e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=6.1e+5]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=6.1e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=6.1e+5]\n",
            "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458, valid_loss=6.1e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=6.1e+5]\n",
            "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439, valid_loss=6.1e+5]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=6.1e+5]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=6.1e+5]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=6.1e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=6.1e+5]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=6.1e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=6.1e+5]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=6.1e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=6.1e+5]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=6.1e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=6.1e+5]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=6.1e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=6.1e+5]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=6.1e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=6.1e+5]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=6.1e+5]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=6.1e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=6.1e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=6.1e+5]\n",
            "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=6.1e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443, valid_loss=6.1e+5]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443, valid_loss=6.1e+5]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=6.1e+5]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=6.1e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=6.1e+5]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=6.1e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=6.1e+5]\n",
            "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=6.1e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=6.1e+5]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=6.1e+5]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=6.1e+5]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=6.1e+5]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=6.1e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=6.1e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=6.1e+5]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=6.1e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=6.1e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=6.1e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=6.1e+5]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=6.1e+5]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=6.1e+5]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=6.1e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=6.1e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=6.1e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=6.1e+5]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=6.1e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=6.1e+5]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=6.1e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.1e+5]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.1e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=6.1e+5]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=6.1e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=6.1e+5]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=6.1e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=6.1e+5]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=6.1e+5]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=6.1e+5]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=6.1e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=6.1e+5]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=6.1e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=6.1e+5]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=6.1e+5]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.1e+5]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.1e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=6.1e+5]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=6.1e+5]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0303, valid_loss=6.1e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=6.1e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=6.1e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.0308, valid_loss=6.1e+5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=7.02e+5]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=7.02e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=7.02e+5]\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=7.02e+5]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=7.02e+5]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=7.02e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=7.02e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=7.02e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.02e+5]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.02e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=7.02e+5]        \n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=7.02e+5]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=7.02e+5]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=7.02e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=7.02e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=7.02e+5]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=7.02e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=7.02e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=7.02e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=7.02e+5]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=7.02e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.02e+5]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.02e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=7.02e+5]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=7.02e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=7.02e+5]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=7.02e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=7.02e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=7.02e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=7.02e+5]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=7.02e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=7.02e+5]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=7.02e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=7.02e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=7.02e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.02e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.02e+5]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.02e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.02e+5]\n",
            "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.02e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=7.02e+5]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=7.02e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=7.02e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=7.02e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=7.02e+5]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=7.02e+5]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=7.02e+5]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=7.02e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=7.02e+5]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=7.02e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=7.02e+5]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=7.02e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=7.02e+5]\n",
            "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=7.02e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.02e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.02e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=7.02e+5]\n",
            "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=7.02e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=7.02e+5]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=7.02e+5]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.02e+5]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.02e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.02e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.02e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.02e+5]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.02e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=7.02e+5]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=7.02e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=7.02e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=7.02e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.035, valid_loss=7.02e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=7.02e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=7.02e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=7.02e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=7.02e+5]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=7.02e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=7.02e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=7.02e+5]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=7.02e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=7.02e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.02e+5]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.02e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=7.02e+5]\n",
            "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=7.02e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=7.02e+5]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=7.02e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=7.02e+5]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=7.02e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.02e+5]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.02e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=7.02e+5]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=7.02e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=7.02e+5]\n",
            "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=7.02e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.02e+5]\n",
            "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.02e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=7.02e+5]\n",
            "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=7.02e+5]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.02e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.02e+5]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=7.02e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=7.02e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.02e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.02e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=7.02e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=7.02e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=7.02e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=7.02e+5]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=7.02e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.02e+5]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.02e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=7.02e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=7.02e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=7.02e+5]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=7.02e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.02e+5]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.02e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=7.02e+5]\n",
            "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=7.02e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=7.02e+5]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=7.02e+5]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=7.02e+5]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=7.02e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=7.02e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=7.02e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=7.02e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=7.02e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=7.02e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=7.02e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=7.02e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=7.02e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=7.02e+5]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=7.02e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=7.02e+5]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.02e+5]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.02e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=7.02e+5]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=7.02e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=7.02e+5]\n",
            "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=7.02e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=7.02e+5]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=7.02e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=7.02e+5]\n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=7.02e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=7.02e+5]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=7.02e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=7.02e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=7.02e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=7.02e+5]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=7.02e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=7.02e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.02e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.02e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=7.02e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=7.02e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=7.02e+5]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=7.02e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=7.02e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=7.02e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=7.02e+5]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=7.02e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=7.02e+5]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=7.02e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=7.02e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=7.02e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=7.02e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=7.02e+5]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=7.02e+5]\n",
            "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=7.02e+5]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=7.02e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=7.02e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=7.02e+5] \n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=7.02e+5]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=7.02e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.02e+5]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.02e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=7.02e+5]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=7.02e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=7.02e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=7.02e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.02e+5]\n",
            "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.02e+5]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=7.02e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=7.02e+5]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=7.02e+5]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=7.02e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.02e+5]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.02e+5]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=7.02e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=7.02e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.026, valid_loss=7.02e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=7.24e+5]\n",
            "Epoch 500: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=7.24e+5]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.24e+5]\n",
            "Epoch 501: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.24e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=7.24e+5]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=7.24e+5]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.24e+5]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.24e+5]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.24e+5]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.24e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=7.24e+5]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=7.24e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=7.24e+5]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=7.24e+5]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=7.24e+5]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=7.24e+5]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=7.24e+5]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=7.24e+5]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=7.24e+5]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=7.24e+5]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.24e+5]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.24e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.24e+5]\n",
            "Epoch 511: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.24e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.24e+5]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.24e+5]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=7.24e+5]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=7.24e+5]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.24e+5]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.24e+5]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.24e+5]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.24e+5]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.24e+5]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.24e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=7.24e+5]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=7.24e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=7.24e+5]\n",
            "Epoch 519: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=7.24e+5]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=7.24e+5]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=7.24e+5]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=7.24e+5]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=7.24e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=7.24e+5]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=7.24e+5]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=7.24e+5]\n",
            "Epoch 523: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=7.24e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=7.24e+5]\n",
            "Epoch 524: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=7.24e+5]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=7.24e+5]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=7.24e+5]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=7.24e+5]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=7.24e+5]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.24e+5]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.24e+5]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0228, valid_loss=7.24e+5]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 529: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=7.24e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=7.24e+5]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0236, train_loss_epoch=0.0236, valid_loss=7.24e+5]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0236, train_loss_epoch=0.0236, valid_loss=7.24e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.24e+5]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.24e+5]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.24e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.24e+5]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.24e+5]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.24e+5]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=7.24e+5]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=7.24e+5]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=7.24e+5]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=7.24e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.24e+5]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.24e+5]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 539: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.24e+5]\n",
            "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.24e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204, valid_loss=7.24e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204, valid_loss=7.24e+5]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.24e+5]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.24e+5]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.24e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.24e+5]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.24e+5]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.24e+5]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=7.24e+5]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=7.24e+5]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=7.24e+5]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=7.24e+5]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.24e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.24e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.24e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.24e+5]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.24e+5]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=7.24e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=7.24e+5]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=7.24e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=7.24e+5]\n",
            "Epoch 551: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=7.24e+5]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.24e+5]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.24e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=7.24e+5]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=7.24e+5]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.24e+5]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.24e+5]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.24e+5]\n",
            "Epoch 555: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.24e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=7.24e+5]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=7.24e+5]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=7.24e+5]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=7.24e+5]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=7.24e+5]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=7.24e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.24e+5]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.24e+5]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=7.24e+5]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=7.24e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=7.24e+5]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=7.24e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.24e+5]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=7.24e+5]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=7.24e+5]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=7.24e+5]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=7.24e+5]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=7.24e+5]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.24e+5]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.24e+5]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0242, valid_loss=7.24e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=7.24e+5]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=7.24e+5]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=7.24e+5]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=7.24e+5]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=7.24e+5]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=7.24e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=7.24e+5]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=7.24e+5]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=7.24e+5]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=7.24e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=7.24e+5]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=7.24e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=7.24e+5]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=7.24e+5]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.24e+5]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.24e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=7.24e+5]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=7.24e+5]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=7.24e+5]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=7.24e+5]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.24e+5]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.24e+5]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=7.24e+5]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=7.24e+5]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.025, valid_loss=7.24e+5]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=7.24e+5]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=7.24e+5]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.24e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=7.24e+5]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=7.24e+5]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.24e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.24e+5]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.24e+5]\n",
            "Epoch 584: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.24e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.24e+5]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.24e+5]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=7.24e+5]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=7.24e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.24e+5]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.24e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=7.24e+5]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=7.24e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=7.24e+5]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=7.24e+5]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.24e+5]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.24e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=7.24e+5]\n",
            "Epoch 591: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=7.24e+5]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.24e+5]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.24e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.24e+5]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.24e+5]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211, valid_loss=7.24e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211, valid_loss=7.24e+5]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.24e+5]\n",
            "Epoch 595: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.24e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=7.24e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=7.24e+5]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=7.24e+5]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=7.24e+5]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=7.24e+5]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=7.24e+5]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0196, train_loss_epoch=0.0196, valid_loss=7.24e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.0196, train_loss_epoch=0.0196, valid_loss=7.24e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0196, valid_loss=7.24e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:53:13,155\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=44851)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0196, valid_loss=7.21e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212, valid_loss=7.21e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212, valid_loss=7.21e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=46972)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_547ef562_7_batch_size=16,early_stop_patience_steps=5,h=5,hidden_size=128,hist_exog_list=Close_Open_High_Low_Volume_Mar_2024-04-15_11-45-22/lightning_logs\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 2024-04-15 11:53:24.317041: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 2024-04-15 11:53:24.317104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 2024-04-15 11:53:24.318609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 2024-04-15 11:53:25.542489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 4 | embedding               | TFTEmbedding             | 2.0 K \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 331 K \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 1.1 M \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 256 K \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 8 | output_adapter          | Linear                   | 129   \n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 1.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 1.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m 6.834     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=46972)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.880]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=1.880]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.020]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.800]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.59it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.33e+5]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.33e+5]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=3.33e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.33e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.33e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.33e+5]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.33e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.33e+5]\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=3.33e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.33e+5]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.33e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=3.33e+5]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=3.33e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.33e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.33e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 13.41it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=3.33e+5]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.33e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.33e+5]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.33e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=3.33e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.33e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.33e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.33e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=3.33e+5]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.33e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.33e+5]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.33e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.33e+5]        \n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.33e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=3.33e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.33e+5]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.33e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.33e+5]\n",
            "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=3.33e+5]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.33e+5]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.33e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=3.33e+5]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.33e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=3.33e+5]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=3.33e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.33e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.33e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.33e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.33e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.33e+5]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 13.75it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.33e+5]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.33e+5]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.33e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.33e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.33e+5]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.33e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.33e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.33e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.33e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.33e+5]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.33e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.33e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.33e+5]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.33e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.33e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.33e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.33e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.33e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.33e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.33e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.33e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.33e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.33e+5]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.33e+5]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.33e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.33e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.33e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.33e+5]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.33e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.33e+5]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.33e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.33e+5]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.33e+5]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.33e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.33e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=3.33e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.33e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.33e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=3.33e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.33e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.33e+5]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.33e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.33e+5]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.33e+5]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=3.33e+5]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.33e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=3.33e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=3.33e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=3.33e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=3.33e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=3.33e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=3.33e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=3.33e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=3.33e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=3.33e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=3.33e+5]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=3.33e+5]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=3.33e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=3.33e+5]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=3.33e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=3.33e+5]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=3.33e+5]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=3.33e+5]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=3.33e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=3.33e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=3.33e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=3.33e+5]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=3.33e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=3.33e+5]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=3.33e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.33e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.33e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=3.33e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.33e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=3.33e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.916, valid_loss=3.33e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.19it/s]\u001b[A\n",
            "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=4.31e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=4.31e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=4.31e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=4.31e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=4.31e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=4.31e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=4.31e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=4.31e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=4.31e+5]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 13.80it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=4.31e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=4.31e+5]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=4.31e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=4.31e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=4.31e+5]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=4.31e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=4.31e+5]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=4.31e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=4.31e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=4.31e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=4.31e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=4.31e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=4.31e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=4.31e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=4.31e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=4.31e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=4.31e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=4.31e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=4.31e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=4.31e+5]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=4.31e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=4.31e+5]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=4.31e+5]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=4.31e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=4.31e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=4.31e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=4.31e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=4.31e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=4.31e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=4.31e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=4.31e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=4.31e+5]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=4.31e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=4.31e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=4.31e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.592, valid_loss=4.31e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=4.31e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=4.31e+5]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=4.31e+5]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=4.31e+5]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=4.31e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=4.31e+5]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=4.31e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=4.31e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=4.31e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=4.31e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=4.31e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=4.31e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=4.31e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=4.31e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=4.31e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=4.31e+5]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=4.31e+5]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=4.31e+5]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=4.31e+5]\n",
            "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=4.31e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=4.31e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=4.31e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=4.31e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=4.31e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=4.31e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=4.31e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=4.31e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=4.31e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=4.31e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=4.31e+5]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 12.33it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=4.31e+5]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 13.25it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=4.31e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=4.31e+5]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=4.31e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=4.31e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=4.31e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=4.31e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=4.31e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=4.31e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=4.31e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=4.31e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=4.31e+5]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=4.31e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=4.31e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=4.31e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=4.31e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=4.31e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=4.31e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=4.31e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=4.31e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=4.31e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=4.31e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=4.31e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=4.31e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=4.31e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=4.31e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=4.31e+5]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00, 12.65it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=4.31e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=4.31e+5]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 13.03it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=4.31e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=4.31e+5]\n",
            "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=4.31e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=4.31e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=4.31e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=4.31e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=4.31e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=4.31e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=4.31e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=4.31e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=4.31e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=4.31e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=4.31e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.403, valid_loss=4.31e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.83it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=5.94e+5]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=5.94e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=5.94e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=5.94e+5]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=5.94e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=5.94e+5]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=5.94e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=5.94e+5]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=5.94e+5]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=5.94e+5]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=5.94e+5]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=5.94e+5]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=5.94e+5]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=5.94e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=5.94e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=5.94e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=5.94e+5]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=5.94e+5]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=5.94e+5]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=5.94e+5]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=5.94e+5]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=5.94e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=5.94e+5]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=5.94e+5]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=5.94e+5]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=5.94e+5]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=5.94e+5]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 15.42it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=5.94e+5]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=5.94e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=5.94e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=5.94e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=5.94e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=5.94e+5]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=5.94e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=5.94e+5]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=5.94e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=5.94e+5]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=5.94e+5]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=5.94e+5]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=5.94e+5]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=5.94e+5]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=5.94e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=5.94e+5]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=5.94e+5]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=5.94e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=5.94e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=5.94e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=5.94e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=5.94e+5]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.366, valid_loss=5.94e+5]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=5.94e+5]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=5.94e+5]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=5.94e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=5.94e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=5.94e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.353, valid_loss=5.94e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=5.94e+5]        \n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=5.94e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=5.94e+5]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=5.94e+5]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.423, valid_loss=5.94e+5]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=5.94e+5]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=5.94e+5]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=5.94e+5]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=5.94e+5]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=5.94e+5]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=5.94e+5]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=5.94e+5]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=5.94e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=5.94e+5]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=5.94e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=5.94e+5]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=5.94e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=5.94e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=5.94e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=5.94e+5]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=5.94e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=5.94e+5]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=5.94e+5]\n",
            "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=5.94e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=5.94e+5]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=5.94e+5]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=5.94e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=5.94e+5]\n",
            "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=5.94e+5]\n",
            "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=5.94e+5]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=5.94e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=5.94e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=5.94e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=5.94e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=5.94e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=5.94e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=5.94e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=5.94e+5]\n",
            "Epoch 376: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=5.94e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=5.94e+5]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=5.94e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=5.94e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=5.94e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=5.94e+5]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=5.94e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=5.94e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=5.94e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=5.94e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=5.94e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=5.94e+5]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=5.94e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=5.94e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=5.94e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=5.94e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=5.94e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=5.94e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=5.94e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=5.94e+5]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=5.94e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=5.94e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=5.94e+5]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=5.94e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=5.94e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=5.94e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.294, valid_loss=5.94e+5]\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.99it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=6.18e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=6.18e+5]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=6.18e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=6.18e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=6.18e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=6.18e+5]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=6.18e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=6.18e+5]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=6.18e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=6.18e+5]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=6.18e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=6.18e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=6.18e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=6.18e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=6.18e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=6.18e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=6.18e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=6.18e+5]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=6.18e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=6.18e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=6.18e+5]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=6.18e+5]\n",
            "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=6.18e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=6.18e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=6.18e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=6.18e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=6.18e+5]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=6.18e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=6.18e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=6.18e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=6.18e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=6.18e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=6.18e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=6.18e+5]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=6.18e+5]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=6.18e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=6.18e+5]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=6.18e+5]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=6.18e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=6.18e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=6.18e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=6.18e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=6.18e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=6.18e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=6.18e+5]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=6.18e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=6.18e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=6.18e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=6.18e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=6.18e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=6.18e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=6.18e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=6.18e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=6.18e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=6.18e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=6.18e+5]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=6.18e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=6.18e+5]\n",
            "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=6.18e+5]\n",
            "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=6.18e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=6.18e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=6.18e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=6.18e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=6.18e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=6.18e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=6.18e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=6.18e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=6.18e+5]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=6.18e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=6.18e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=6.18e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=6.18e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=6.18e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=6.18e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=6.18e+5]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.246, valid_loss=6.18e+5]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=6.18e+5]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=6.18e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=6.18e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=6.18e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=6.18e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=6.18e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=6.18e+5]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=6.18e+5]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=6.18e+5]\n",
            "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=6.18e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=6.18e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=6.18e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=6.18e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=6.18e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=6.18e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=6.18e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=6.18e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=6.18e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=6.18e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=6.18e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=6.18e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=6.18e+5]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=6.18e+5]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=6.18e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=6.18e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=6.18e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=6.18e+5]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=6.18e+5]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=6.18e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=6.18e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=6.18e+5]\n",
            "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=6.18e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=6.18e+5]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=6.18e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=6.18e+5]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=6.18e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=6.18e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=6.18e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=6.18e+5]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=6.18e+5]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=6.18e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=6.18e+5]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=6.18e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.254, valid_loss=6.18e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.15it/s]\u001b[A\n",
            "Epoch 500: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=5.3e+5]\n",
            "Epoch 501: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=5.3e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=5.3e+5]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=5.3e+5]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=5.3e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=5.3e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=5.3e+5]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=5.3e+5]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=5.3e+5]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=5.3e+5]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=5.3e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=5.3e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=5.3e+5]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=5.3e+5]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.232, valid_loss=5.3e+5]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=5.3e+5]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=5.3e+5]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=5.3e+5]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=5.3e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=5.3e+5]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=5.3e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=5.3e+5]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=5.3e+5]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=5.3e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=5.3e+5]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=5.3e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=5.3e+5]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=5.3e+5]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=5.3e+5]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=5.3e+5]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=5.3e+5]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=5.3e+5]\n",
            "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=5.3e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=5.3e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=5.3e+5]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=5.3e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=5.3e+5]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=5.3e+5]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=5.3e+5]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=5.3e+5]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=5.3e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=5.3e+5]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=5.3e+5]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=5.3e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=5.3e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=5.3e+5]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=5.3e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=5.3e+5]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=5.3e+5]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=5.3e+5]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=5.3e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=5.3e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=5.3e+5]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=5.3e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=5.3e+5]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=5.3e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=5.3e+5]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=5.3e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=5.3e+5]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=5.3e+5]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=5.3e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=5.3e+5]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=5.3e+5]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=5.3e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=5.3e+5]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=5.3e+5]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=5.3e+5]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=5.3e+5]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=5.3e+5]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=5.3e+5]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=5.3e+5]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=5.3e+5]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=5.3e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=5.3e+5]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00, 13.41it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=5.3e+5]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=5.3e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=5.3e+5]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=5.3e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=5.3e+5]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=5.3e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=5.3e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=5.3e+5]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=5.3e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=5.3e+5]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=5.3e+5]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=5.3e+5]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=5.3e+5]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=5.3e+5]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=5.3e+5]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=5.3e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=5.3e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=5.3e+5]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=5.3e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=5.3e+5]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=5.3e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=5.3e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=5.3e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=5.3e+5]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=5.3e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=5.3e+5]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=5.3e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=5.3e+5]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=5.3e+5]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=5.3e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=5.3e+5]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=5.3e+5]        \n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=5.3e+5]\n",
            "Epoch 595: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=5.3e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=5.3e+5]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=5.3e+5]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=5.3e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:54:41,269\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rEpoch 598: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.199, valid_loss=5.3e+5]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=5.3e+5]\rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=5.3e+5]        \rEpoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=5.3e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=5.3e+5]\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.197, valid_loss=5.3e+5]\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 34.37it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=46972)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.197, valid_loss=5.17e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=5.17e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=5.17e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=47398)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_243f18f1_8_batch_size=32,early_stop_patience_steps=5,h=5,hidden_size=64,hist_exog_list=Close_Open_High_Low_Volume_Mark_2024-04-15_11-53-22/lightning_logs\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 2024-04-15 11:54:52.468905: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 2024-04-15 11:54:52.468961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 2024-04-15 11:54:52.470334: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 2024-04-15 11:54:53.694705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 4 | embedding               | TFTEmbedding             | 1.0 K \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 83.8 K\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 284 K \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 64.8 K\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 8 | output_adapter          | Linear                   | 65    \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 434 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 434 K     Total params\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m 1.738     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=47398)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s, v_num=0, train_loss_step=1.800]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.608]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398]\n",
            "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316]\n",
            "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339]\n",
            "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.255]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.34e+5]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.34e+5]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.34e+5]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.34e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.34e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.34e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.34e+5]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.34e+5]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.34e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.34e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.34e+5]\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.34e+5]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.34e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.34e+5]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.34e+5]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.34e+5]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.34e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.34e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.34e+5]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.34e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.34e+5]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.34e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.34e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.34e+5]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.34e+5]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.34e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.34e+5]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.34e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.34e+5]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.34e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.34e+5]\n",
            "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.34e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.34e+5]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.34e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.34e+5]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.34e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.34e+5]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.34e+5]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.34e+5]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.34e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.34e+5]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.34e+5]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.34e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.34e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.34e+5]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.34e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.34e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.34e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=3.34e+5]\n",
            "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=3.34e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=3.34e+5]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=3.34e+5]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.34e+5]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.34e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=3.34e+5]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=3.34e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.34e+5]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.34e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.34e+5]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.34e+5]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=3.34e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=3.34e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.34e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.34e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.34e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.34e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=3.34e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=3.34e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=3.34e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=3.34e+5]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.34e+5]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.34e+5]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=3.34e+5]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=3.34e+5]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=3.34e+5]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=3.34e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.34e+5]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.34e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.34e+5]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.34e+5]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.34e+5]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.34e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.34e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.34e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.34e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.34e+5]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.34e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.34e+5]\n",
            "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.34e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=3.34e+5]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=3.34e+5]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.34e+5]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.34e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.34e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.34e+5]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.34e+5]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.34e+5]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=3.34e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=3.34e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.34e+5]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.34e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.34e+5]\n",
            "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.34e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.34e+5]\n",
            "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.34e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.34e+5]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.34e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=3.34e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=3.34e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=3.34e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.34e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.34e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.34e+5]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.34e+5]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.34e+5]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.34e+5]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.34e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.34e+5]\n",
            "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.34e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.34e+5]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.34e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.34e+5]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.34e+5]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.34e+5]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.34e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.34e+5]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.34e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.34e+5]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.34e+5]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.34e+5]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.34e+5]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.34e+5]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.34e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.34e+5]\n",
            "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.34e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.34e+5]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.34e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.34e+5]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.34e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.34e+5]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.34e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.34e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.34e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.34e+5]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.34e+5]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.34e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.34e+5]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.34e+5]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.34e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.34e+5]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.34e+5]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.34e+5]\n",
            "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.34e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.34e+5]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.34e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.34e+5]\n",
            "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.34e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.34e+5]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.34e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.34e+5]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.34e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.34e+5]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.34e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.34e+5]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.34e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.34e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.34e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.34e+5]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.34e+5]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.34e+5]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.34e+5]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.34e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.34e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.34e+5]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.34e+5]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.34e+5]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.34e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.34e+5]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.34e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.34e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.34e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.34e+5]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.34e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.34e+5]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.34e+5]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=3.34e+5]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=3.34e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.34e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.34e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=3.34e+5]\n",
            "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=3.34e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.34e+5]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.34e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.190, valid_loss=3.34e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.83it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.98e+5]\n",
            "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.98e+5]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.98e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.98e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.98e+5]\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=4.98e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.98e+5]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.98e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.98e+5]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.98e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.98e+5]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.98e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.98e+5]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.98e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.98e+5]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.98e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.98e+5]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.98e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=4.98e+5]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=4.98e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=4.98e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=4.98e+5]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=4.98e+5]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=4.98e+5]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=4.98e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=4.98e+5]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=4.98e+5]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=4.98e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=4.98e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=4.98e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=4.98e+5]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=4.98e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=4.98e+5]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=4.98e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=4.98e+5]\n",
            "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=4.98e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=4.98e+5]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=4.98e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=4.98e+5]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=4.98e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.98e+5]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.98e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=4.98e+5]\n",
            "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=4.98e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=4.98e+5]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=4.98e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=4.98e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=4.98e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=4.98e+5]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=4.98e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=4.98e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=4.98e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=4.98e+5]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=4.98e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=4.98e+5]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=4.98e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=4.98e+5]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=4.98e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=4.98e+5]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=4.98e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=4.98e+5]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=4.98e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=4.98e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=4.98e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=4.98e+5]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=4.98e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=4.98e+5]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=4.98e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=4.98e+5]\n",
            "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=4.98e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=4.98e+5]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=4.98e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=4.98e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=4.98e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=4.98e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=4.98e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.98e+5]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.98e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.98e+5]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.98e+5]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=4.98e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=4.98e+5]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=4.98e+5]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=4.98e+5]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=4.98e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=4.98e+5]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=4.98e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=4.98e+5]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=4.98e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=4.98e+5]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=4.98e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=4.98e+5]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=4.98e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=4.98e+5]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=4.98e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.98e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=4.98e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=4.98e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=4.98e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=4.98e+5]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=4.98e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=4.98e+5]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=4.98e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=4.98e+5]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=4.98e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=4.98e+5]\n",
            "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=4.98e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=4.98e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=4.98e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=4.98e+5]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=4.98e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=4.98e+5]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=4.98e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=4.98e+5]\n",
            "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=4.98e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=4.98e+5]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=4.98e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0998, train_loss_epoch=0.0998, valid_loss=4.98e+5]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.0998, train_loss_epoch=0.0998, valid_loss=4.98e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=4.98e+5]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=4.98e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=4.98e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=4.98e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0909, train_loss_epoch=0.0909, valid_loss=4.98e+5]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0909, train_loss_epoch=0.0909, valid_loss=4.98e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=4.98e+5]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=4.98e+5]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=4.98e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.0943, valid_loss=4.98e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0856, train_loss_epoch=0.0856, valid_loss=4.98e+5]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=0.0856, train_loss_epoch=0.0856, valid_loss=4.98e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=4.98e+5]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=0, train_loss_step=0.0988, train_loss_epoch=0.0988, valid_loss=4.98e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=4.98e+5]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=4.98e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=4.98e+5]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=4.98e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=4.98e+5]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=4.98e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=4.98e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=4.98e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0792, train_loss_epoch=0.0792, valid_loss=4.98e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.0792, train_loss_epoch=0.0792, valid_loss=4.98e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=4.98e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=4.98e+5]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0851, train_loss_epoch=0.0851, valid_loss=4.98e+5]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=0.0851, train_loss_epoch=0.0851, valid_loss=4.98e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=4.98e+5]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=0, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=4.98e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=4.98e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.079, train_loss_epoch=0.079, valid_loss=4.98e+5]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=0, train_loss_step=0.079, train_loss_epoch=0.079, valid_loss=4.98e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=4.98e+5]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=4.98e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=4.98e+5]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=0, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=4.98e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=4.98e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826, valid_loss=4.98e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=4.98e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=4.98e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0786, train_loss_epoch=0.0786, valid_loss=4.98e+5]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=0, train_loss_step=0.0786, train_loss_epoch=0.0786, valid_loss=4.98e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=4.98e+5]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=4.98e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=4.98e+5]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=4.98e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=4.98e+5]\n",
            "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=4.98e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=4.98e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=4.98e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0727, train_loss_epoch=0.0727, valid_loss=4.98e+5]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.0727, train_loss_epoch=0.0727, valid_loss=4.98e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=4.98e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=4.98e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736, valid_loss=4.98e+5]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736, valid_loss=4.98e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0759, train_loss_epoch=0.0759, valid_loss=4.98e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=0.0759, train_loss_epoch=0.0759, valid_loss=4.98e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=4.98e+5]\n",
            "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=4.98e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=4.98e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=4.98e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0835, train_loss_epoch=0.0835, valid_loss=4.98e+5]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.0835, train_loss_epoch=0.0835, valid_loss=4.98e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=4.98e+5]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=4.98e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=4.98e+5]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=4.98e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0703, train_loss_epoch=0.0703, valid_loss=4.98e+5]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.0703, train_loss_epoch=0.0703, valid_loss=4.98e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=4.98e+5]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=4.98e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=4.98e+5]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=4.98e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679, valid_loss=4.98e+5]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679, valid_loss=4.98e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=4.98e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=4.98e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0684, valid_loss=4.98e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.92it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=5.93e+5]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=5.93e+5]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=5.93e+5]\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=5.93e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=5.93e+5]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=5.93e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=5.93e+5]\n",
            "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=5.93e+5]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=5.93e+5]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=5.93e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0613, train_loss_epoch=0.0613, valid_loss=5.93e+5]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=0, train_loss_step=0.0613, train_loss_epoch=0.0613, valid_loss=5.93e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=5.93e+5]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=5.93e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=5.93e+5]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=5.93e+5]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=5.93e+5]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.0612, train_loss_epoch=0.0612, valid_loss=5.93e+5]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=5.93e+5]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=5.93e+5]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=5.93e+5]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=5.93e+5]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=5.93e+5]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=5.93e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=5.93e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=5.93e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=5.93e+5]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=5.93e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=5.93e+5]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=5.93e+5]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=5.93e+5]\n",
            "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=5.93e+5]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=5.93e+5]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=5.93e+5]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=5.93e+5]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=5.93e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=5.93e+5]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.0548, train_loss_epoch=0.0548, valid_loss=5.93e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=5.93e+5]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=5.93e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=5.93e+5]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=5.93e+5]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=5.93e+5]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=5.93e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0546, train_loss_epoch=0.0546, valid_loss=5.93e+5]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.0546, train_loss_epoch=0.0546, valid_loss=5.93e+5]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=5.93e+5]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=5.93e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502, valid_loss=5.93e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502, valid_loss=5.93e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=5.93e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053, valid_loss=5.93e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=5.93e+5]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=5.93e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=5.93e+5]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=0, train_loss_step=0.0514, train_loss_epoch=0.0514, valid_loss=5.93e+5]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=5.93e+5]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=5.93e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=5.93e+5]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509, valid_loss=5.93e+5]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=5.93e+5]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=0, train_loss_step=0.052, train_loss_epoch=0.052, valid_loss=5.93e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=5.93e+5]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=5.93e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=5.93e+5]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=5.93e+5]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059, valid_loss=5.93e+5]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=5.93e+5]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=5.93e+5]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=5.93e+5]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=5.93e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=5.93e+5]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.0539, valid_loss=5.93e+5] \n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048, valid_loss=5.93e+5]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048, valid_loss=5.93e+5]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=5.93e+5]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537, valid_loss=5.93e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=5.93e+5]\n",
            "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=0, train_loss_step=0.0505, train_loss_epoch=0.0505, valid_loss=5.93e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=5.93e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=5.93e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=5.93e+5]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=0.0503, train_loss_epoch=0.0503, valid_loss=5.93e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=5.93e+5]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526, valid_loss=5.93e+5]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=5.93e+5]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=5.93e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=5.93e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.0499, train_loss_epoch=0.0499, valid_loss=5.93e+5]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=5.93e+5]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511, valid_loss=5.93e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0524, train_loss_epoch=0.0524, valid_loss=5.93e+5]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.0524, train_loss_epoch=0.0524, valid_loss=5.93e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=5.93e+5]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=5.93e+5]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=5.93e+5]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=5.93e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=5.93e+5]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=5.93e+5]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=5.93e+5]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=5.93e+5]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476, valid_loss=5.93e+5]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476, valid_loss=5.93e+5]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=5.93e+5]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469, valid_loss=5.93e+5]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=5.93e+5]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465, valid_loss=5.93e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=5.93e+5]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=5.93e+5]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=5.93e+5]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=5.93e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=5.93e+5]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045, valid_loss=5.93e+5]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=5.93e+5]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=5.93e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=5.93e+5]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=5.93e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=5.93e+5]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=5.93e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=5.93e+5]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=5.93e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=5.93e+5]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=5.93e+5]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=5.93e+5]\n",
            "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=5.93e+5]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=5.93e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=5.93e+5]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419, valid_loss=5.93e+5]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419, valid_loss=5.93e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=5.93e+5]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=5.93e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=5.93e+5]\n",
            "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=5.93e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=5.93e+5]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=5.93e+5]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=5.93e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=5.93e+5]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=5.93e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=5.93e+5]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=5.93e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=5.93e+5]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=5.93e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=5.93e+5]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=5.93e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=5.93e+5]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=5.93e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=5.93e+5]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=5.93e+5]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=5.93e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=5.93e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=5.93e+5]\n",
            "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=5.93e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=5.93e+5]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=5.93e+5]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=5.93e+5]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=5.93e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=5.93e+5]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=5.93e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=5.93e+5]\n",
            "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=5.93e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=5.93e+5]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=5.93e+5]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=5.93e+5]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=5.93e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=5.93e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=5.93e+5]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=5.93e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=5.93e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=5.93e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=5.93e+5]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=5.93e+5]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=5.93e+5]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=5.93e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=5.93e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=5.93e+5]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.0415, train_loss_epoch=0.0415, valid_loss=5.93e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=5.93e+5]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=5.93e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=5.93e+5]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=5.93e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=5.93e+5]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=5.93e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=5.93e+5]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=5.93e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=5.93e+5]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=5.93e+5]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=5.93e+5]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=5.93e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=5.93e+5]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=5.93e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=5.93e+5]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=5.93e+5]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=5.93e+5]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=5.93e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=5.93e+5]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=5.93e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=5.93e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=5.93e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0421, valid_loss=5.93e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.91it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=6.52e+5]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=6.52e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=6.52e+5]\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=6.52e+5]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=6.52e+5]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=6.52e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=6.52e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=6.52e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=6.52e+5]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=6.52e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=6.52e+5]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=6.52e+5]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=6.52e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=6.52e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=6.52e+5]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=6.52e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=6.52e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367, valid_loss=6.52e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=6.52e+5]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=6.52e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=6.52e+5]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=6.52e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=6.52e+5]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=6.52e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=6.52e+5]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=6.52e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=6.52e+5]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=6.52e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=6.52e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=6.52e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=6.52e+5]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=6.52e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=6.52e+5]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=6.52e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=6.52e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=6.52e+5]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=6.52e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=6.52e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=6.52e+5]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=6.52e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=6.52e+5]\n",
            "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=6.52e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=6.52e+5]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=6.52e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=6.52e+5]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=6.52e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=6.52e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=6.52e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=6.52e+5]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=6.52e+5]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=6.52e+5]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=6.52e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=6.52e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=6.52e+5]\n",
            "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=6.52e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=6.52e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=6.52e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=6.52e+5]\n",
            "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=6.52e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=6.52e+5]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=6.52e+5]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=6.52e+5]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=6.52e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=6.52e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=6.52e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=6.52e+5]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=6.52e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=6.52e+5]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=6.52e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.52e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.52e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=6.52e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=6.52e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=6.52e+5]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=6.52e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=6.52e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=6.52e+5]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=6.52e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=6.52e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=6.52e+5]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=6.52e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=6.52e+5]\n",
            "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=6.52e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=6.52e+5]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=6.52e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=6.52e+5]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=6.52e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=6.52e+5]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=6.52e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=6.52e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=6.52e+5]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=6.52e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=6.52e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=6.52e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=6.52e+5]\n",
            "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=6.52e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=6.52e+5]\n",
            "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=6.52e+5]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=6.52e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=6.52e+5]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=6.52e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=6.52e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=6.52e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=6.52e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=6.52e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=6.52e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=6.52e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=6.52e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=6.52e+5]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=6.52e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=6.52e+5]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=6.52e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=6.52e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=6.52e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=6.52e+5]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=6.52e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=6.52e+5]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=6.52e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=6.52e+5]\n",
            "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=6.52e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=6.52e+5]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=6.52e+5]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=6.52e+5]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=6.52e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=6.52e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=6.52e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=6.52e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=6.52e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=6.52e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=6.52e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=6.52e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=6.52e+5]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=6.52e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=6.52e+5]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=6.52e+5]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=6.52e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=6.52e+5]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=6.52e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=6.52e+5]\n",
            "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=6.52e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.52e+5]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=6.52e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=6.52e+5]\n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=6.52e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=6.52e+5]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=6.52e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=6.52e+5]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=6.52e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=6.52e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=6.52e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=6.52e+5]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=6.52e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=6.52e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=6.52e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=6.52e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=6.52e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=6.52e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=6.52e+5]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=6.52e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=6.52e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=6.52e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=6.52e+5]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=6.52e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=6.52e+5]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=6.52e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=6.52e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=6.52e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=6.52e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=6.52e+5]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=6.52e+5]\n",
            "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=6.52e+5]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=6.52e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=6.52e+5]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=6.52e+5]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=6.52e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=6.52e+5]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=6.52e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=6.52e+5]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=6.52e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=6.52e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=6.52e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=6.52e+5]\n",
            "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=6.52e+5]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=6.52e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=6.52e+5]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=6.52e+5]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=6.52e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=6.52e+5]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=6.52e+5]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=6.52e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=6.52e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0284, valid_loss=6.52e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.29e+5]\n",
            "Epoch 500: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=7.29e+5]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=7.29e+5]\n",
            "Epoch 501: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=7.29e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=7.29e+5]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=7.29e+5]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=7.29e+5]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=7.29e+5]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=7.29e+5]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=7.29e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=7.29e+5]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=7.29e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=7.29e+5]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=7.29e+5]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.29e+5]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=7.29e+5]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=7.29e+5]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=7.29e+5]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=7.29e+5]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=7.29e+5]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=7.29e+5]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=7.29e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=7.29e+5]\n",
            "Epoch 511: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=7.29e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.29e+5]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=7.29e+5]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=7.29e+5]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=7.29e+5]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=7.29e+5]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=7.29e+5]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=7.29e+5]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=7.29e+5]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.29e+5]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=7.29e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=7.29e+5]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=7.29e+5]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.29e+5]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=7.29e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=7.29e+5]\n",
            "Epoch 519: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=7.29e+5]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.29e+5]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=7.29e+5]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=7.29e+5]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=7.29e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.29e+5]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=7.29e+5]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=7.29e+5]\n",
            "Epoch 523: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=7.29e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=7.29e+5]\n",
            "Epoch 524: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=7.29e+5]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=7.29e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=7.29e+5]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=7.29e+5]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=7.29e+5]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=7.29e+5]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=7.29e+5]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=7.29e+5]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.29e+5]\n",
            "Epoch 529: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=7.29e+5]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=7.29e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=7.29e+5]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=7.29e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=7.29e+5]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=7.29e+5]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=7.29e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.29e+5]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.29e+5]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=7.29e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=7.29e+5]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246, valid_loss=7.29e+5]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246, valid_loss=7.29e+5]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.29e+5]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=7.29e+5]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.29e+5]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=7.29e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.29e+5]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.29e+5]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.29e+5]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.29e+5]\n",
            "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.29e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.29e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=7.29e+5]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.29e+5]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=7.29e+5]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.29e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.29e+5]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=7.29e+5]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=7.29e+5]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=7.29e+5]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=7.29e+5]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=7.29e+5]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=7.29e+5]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.29e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=7.29e+5]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=7.29e+5]\n",
            "Epoch 551: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=7.29e+5]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 555: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=7.29e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.29e+5]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.29e+5]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=7.29e+5]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=7.29e+5]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.29e+5]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=7.29e+5]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.29e+5]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=7.29e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0225, train_loss_epoch=0.0225, valid_loss=7.29e+5]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=0.0225, train_loss_epoch=0.0225, valid_loss=7.29e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=7.29e+5]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=7.29e+5]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=7.29e+5]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=7.29e+5]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=7.29e+5]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=7.29e+5]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=7.29e+5]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=7.29e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=7.29e+5]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=7.29e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=7.29e+5]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=7.29e+5]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=7.29e+5]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=7.29e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=7.29e+5]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=7.29e+5]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=7.29e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=7.29e+5]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=7.29e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=7.29e+5]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=7.29e+5]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=7.29e+5]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=7.29e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212, valid_loss=7.29e+5]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212, valid_loss=7.29e+5]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=7.29e+5]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=7.29e+5]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211, valid_loss=7.29e+5]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211, valid_loss=7.29e+5]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=7.29e+5]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=7.29e+5]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=7.29e+5]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=7.29e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=7.29e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=7.29e+5]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=7.29e+5]\n",
            "Epoch 584: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=7.29e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.29e+5]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=7.29e+5]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=7.29e+5]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=7.29e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=7.29e+5]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=7.29e+5]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=7.29e+5]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=7.29e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=7.29e+5]\n",
            "Epoch 591: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=7.29e+5]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=7.29e+5]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=7.29e+5]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=7.29e+5]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=7.29e+5]\n",
            "Epoch 595: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=7.29e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=7.29e+5]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=7.29e+5]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=7.29e+5]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=7.29e+5]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=7.29e+5]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=7.29e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=7.29e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:57:13,221\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.022, valid_loss=7.29e+5]\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.05it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47398)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.022, valid_loss=6.74e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=6.74e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=6.74e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=48092)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_f2b602aa_9_batch_size=32,early_stop_patience_steps=5,h=5,hidden_size=64,hist_exog_list=Close_Open_High_Low_Volume_Mark_2024-04-15_11-54-50/lightning_logs\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 2024-04-15 11:57:23.447135: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 2024-04-15 11:57:23.447196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 2024-04-15 11:57:23.448832: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 2024-04-15 11:57:24.685583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 4 | embedding               | TFTEmbedding             | 1.0 K \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 83.8 K\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 284 K \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 64.8 K\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 8 | output_adapter          | Linear                   | 65    \n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 434 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 434 K     Total params\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m 1.738     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=48092)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=48092)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=48092)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 11:57:28,653\tERROR tune_controller.py:1332 -- Trial task failed for trial _train_tune_f2b602aa\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2667, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
            "\tclass_name: ImplicitFunc\n",
            "\tactor_id: 07171d0e191c8762e2cde17f01000000\n",
            "\tpid: 48092\n",
            "\tnamespace: 791de3bc-b2d5-43e8-80f5-b4b2074fefa9\n",
            "\tip: 172.28.0.12\n",
            "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 724, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 334, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 53, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 261, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 209, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 357, in _fit_model\n",
            "    model = model.fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 638, in fit\n",
            "    return self._fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_model.py\", line 215, in _fit\n",
            "    trainer.fit(model, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1033, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 250, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 190, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 385, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 146, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 138, in closure\n",
            "    self._backward_fn(step_output.closure_loss)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 239, in backward_fn\n",
            "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 213, in backward\n",
            "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 72, in backward\n",
            "    model.backward(tensor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1090, in backward\n",
            "    loss.backward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 14.75 GiB of which 829.06 MiB is free. Process 13880 has 164.00 MiB memory in use. Process 777046 has 13.78 GiB memory in use. Of the allocated memory 11.20 GiB is allocated by PyTorch, and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1245, in dump\n",
            "    return super().dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tblib/pickling_support.py\", line 46, in pickle_exception\n",
            "    rv = obj.__reduce_ex__(3)\n",
            "RecursionError: maximum recursion depth exceeded while calling a Python object\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1479, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1249, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 724, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 334, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 53, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 261, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 209, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 357, in _fit_model\n",
            "    model = model.fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 638, in fit\n",
            "    return self._fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_model.py\", line 215, in _fit\n",
            "    trainer.fit(model, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1033, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 250, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 190, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 385, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 146, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 138, in closure\n",
            "    self._backward_fn(step_output.closure_loss)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 239, in backward_fn\n",
            "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 213, in backward\n",
            "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 72, in backward\n",
            "    model.backward(tensor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1090, in backward\n",
            "    loss.backward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 14.75 GiB of which 829.06 MiB is free. Process 13880 has 164.00 MiB memory in use. Process 777046 has 13.78 GiB memory in use. Of the allocated memory 11.20 GiB is allocated by PyTorch, and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1245, in dump\n",
            "    return super().dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tblib/pickling_support.py\", line 46, in pickle_exception\n",
            "    rv = obj.__reduce_ex__(3)\n",
            "RecursionError: maximum recursion depth exceeded while calling a Python object\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1479, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1249, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff07171d0e191c8762e2cde17f01000000 Worker ID: 390b3813a262400b4fb2d8dff600bf98850934d2d4a21f4202955862 Node ID: 15e3893806042dec6df5bfc4f8fedb384d9858b8bdec81f1d150fe57 Worker IP address: 172.28.0.12 Worker port: 37959 Worker PID: 48092 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1830, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 724, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 334, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 88, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 53, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 261, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 209, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_auto.py\", line 357, in _fit_model\n",
            "    model = model.fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_windows.py\", line 638, in fit\n",
            "    return self._fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/neuralforecast/common/_base_model.py\", line 215, in _fit\n",
            "    trainer.fit(model, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1033, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 250, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 190, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1303, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\", line 152, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 75, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 385, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 146, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 138, in closure\n",
            "    self._backward_fn(step_output.closure_loss)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 239, in backward_fn\n",
            "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\", line 213, in backward\n",
            "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 72, in backward\n",
            "    model.backward(tensor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\", line 1090, in backward\n",
            "    loss.backward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 14.75 GiB of which 829.06 MiB is free. Process 13880 has 164.00 MiB memory in use. Process 777046 has 13.78 GiB memory in use. Of the allocated memory 11.20 GiB is allocated by PyTorch, and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1245, in dump\n",
            "    return super().dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tblib/pickling_support.py\", line 46, in pickle_exception\n",
            "    rv = obj.__reduce_ex__(3)\n",
            "RecursionError: maximum recursion depth exceeded while calling a Python object\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1479, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle.py\", line 1249, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "\n",
            "Trial _train_tune_f2b602aa errored after 0 iterations at 2024-04-15 11:57:28. Total running time: 26min 14s\n",
            "Error file: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/driver_artifacts/_train_tune_f2b602aa_9_batch_size=32,early_stop_patience_steps=5,h=5,hidden_size=64,hist_exog_list=Close_Open_High_Low_Volume_Mark_2024-04-15_11-54-50/error.txt\n",
            "Epoch 1:   0%|          | 0/1 [00:02<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=48198)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m   warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_11-31-13/_train_tune_2024-04-15_11-31-13/working_dirs/_train_tune_b0d46c1b_10_batch_size=32,early_stop_patience_steps=5,h=5,hidden_size=128,hist_exog_list=Close_Open_High_Low_Volume_Ma_2024-04-15_11-57-21/lightning_logs\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 2024-04-15 11:57:38.253486: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 2024-04-15 11:57:38.253537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 2024-04-15 11:57:38.254768: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 2024-04-15 11:57:39.499788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m   | Name                    | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 0 | loss                    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 1 | valid_loss              | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 2 | padder_train            | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 3 | scaler                  | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 4 | embedding               | TFTEmbedding             | 2.0 K \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 5 | static_encoder          | StaticCovariateEncoder   | 331 K \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 6 | temporal_encoder        | TemporalCovariateEncoder | 1.1 M \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 7 | temporal_fusion_decoder | TemporalFusionDecoder    | 256 K \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 8 | output_adapter          | Linear                   | 129   \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m ---------------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 1.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 1.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m 6.834     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=48198)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]\n",
            "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
            "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
            "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
            "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
            "Epoch 51: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 61: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 65: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]\n",
            "Epoch 74: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912]\n",
            "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888]\n",
            "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976]\n",
            "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861]\n",
            "Epoch 90: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887]\n",
            "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.836]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=6.38e+5]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=6.38e+5]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=6.38e+5]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=6.38e+5]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=6.38e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=6.38e+5]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.959, valid_loss=6.38e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=6.38e+5]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=6.38e+5]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=6.38e+5]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=6.38e+5]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=6.38e+5]\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=6.38e+5]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=6.38e+5]\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=6.38e+5]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=6.38e+5]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=6.38e+5]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=6.38e+5]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=6.38e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=6.38e+5]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=6.38e+5]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=6.38e+5]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=6.38e+5]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=6.38e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=6.38e+5]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=6.38e+5]\n",
            "Epoch 112: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=6.38e+5]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=6.38e+5]\n",
            "Epoch 113: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=6.38e+5]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=6.38e+5]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=6.38e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=6.38e+5]\n",
            "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=6.38e+5]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=6.38e+5]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=6.38e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=6.38e+5]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=6.38e+5]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=6.38e+5]\n",
            "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=6.38e+5]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=6.38e+5]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=6.38e+5]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=6.38e+5]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=6.38e+5]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=6.38e+5]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=6.38e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=6.38e+5]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=6.38e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=6.38e+5]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=6.38e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=6.38e+5]\n",
            "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=6.38e+5]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=6.38e+5]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=6.38e+5]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=6.38e+5]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=6.38e+5]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=6.38e+5]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=6.38e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=6.38e+5]\n",
            "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=6.38e+5]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=6.38e+5]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=6.38e+5]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=6.38e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=6.38e+5]\n",
            "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.733, valid_loss=6.38e+5]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=6.38e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=6.38e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=6.38e+5]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=6.38e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=6.38e+5]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=6.38e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=6.38e+5]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=6.38e+5]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=6.38e+5]\n",
            "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=6.38e+5]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=6.38e+5]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=6.38e+5]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=6.38e+5]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=6.38e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=6.38e+5]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=6.38e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=6.38e+5]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=6.38e+5]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=6.38e+5]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=6.38e+5]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=6.38e+5]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=6.38e+5]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=6.38e+5]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=6.38e+5]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=6.38e+5]\n",
            "Epoch 143: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=6.38e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=6.38e+5]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=6.38e+5]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=6.38e+5]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=6.38e+5]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=6.38e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=6.38e+5]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=6.38e+5]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=6.38e+5]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=6.38e+5]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=6.38e+5]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=6.38e+5]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=6.38e+5]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=6.38e+5]\n",
            "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=6.38e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=6.38e+5]\n",
            "Epoch 151: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=6.38e+5]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=6.38e+5]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=6.38e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=6.38e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=6.38e+5]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=6.38e+5]\n",
            "Epoch 154: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=6.38e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=6.38e+5]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=6.38e+5]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=6.38e+5]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=6.38e+5]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=6.38e+5]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=6.38e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=6.38e+5]\n",
            "Epoch 158: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=6.38e+5]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=6.38e+5]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=6.38e+5]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=6.38e+5]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=6.38e+5]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=6.38e+5]\n",
            "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=6.38e+5]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=6.38e+5]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=6.38e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=6.38e+5]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=6.38e+5]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=6.38e+5]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=6.38e+5]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=6.38e+5]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=6.38e+5]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=6.38e+5]\n",
            "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=6.38e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=6.38e+5]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=6.38e+5]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=6.38e+5]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=6.38e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=6.38e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=6.38e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=6.38e+5]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=6.38e+5]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=6.38e+5]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=6.38e+5]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=6.38e+5]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=6.38e+5]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=6.38e+5]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=6.38e+5]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=6.38e+5]\n",
            "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=6.38e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=6.38e+5]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=6.38e+5]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=6.38e+5]\n",
            "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=6.38e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=6.38e+5]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=6.38e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=6.38e+5]\n",
            "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=6.38e+5]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=6.38e+5]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=6.38e+5]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=6.38e+5]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=6.38e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=6.38e+5]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=6.38e+5]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=6.38e+5]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=6.38e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=6.38e+5]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=6.38e+5]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=6.38e+5]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=6.38e+5]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=6.38e+5]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=6.38e+5]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=6.38e+5]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=6.38e+5]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=6.38e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=6.38e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=6.38e+5]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=6.38e+5]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=6.38e+5]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=6.38e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=6.38e+5]\n",
            "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=6.38e+5]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=6.38e+5]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=6.38e+5]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=6.38e+5]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=6.38e+5]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=6.38e+5]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=6.38e+5]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=6.38e+5]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=6.38e+5]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=6.38e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=6.38e+5]\n",
            "Epoch 195: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=6.38e+5]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=6.38e+5]\n",
            "Epoch 196: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=6.38e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=6.38e+5]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=6.38e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=6.38e+5]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=6.38e+5]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=6.38e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=6.38e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.378, valid_loss=6.38e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=3.22e+5]\n",
            "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=3.22e+5]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=3.22e+5]\n",
            "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=3.22e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=3.22e+5]\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=3.22e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=3.22e+5]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=3.22e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=3.22e+5]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=3.22e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=3.22e+5]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=3.22e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=3.22e+5]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=3.22e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=3.22e+5]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=3.22e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=3.22e+5]\n",
            "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=3.22e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.22e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.22e+5]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=3.22e+5]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=3.22e+5]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=3.22e+5]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.22e+5]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.22e+5]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=3.22e+5]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=3.22e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=3.22e+5]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=3.22e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.22e+5]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.22e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=3.22e+5]\n",
            "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=3.22e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.22e+5]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.22e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.22e+5]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.22e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=3.22e+5]\n",
            "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=3.22e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.22e+5]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.22e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=3.22e+5]\n",
            "Epoch 223: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=3.22e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=3.22e+5]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=3.22e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=3.22e+5]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=3.22e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=3.22e+5]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=3.22e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.22e+5]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.22e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=3.22e+5]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=3.22e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=3.22e+5]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=3.22e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.22e+5]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.22e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.22e+5]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.22e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.22e+5]\n",
            "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.22e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.22e+5]\n",
            "Epoch 235: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.22e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.22e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.22e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.22e+5]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.22e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.22e+5]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.22e+5]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.22e+5]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.22e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=3.22e+5]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=3.22e+5]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.22e+5]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.22e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.22e+5]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.22e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.22e+5]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.22e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.22e+5]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.22e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.22e+5]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.22e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=3.22e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=3.22e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=3.22e+5]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=3.22e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.22e+5]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.22e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=3.22e+5]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=3.22e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.22e+5]\n",
            "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.22e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.22e+5]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.22e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.22e+5]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.22e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=3.22e+5]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=3.22e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=3.22e+5]\n",
            "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=3.22e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.22e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.22e+5]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.22e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.22e+5]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.22e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.22e+5]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.22e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.22e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.22e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.22e+5]\n",
            "Epoch 265: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.22e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.22e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.22e+5]\n",
            "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.22e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.22e+5]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.22e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.22e+5]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.22e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.22e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.22e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.22e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.22e+5]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=3.22e+5]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=3.22e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=3.22e+5]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=3.22e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.22e+5]\n",
            "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.22e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.22e+5]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.22e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.22e+5]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.22e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.22e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.22e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=3.22e+5]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=3.22e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.22e+5]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.22e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.22e+5]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.22e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.22e+5]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.22e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.22e+5]\n",
            "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.22e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.22e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.22e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.357, valid_loss=3.22e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.22e+5]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.22e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.22e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.22e+5]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.22e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=3.22e+5]\n",
            "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=3.22e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.22e+5]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.22e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.22e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.22e+5]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.22e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.22e+5]\n",
            "Epoch 294: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.22e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.22e+5]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.22e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.22e+5]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.22e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.22e+5]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.22e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.22e+5]\n",
            "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.22e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.22e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.22e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.362, valid_loss=3.22e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.26e+5]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.26e+5]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.26e+5]\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.26e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.26e+5]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.26e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.26e+5]\n",
            "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.26e+5]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.26e+5]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.26e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.26e+5]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.26e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.26e+5]\n",
            "Epoch 306: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.26e+5]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.26e+5]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.26e+5]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.26e+5]\n",
            "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.26e+5]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.26e+5]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.26e+5]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.26e+5]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.26e+5]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.26e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.26e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.26e+5]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.26e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.26e+5]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.26e+5]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.26e+5]\n",
            "Epoch 315: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.26e+5]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.26e+5]\n",
            "Epoch 316: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.26e+5]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.26e+5]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.26e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.26e+5]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.26e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.26e+5]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.26e+5]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.26e+5]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.26e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.26e+5]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.26e+5]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.26e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.26e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.26e+5]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.26e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.26e+5]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=3.26e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.26e+5]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.26e+5]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.26e+5]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.26e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.26e+5]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.26e+5]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.26e+5]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.26e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.26e+5]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.26e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.26e+5]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.26e+5]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.26e+5]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.26e+5]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.26e+5]\n",
            "Epoch 336: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.26e+5]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.26e+5]\n",
            "Epoch 337: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.26e+5]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.26e+5]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.26e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.26e+5]\n",
            "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.26e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.26e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.26e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.26e+5]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.26e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.26e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.26e+5]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.26e+5]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.26e+5]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.26e+5]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.26e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.26e+5]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.26e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.26e+5]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.26e+5]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.26e+5]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.26e+5]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.26e+5]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.26e+5]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.26e+5]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.26e+5]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.26e+5]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.26e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.26e+5]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.26e+5]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.26e+5]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.26e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.26e+5]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.26e+5]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.26e+5]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.26e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.26e+5]\n",
            "Epoch 358: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.26e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.26e+5]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.26e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.26e+5]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.26e+5]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.26e+5]\n",
            "Epoch 362: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.26e+5]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.26e+5]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.26e+5]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.26e+5]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.26e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.26e+5]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.26e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.26e+5]\n",
            "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.26e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.26e+5]\n",
            "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.26e+5]\n",
            "Epoch 367: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.26e+5]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.26e+5]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.26e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.26e+5]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.26e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=3.26e+5]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=3.26e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.26e+5]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.26e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.26e+5]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.26e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.26e+5]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.26e+5]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.26e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.26e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.26e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.26e+5]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.26e+5]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.26e+5]\n",
            "Epoch 378: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.26e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.26e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.26e+5]\n",
            "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.26e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.26e+5]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.26e+5]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.26e+5]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.26e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.26e+5]\n",
            "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.26e+5]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.26e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.26e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.26e+5]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.26e+5]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.26e+5]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.26e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.26e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.26e+5]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.26e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.26e+5]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.26e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.26e+5]\n",
            "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.26e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.26e+5]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.26e+5]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.26e+5]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.26e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.26e+5]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.26e+5]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.26e+5]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.26e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.26e+5]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.26e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.26e+5]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.26e+5]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.26e+5]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.26e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.26e+5]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.26e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.26e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.26e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.331, valid_loss=3.26e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.21e+5]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.21e+5]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.21e+5]\n",
            "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.21e+5]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.21e+5]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.21e+5]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.21e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.21e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.21e+5]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.21e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.21e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.21e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.21e+5]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.21e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.21e+5]\n",
            "Epoch 410: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.21e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.21e+5]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.21e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.21e+5]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.21e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.21e+5]\n",
            "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.21e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.21e+5]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.21e+5]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.21e+5]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.21e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.21e+5]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.21e+5]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=3.21e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=3.21e+5]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.379, valid_loss=3.21e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.21e+5]\n",
            "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.21e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.21e+5]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.21e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.21e+5]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.21e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.21e+5]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.21e+5]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.21e+5]\n",
            "Epoch 428: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.21e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.21e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.21e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.21e+5]\n",
            "Epoch 430: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.21e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.21e+5]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.21e+5]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=3.21e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=3.21e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.21e+5]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.21e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.21e+5]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.21e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.21e+5]\n",
            "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.21e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.21e+5]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.21e+5]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.21e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.21e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.21e+5]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.21e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.21e+5]\n",
            "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.21e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.21e+5]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.21e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.21e+5]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.21e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.21e+5]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.21e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.21e+5]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.21e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=3.21e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=3.21e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.21e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.21e+5]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.21e+5]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.21e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.21e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.21e+5]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.21e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.21e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.21e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.21e+5]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.21e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.21e+5]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.21e+5]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.353, valid_loss=3.21e+5]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.21e+5]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.21e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.21e+5]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.21e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.21e+5]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.21e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.21e+5]\n",
            "Epoch 463: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.21e+5]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.21e+5]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.21e+5]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.21e+5]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.21e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.21e+5]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.21e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.21e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.21e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.21e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.21e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.21e+5]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.21e+5]\n",
            "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.21e+5]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.21e+5]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.21e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=3.21e+5]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=3.21e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.21e+5]\n",
            "Epoch 473: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.21e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.21e+5]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.21e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.21e+5]\n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.21e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.21e+5]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.21e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.21e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.21e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.21e+5]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.21e+5]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.21e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.21e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.21e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.21e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.21e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=3.21e+5]\n",
            "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=3.21e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.21e+5]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.21e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.21e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.21e+5]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.326, valid_loss=3.21e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.21e+5]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.21e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.21e+5]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.21e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.21e+5]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.21e+5]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.21e+5]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.21e+5]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.21e+5]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.21e+5]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.21e+5]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.21e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.21e+5]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.21e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.21e+5]\n",
            "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.21e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.21e+5]\n",
            "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.21e+5]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.21e+5]\n",
            "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.21e+5]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.21e+5]\n",
            "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.21e+5]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.21e+5]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.21e+5]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.21e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.21e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.317, valid_loss=3.21e+5]\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.35e+5]\n",
            "Epoch 500: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.35e+5]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.35e+5]\n",
            "Epoch 501: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.35e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.35e+5]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.35e+5]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.35e+5]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.35e+5]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.35e+5]\n",
            "Epoch 504: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.35e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.35e+5]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.35e+5]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.35e+5]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.35e+5]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 508: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.35e+5]\n",
            "Epoch 509: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.35e+5]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.35e+5]\n",
            "Epoch 511: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.35e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.35e+5]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.35e+5]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.35e+5]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.35e+5]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.35e+5]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.35e+5]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 516: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.35e+5]\n",
            "Epoch 518: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.35e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.35e+5]\n",
            "Epoch 519: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.35e+5]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.35e+5]\n",
            "Epoch 520: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.35e+5]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.35e+5]\n",
            "Epoch 521: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.35e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.35e+5]\n",
            "Epoch 522: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.35e+5]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.35e+5]\n",
            "Epoch 523: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.35e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 524: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.35e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.35e+5]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.35e+5]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.35e+5]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 529: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.35e+5]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.35e+5]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.35e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.35e+5]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.35e+5]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.35e+5]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.35e+5]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.35e+5]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.35e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.35e+5]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 535: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.35e+5]\n",
            "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.35e+5]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 537: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.35e+5]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.35e+5]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.35e+5]\n",
            "Epoch 539: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.35e+5]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.35e+5]\n",
            "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.35e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.35e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.35e+5]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.35e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.35e+5]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.35e+5]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.35e+5]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.35e+5]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.35e+5]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 548: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.35e+5]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.35e+5]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.35e+5]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.35e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.35e+5]\n",
            "Epoch 551: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.35e+5]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.35e+5]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.35e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.35e+5]\n",
            "Epoch 553: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.35e+5]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.35e+5]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.35e+5]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.35e+5]\n",
            "Epoch 555: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.35e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.35e+5]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.35e+5]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.35e+5]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.35e+5]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 558: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.35e+5]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.35e+5]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.35e+5]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.35e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.35e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.35e+5]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.35e+5]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=3.35e+5]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=3.35e+5]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.35e+5]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.35e+5]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.35e+5]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.35e+5]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.35e+5]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.35e+5]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.35e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.35e+5]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.35e+5]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.35e+5]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.35e+5]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.35e+5]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.35e+5]\n",
            "Epoch 570: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.35e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.35e+5]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.35e+5]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.35e+5]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.35e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.35e+5]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.35e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 574: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.35e+5]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.35e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 576: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.35e+5]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.35e+5]\n",
            "Epoch 577: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.35e+5]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.35e+5]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.35e+5]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.35e+5]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.35e+5]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.35e+5]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.35e+5]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.35e+5]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.35e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.35e+5]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.35e+5]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.35e+5]\n",
            "Epoch 584: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.35e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.35e+5]\n",
            "Epoch 585: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.35e+5]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.35e+5]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.35e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.35e+5]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.35e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.35e+5]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.35e+5]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 589: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.35e+5]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.35e+5]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 591: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.35e+5]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.35e+5]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 594: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.35e+5]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.35e+5]\n",
            "Epoch 595: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.35e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.35e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.35e+5]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.35e+5]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.35e+5]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.35e+5]\n",
            "Epoch 598: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.35e+5]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.35e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.35e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.353, valid_loss=3.35e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.29e+5]\n",
            "Epoch 600: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.29e+5]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.29e+5]\n",
            "Epoch 601: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.29e+5]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.29e+5]\n",
            "Epoch 602: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.29e+5]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.29e+5]\n",
            "Epoch 603: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.29e+5]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.29e+5]\n",
            "Epoch 604: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.29e+5]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.29e+5]\n",
            "Epoch 605: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.29e+5]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.29e+5]\n",
            "Epoch 606: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.29e+5]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.29e+5]\n",
            "Epoch 607: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.29e+5]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.29e+5]\n",
            "Epoch 608: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.29e+5]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.29e+5]\n",
            "Epoch 609: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.29e+5]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.29e+5]\n",
            "Epoch 610: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.29e+5]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.29e+5]\n",
            "Epoch 611: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.29e+5]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.29e+5]\n",
            "Epoch 612: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.29e+5]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.29e+5]\n",
            "Epoch 613: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.29e+5]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.29e+5]\n",
            "Epoch 614: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.29e+5]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.29e+5]\n",
            "Epoch 615: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.29e+5]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.29e+5]\n",
            "Epoch 616: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.29e+5]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.29e+5]\n",
            "Epoch 617: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.29e+5]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.29e+5]\n",
            "Epoch 618: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.29e+5]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.29e+5]\n",
            "Epoch 619: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.29e+5]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.29e+5]\n",
            "Epoch 620: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.29e+5]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.29e+5]\n",
            "Epoch 621: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.29e+5]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.29e+5]\n",
            "Epoch 622: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.29e+5]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.29e+5]\n",
            "Epoch 623: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.29e+5]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.29e+5]\n",
            "Epoch 624: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.29e+5]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.29e+5]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.29e+5]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.29e+5]\n",
            "Epoch 627: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.29e+5]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 628: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.29e+5]\n",
            "Epoch 629: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.29e+5]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.29e+5]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.29e+5]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.29e+5]\n",
            "Epoch 631: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.29e+5]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.29e+5]\n",
            "Epoch 632: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.29e+5]\n",
            "Epoch 632: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.29e+5]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.29e+5]\n",
            "Epoch 633: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.29e+5]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.29e+5]\n",
            "Epoch 634: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.29e+5]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.29e+5]\n",
            "Epoch 635: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.29e+5]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.29e+5]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.29e+5]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.29e+5]\n",
            "Epoch 637: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.29e+5]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.29e+5]\n",
            "Epoch 638: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.29e+5]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.29e+5]\n",
            "Epoch 639: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.29e+5]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 640: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.29e+5]\n",
            "Epoch 641: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.29e+5]\n",
            "Epoch 641: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.29e+5]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.29e+5]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.29e+5]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.29e+5]\n",
            "Epoch 643: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.29e+5]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.29e+5]\n",
            "Epoch 644: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.29e+5]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.29e+5]\n",
            "Epoch 645: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.29e+5]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.29e+5]\n",
            "Epoch 646: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.29e+5]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.29e+5]\n",
            "Epoch 647: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.29e+5]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 648: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.29e+5]\n",
            "Epoch 649: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.29e+5]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.29e+5]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.29e+5]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.29e+5]\n",
            "Epoch 651: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.29e+5]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.29e+5]\n",
            "Epoch 652: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.29e+5]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.29e+5]\n",
            "Epoch 653: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.29e+5]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.29e+5]\n",
            "Epoch 654: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.29e+5]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.29e+5]\n",
            "Epoch 655: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.29e+5]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.29e+5]\n",
            "Epoch 656: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.29e+5]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.29e+5]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.29e+5]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 658: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.29e+5]\n",
            "Epoch 659: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.29e+5]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.29e+5]\n",
            "Epoch 660: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.29e+5]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.29e+5]\n",
            "Epoch 661: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.29e+5]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.29e+5]\n",
            "Epoch 662: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.29e+5]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.29e+5]\n",
            "Epoch 663: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.29e+5]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.29e+5]\n",
            "Epoch 664: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.29e+5]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 665: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.29e+5]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.29e+5]\n",
            "Epoch 666: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.29e+5]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.29e+5]\n",
            "Epoch 667: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.29e+5]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.29e+5]\n",
            "Epoch 668: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.29e+5]\n",
            "Epoch 668: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.29e+5]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.29e+5]\n",
            "Epoch 669: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.29e+5]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.29e+5]\n",
            "Epoch 670: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.29e+5]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.29e+5]\n",
            "Epoch 671: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.29e+5]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.29e+5]\n",
            "Epoch 672: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.29e+5]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.29e+5]\n",
            "Epoch 673: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.29e+5]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.29e+5]\n",
            "Epoch 674: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.29e+5]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.29e+5]\n",
            "Epoch 675: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.29e+5]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.29e+5]\n",
            "Epoch 676: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.29e+5]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.29e+5]\n",
            "Epoch 677: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.29e+5]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.29e+5]\n",
            "Epoch 678: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.29e+5]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.29e+5]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.29e+5]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.29e+5]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.29e+5]\n",
            "Epoch 680: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.29e+5]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.29e+5]\n",
            "Epoch 681: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.29e+5]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.29e+5]\n",
            "Epoch 682: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.29e+5]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.29e+5]\n",
            "Epoch 683: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.29e+5]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 684: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.29e+5]\n",
            "Epoch 685: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.29e+5]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.29e+5]\n",
            "Epoch 687: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.29e+5]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.29e+5]\n",
            "Epoch 688: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.29e+5]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.29e+5]\n",
            "Epoch 689: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.29e+5]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.29e+5]\n",
            "Epoch 690: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.29e+5]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.29e+5]\n",
            "Epoch 691: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.29e+5]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.29e+5]\n",
            "Epoch 692: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.29e+5]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.29e+5]\n",
            "Epoch 693: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.29e+5]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 694: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.29e+5]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.29e+5]\n",
            "Epoch 695: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.29e+5]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.29e+5]\n",
            "Epoch 696: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.29e+5]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.29e+5]\n",
            "Epoch 697: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.29e+5]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.29e+5]\n",
            "Epoch 698: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.29e+5]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.29e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.29e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.304, valid_loss=3.29e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.31e+5]\n",
            "Epoch 700: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.31e+5]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.31e+5]\n",
            "Epoch 701: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.31e+5]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.31e+5]\n",
            "Epoch 702: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.31e+5]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.31e+5]\n",
            "Epoch 703: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.31e+5]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.31e+5]\n",
            "Epoch 704: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.31e+5]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.31e+5]\n",
            "Epoch 705: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.31e+5]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.31e+5]\n",
            "Epoch 706: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.31e+5]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.31e+5]\n",
            "Epoch 707: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.31e+5]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.31e+5]\n",
            "Epoch 708: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.31e+5]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.31e+5]\n",
            "Epoch 709: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.31e+5]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.31e+5]\n",
            "Epoch 710: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.31e+5]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.31e+5]\n",
            "Epoch 711: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.31e+5]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.31e+5]\n",
            "Epoch 712: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.31e+5]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.31e+5]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.31e+5]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.31e+5]\n",
            "Epoch 714: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.31e+5]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.31e+5]\n",
            "Epoch 715: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.31e+5]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.31e+5]\n",
            "Epoch 716: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.31e+5]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.31e+5]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.31e+5]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.31e+5]\n",
            "Epoch 718: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.31e+5]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 719: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.31e+5]\n",
            "Epoch 720: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.31e+5]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.31e+5]\n",
            "Epoch 721: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.31e+5]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.31e+5]\n",
            "Epoch 722: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.31e+5]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.31e+5]\n",
            "Epoch 723: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.31e+5]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.31e+5]\n",
            "Epoch 724: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.31e+5]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.31e+5]\n",
            "Epoch 725: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.31e+5]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.31e+5]\n",
            "Epoch 726: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.31e+5]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.31e+5]\n",
            "Epoch 727: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.31e+5]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.31e+5]\n",
            "Epoch 728: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.31e+5]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.31e+5]\n",
            "Epoch 729: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.31e+5]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.31e+5]\n",
            "Epoch 730: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.31e+5]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.31e+5]\n",
            "Epoch 731: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.31e+5]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.31e+5]\n",
            "Epoch 732: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.31e+5]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.31e+5]\n",
            "Epoch 733: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.31e+5]\n",
            "Epoch 733: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.31e+5]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.31e+5]\n",
            "Epoch 734: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.31e+5]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.31e+5]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.31e+5]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.31e+5]\n",
            "Epoch 736: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.31e+5]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 737: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 738: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.31e+5]\n",
            "Epoch 739: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.31e+5]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.31e+5]\n",
            "Epoch 740: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.31e+5]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.31e+5]\n",
            "Epoch 741: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.31e+5]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.31e+5]\n",
            "Epoch 742: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.31e+5]\n",
            "Epoch 742: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 743: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 744: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.31e+5]\n",
            "Epoch 745: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.31e+5]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.31e+5]\n",
            "Epoch 746: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.31e+5]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.31e+5]\n",
            "Epoch 747: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.31e+5]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.31e+5]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.31e+5]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.31e+5]\n",
            "Epoch 749: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.31e+5]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.31e+5]\n",
            "Epoch 750: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.31e+5]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.31e+5]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.31e+5]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 752: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.31e+5]\n",
            "Epoch 753: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.31e+5]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.31e+5]\n",
            "Epoch 754: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.31e+5]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=3.31e+5]\n",
            "Epoch 755: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=3.31e+5]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.31e+5]\n",
            "Epoch 756: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.31e+5]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.31e+5]\n",
            "Epoch 757: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.31e+5]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 758: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.31e+5]\n",
            "Epoch 759: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.31e+5]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.31e+5]\n",
            "Epoch 760: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.31e+5]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 761: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.31e+5]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.31e+5]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.31e+5]\n",
            "Epoch 763: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.31e+5]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.31e+5]\n",
            "Epoch 764: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.31e+5]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.31e+5]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.31e+5]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.31e+5]\n",
            "Epoch 766: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.31e+5]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.31e+5]\n",
            "Epoch 767: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.31e+5]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.31e+5]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.31e+5]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 769: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.31e+5]\n",
            "Epoch 770: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.31e+5]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.31e+5]\n",
            "Epoch 771: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.31e+5]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.31e+5]\n",
            "Epoch 772: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.31e+5]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.31e+5]\n",
            "Epoch 773: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.31e+5]\n",
            "Epoch 773: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 774: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.31e+5]\n",
            "Epoch 775: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.31e+5]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.31e+5]\n",
            "Epoch 776: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.31e+5]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.31e+5]\n",
            "Epoch 777: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.31e+5]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.31e+5]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.31e+5]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.31e+5]\n",
            "Epoch 779: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.31e+5]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.31e+5]\n",
            "Epoch 780: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.31e+5]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.31e+5]\n",
            "Epoch 781: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.31e+5]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 782: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.31e+5]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.31e+5]\n",
            "Epoch 783: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.31e+5]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.31e+5]\n",
            "Epoch 784: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.31e+5]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 785: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.31e+5]\n",
            "Epoch 786: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.31e+5]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.31e+5]\n",
            "Epoch 787: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.31e+5]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.31e+5]\n",
            "Epoch 788: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.31e+5]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.31e+5]\n",
            "Epoch 789: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.31e+5]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 790: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.31e+5]\n",
            "Epoch 791: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.31e+5]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 792: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 793: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 794: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.31e+5]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.31e+5]\n",
            "Epoch 795: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.31e+5]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 796: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.31e+5]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 797: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.31e+5]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.31e+5]\n",
            "Epoch 798: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.31e+5]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.31e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.31e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.296, valid_loss=3.31e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.39e+5]\n",
            "Epoch 800: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.39e+5]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.39e+5]\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.39e+5]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 802: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.39e+5]\n",
            "Epoch 803: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.39e+5]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.39e+5]\n",
            "Epoch 804: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.39e+5]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.39e+5]\n",
            "Epoch 805: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.39e+5]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.39e+5]\n",
            "Epoch 806: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.39e+5]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.39e+5]\n",
            "Epoch 807: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.39e+5]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 808: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.39e+5]\n",
            "Epoch 809: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.39e+5]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 810: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.39e+5]\n",
            "Epoch 811: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.39e+5]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.39e+5]\n",
            "Epoch 812: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.39e+5]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.39e+5]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.39e+5]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=3.39e+5]\n",
            "Epoch 814: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=3.39e+5]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.39e+5]\n",
            "Epoch 815: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.39e+5]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.39e+5]\n",
            "Epoch 816: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.39e+5]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.39e+5]\n",
            "Epoch 817: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.39e+5]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.39e+5]\n",
            "Epoch 818: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.39e+5]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.39e+5]\n",
            "Epoch 819: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.39e+5]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 820: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.39e+5]\n",
            "Epoch 821: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.39e+5]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.39e+5]\n",
            "Epoch 822: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.39e+5]\n",
            "Epoch 822: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.39e+5]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.39e+5]\n",
            "Epoch 823: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.39e+5]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.39e+5]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.39e+5]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 825: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.39e+5]\n",
            "Epoch 826: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.39e+5]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.39e+5]\n",
            "Epoch 827: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.39e+5]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.39e+5]\n",
            "Epoch 828: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.39e+5]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.39e+5]\n",
            "Epoch 829: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.39e+5]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.39e+5]\n",
            "Epoch 830: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.39e+5]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.39e+5]\n",
            "Epoch 831: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.39e+5]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.39e+5]\n",
            "Epoch 832: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.39e+5]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 833: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 834: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.39e+5]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.39e+5]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.39e+5]\n",
            "Epoch 836: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.39e+5]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.39e+5]\n",
            "Epoch 837: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.39e+5]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.39e+5]\n",
            "Epoch 838: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.39e+5]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 839: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 840: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.39e+5]\n",
            "Epoch 841: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.39e+5]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.39e+5]\n",
            "Epoch 842: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.39e+5]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.39e+5]\n",
            "Epoch 843: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.39e+5]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.39e+5]\n",
            "Epoch 844: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.39e+5]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.39e+5]\n",
            "Epoch 845: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.39e+5]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=3.39e+5]\n",
            "Epoch 846: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=3.39e+5]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.39e+5]\n",
            "Epoch 847: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.39e+5]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.39e+5]\n",
            "Epoch 848: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.39e+5]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 849: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.39e+5]\n",
            "Epoch 850: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.39e+5]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.39e+5]\n",
            "Epoch 851: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.39e+5]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 852: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.39e+5]\n",
            "Epoch 853: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.39e+5]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.39e+5]\n",
            "Epoch 854: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.39e+5]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.39e+5]\n",
            "Epoch 855: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.39e+5]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.39e+5]\n",
            "Epoch 856: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.39e+5]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.39e+5]\n",
            "Epoch 857: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.39e+5]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.39e+5]\n",
            "Epoch 858: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.39e+5]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.39e+5]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.39e+5]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 860: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.39e+5]\n",
            "Epoch 861: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.39e+5]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.39e+5]\n",
            "Epoch 862: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.39e+5]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.39e+5]\n",
            "Epoch 863: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.39e+5]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.39e+5]\n",
            "Epoch 864: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.39e+5]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.39e+5]\n",
            "Epoch 865: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.39e+5]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.39e+5]\n",
            "Epoch 866: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.39e+5]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.39e+5]\n",
            "Epoch 867: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.39e+5]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.39e+5]\n",
            "Epoch 868: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.39e+5]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.39e+5]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.39e+5]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.39e+5]\n",
            "Epoch 870: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.39e+5]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.39e+5]\n",
            "Epoch 871: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.39e+5]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 872: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 873: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.39e+5]\n",
            "Epoch 874: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.39e+5]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.39e+5]\n",
            "Epoch 875: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.39e+5]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.39e+5]\n",
            "Epoch 876: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.39e+5]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.39e+5]\n",
            "Epoch 877: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.39e+5]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 878: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.39e+5]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.39e+5]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.39e+5]\n",
            "Epoch 880: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.39e+5]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.39e+5]\n",
            "Epoch 881: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.39e+5]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.39e+5]\n",
            "Epoch 882: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.39e+5]\n",
            "Epoch 882: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.39e+5]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.39e+5]\n",
            "Epoch 883: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.39e+5]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.39e+5]\n",
            "Epoch 884: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.39e+5]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.39e+5]\n",
            "Epoch 885: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.39e+5]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.39e+5]\n",
            "Epoch 886: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.39e+5]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.39e+5]\n",
            "Epoch 887: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.39e+5]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 888: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=3.39e+5]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 889: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.39e+5]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 890: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.39e+5]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.39e+5]\n",
            "Epoch 891: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.39e+5]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 892: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.39e+5]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.39e+5]\n",
            "Epoch 893: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.39e+5]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.39e+5]\n",
            "Epoch 894: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.39e+5]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.39e+5]\n",
            "Epoch 895: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.39e+5]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.39e+5]\n",
            "Epoch 896: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.39e+5]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.39e+5]\n",
            "Epoch 897: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.39e+5]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.39e+5]\n",
            "Epoch 898: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.39e+5]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.39e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.39e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.324, valid_loss=3.39e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:04:30,921\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "2024-04-15 12:04:30,969\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2024-04-15_11-31-13' in 0.0319s.\n",
            "2024-04-15 12:04:30,982\tERROR tune.py:1044 -- Trials did not complete: [_train_tune_f2b602aa]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=48198)\u001b[0m \r                                                                      \u001b[A\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.324, valid_loss=3.46e+5]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.46e+5]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.46e+5]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 1\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                    | Type                     | Params\n",
            "---------------------------------------------------------------------\n",
            "0 | loss                    | MSE                      | 0     \n",
            "1 | valid_loss              | MSE                      | 0     \n",
            "2 | padder_train            | ConstantPad1d            | 0     \n",
            "3 | scaler                  | TemporalNorm             | 0     \n",
            "4 | embedding               | TFTEmbedding             | 2.0 K \n",
            "5 | static_encoder          | StaticCovariateEncoder   | 331 K \n",
            "6 | temporal_encoder        | TemporalCovariateEncoder | 1.1 M \n",
            "7 | temporal_fusion_decoder | TemporalFusionDecoder    | 256 K \n",
            "8 | output_adapter          | Linear                   | 129   \n",
            "---------------------------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "6.834     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2da55f14dc0a437393217d20c53686d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89fde10ce594480480f6183b430f96a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96cfb0c9664641b685c7c20774d0c5ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a2eeaa58dd24a05b7d609e3bb1a2bb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28b2a575b3c445e7ad2a9e1767834f19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e6ab6d506b44556a7167a8d9e1fb4db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86898c8037dd444d9ae70d1ac948abf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8072c4d95444ddfa631c7da81cdcae5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29d3389e4973405ab5f12145742e991e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f09978559b214939aa9f9023e92c4a2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18e69d6698d9473d84b5c051b3578731",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a688c6040e340e8912a5b98b3f8a082",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94ecb5285f8b4daa858a36548d17ce24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:07:26,812\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2024-04-15_12-07-26   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator                   |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 10                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2024-04-15_12-07-26\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/driver_artifacts`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=50807)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_1ddb380e_1_batch_size=32,context_size=10,decoder_hidden_size=128,encoder_hidden_size=20,h=5,learning_rate=0.0003,loss=_2024-04-15_12-07-26/lightning_logs\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 2024-04-15 12:07:40.809351: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 2024-04-15 12:07:40.809409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 2024-04-15 12:07:40.811246: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 2024-04-15 12:07:42.757637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 3.3 K \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 5 | context_adapter | Linear                     | 1.1 K \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 6 | mlp_decoder     | MLP                        | 1.5 K \n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 5.9 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 5.9 K     Total params\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m 0.024     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:02<00:00,  0.48it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=50807)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, v_num=0, train_loss_step=106.0]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 81.09it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 78.86it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 74.84it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 96.78it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 93.40it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 87.57it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 90.53it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 87.52it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 82.81it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 94.17it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 91.14it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 85.70it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 97.45it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 93.64it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 86.41it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 92.88it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 89.81it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 45.91it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 71.96it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 64.04it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=0, train_loss_step=99.90, train_loss_epoch=99.90]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s, v_num=0, train_loss_step=99.50, train_loss_epoch=99.50]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 41.24it/s, v_num=0, train_loss_step=99.10, train_loss_epoch=99.50]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=97.70, train_loss_epoch=97.70]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.10, train_loss_epoch=95.10]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=91.50, train_loss_epoch=91.50]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=86.60, train_loss_epoch=86.60]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=79.90, train_loss_epoch=79.90]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.60, train_loss_epoch=68.60]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=57.10, train_loss_epoch=57.10]\n",
            "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 47.18it/s, v_num=0, train_loss_step=53.90, train_loss_epoch=57.10]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.90, train_loss_epoch=53.90]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.30, train_loss_epoch=40.30]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 51.19it/s, v_num=0, train_loss_step=40.30, train_loss_epoch=40.30]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.90, train_loss_epoch=36.90]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.80, train_loss_epoch=24.80]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 41.02it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 53.61it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.50]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 32.42it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 56.93it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.80]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.85it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=5.46e+6]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=5.46e+6]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.780, train_loss_epoch=8.780, valid_loss=5.46e+6]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.150, train_loss_epoch=7.150, valid_loss=5.46e+6]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.230, train_loss_epoch=6.230, valid_loss=5.46e+6]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.730, train_loss_epoch=5.730, valid_loss=5.46e+6]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.500, train_loss_epoch=5.500, valid_loss=5.46e+6]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 61.78it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.250, valid_loss=5.46e+6]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 92.24it/s, v_num=0, train_loss_step=5.010, train_loss_epoch=5.010, valid_loss=5.46e+6]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.680, train_loss_epoch=4.680, valid_loss=5.46e+6]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.540, train_loss_epoch=4.540, valid_loss=5.46e+6]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.490, train_loss_epoch=4.490, valid_loss=5.46e+6]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.120, train_loss_epoch=4.120, valid_loss=5.46e+6]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070, valid_loss=5.46e+6]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780, valid_loss=5.46e+6]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 51.24it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=5.46e+6]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.490, train_loss_epoch=3.490, valid_loss=5.46e+6]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=5.46e+6]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=5.46e+6]\n",
            "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 82.35it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=5.46e+6]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 85.84it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.420, valid_loss=5.46e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.30it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=5.64e+5]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 63.74it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=5.64e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=5.64e+5]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 80.77it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=5.64e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=5.64e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=5.64e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=5.64e+5]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 43.42it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.64e+5]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 83.37it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.750, valid_loss=5.64e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=5.64e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=5.64e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 67.65it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=5.64e+5]\n",
            "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 42.11it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=5.64e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 88.03it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=5.64e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=5.64e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=5.64e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=5.64e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=5.64e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 89.01it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=5.64e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.40it/s]\u001b[A\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 28.88it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=4.06e+5]\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=4.06e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=4.06e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=4.06e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=4.06e+5]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 87.59it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=4.06e+5]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=4.06e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 90.25it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=4.06e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 85.05it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=4.06e+5]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 78.26it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=4.06e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=4.06e+5]        \n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=4.06e+5]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=4.06e+5]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=4.06e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=4.06e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=4.06e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=4.06e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=4.06e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=4.06e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 82.83it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=4.06e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.75it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.67e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 39.04it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.67e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.67e+5]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 65.00it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.67e+5]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.67e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.67e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.67e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.67e+5]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.67e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.67e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.67e+5]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.67e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.67e+5]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.67e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.67e+5]\n",
            "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 48.22it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.67e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 90.18it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.67e+5]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 49.09it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.67e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.67e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.67e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 91.15it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.67e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.54it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.74e+5]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.74e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.74e+5]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.74e+5]        \n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.74e+5]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.74e+5]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.74e+5]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.74e+5]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.74e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 84.81it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.74e+5]\n",
            "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 46.59it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.74e+5]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00, 97.28it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.74e+5]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.74e+5]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.74e+5]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00, 88.92it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.74e+5]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.74e+5]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.74e+5]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.74e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.74e+5]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:00<00:00, 45.24it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.74e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.74e+5]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:00<00:00, 51.32it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.74e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 85.51it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.74e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.66it/s]\u001b[A\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.79e+5]\n",
            "Epoch 605: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.79e+5]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.79e+5]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.79e+5]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.79e+5]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.79e+5]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.79e+5]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.79e+5]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.79e+5]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.79e+5]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 74.88it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 658: 100%|██████████| 1/1 [00:00<00:00, 61.63it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.79e+5]\n",
            "Epoch 665: 100%|██████████| 1/1 [00:00<00:00, 55.16it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 673: 100%|██████████| 1/1 [00:00<00:00, 71.75it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 680: 100%|██████████| 1/1 [00:00<00:00, 85.71it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]        \n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.79e+5]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.79e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 80.24it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.79e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.46it/s]\u001b[A\n",
            "Epoch 700: 100%|██████████| 1/1 [00:00<00:00, 47.94it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.82e+5]\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.82e+5]        \n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.82e+5]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.82e+5]\n",
            "Epoch 707: 100%|██████████| 1/1 [00:00<00:00, 50.38it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.82e+5]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.82e+5]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.82e+5]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.82e+5]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.82e+5]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.82e+5]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.82e+5]\n",
            "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 89.05it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.82e+5]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.82e+5]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.82e+5]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=3.82e+5]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=3.82e+5]\n",
            "Epoch 759: 100%|██████████| 1/1 [00:00<00:00, 48.95it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=3.82e+5]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=3.82e+5]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=3.82e+5]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=3.82e+5]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=3.82e+5]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=3.82e+5]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=3.82e+5]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=3.82e+5]\n",
            "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 66.24it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=3.82e+5]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=3.82e+5]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=3.82e+5]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=3.82e+5]\n",
            "Epoch 798: 100%|██████████| 1/1 [00:00<00:00, 38.27it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=3.82e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 50.54it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.980, valid_loss=3.82e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.02it/s]\u001b[A\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=3.84e+5]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=3.84e+5]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=3.84e+5]\n",
            "Epoch 818: 100%|██████████| 1/1 [00:00<00:00, 44.38it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=3.84e+5]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=3.84e+5]\n",
            "Epoch 823: 100%|██████████| 1/1 [00:00<00:00, 61.45it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=3.84e+5]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=3.84e+5]\n",
            "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 56.14it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=3.84e+5]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=3.84e+5]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=3.84e+5]\n",
            "Epoch 830: 100%|██████████| 1/1 [00:00<00:00, 58.26it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=3.84e+5]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=3.84e+5]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00, 58.37it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=3.84e+5]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=3.84e+5]\n",
            "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 59.44it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=3.84e+5]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=3.84e+5]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=3.84e+5]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=3.84e+5]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=3.84e+5]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=3.84e+5]\n",
            "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 37.37it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=3.84e+5]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=3.84e+5]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=3.84e+5]\n",
            "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 47.57it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=3.84e+5]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=3.84e+5]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=3.84e+5]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=3.84e+5]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 38.43it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=3.84e+5]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=3.84e+5]\n",
            "Epoch 890: 100%|██████████| 1/1 [00:00<00:00, 75.14it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=3.84e+5]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=3.84e+5]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=3.84e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 93.60it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.946, valid_loss=3.84e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.60it/s]\u001b[A\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 55.04it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=3.85e+5]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=3.85e+5]\n",
            "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 63.05it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=3.85e+5]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 70.73it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=3.85e+5]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 46.27it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=3.85e+5]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 27.29it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=3.85e+5]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=3.85e+5]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=3.85e+5]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=3.85e+5]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=3.85e+5]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=3.85e+5]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=3.85e+5]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=3.85e+5]\n",
            "Epoch 950: 100%|██████████| 1/1 [00:00<00:00, 81.89it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=3.85e+5]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=3.85e+5]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=3.85e+5]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=3.85e+5]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=3.85e+5]\n",
            "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 51.72it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=3.85e+5]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=3.85e+5]\n",
            "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 42.15it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=3.85e+5]\n",
            "Epoch 984: 100%|██████████| 1/1 [00:00<00:00, 63.76it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=3.85e+5]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=3.85e+5]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:08:07,732\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 42.77it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 42.06it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 40.84it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 80.13it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 77.94it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 74.06it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 67.88it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 66.09it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.911, valid_loss=3.85e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 63.31it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 81.77it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 79.23it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.54it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50807)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 29.34it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 28.47it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 27.20it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=3.85e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51021)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_2f2559c2_2_batch_size=32,context_size=5,decoder_hidden_size=64,encoder_hidden_size=100,h=5,learning_rate=0.0000,loss=r_2024-04-15_12-07-38/lightning_logs\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 2024-04-15 12:08:20.951852: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 2024-04-15 12:08:20.951908: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 2024-04-15 12:08:20.968276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 2024-04-15 12:08:23.182611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 80.7 K\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 5 | context_adapter | Linear                     | 2.5 K \n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 6 | mlp_decoder     | MLP                        | 449   \n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 83.7 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 83.7 K    Total params\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m 0.335     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51021)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=0, train_loss_step=106.0]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 68.80it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 66.90it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 64.04it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 50.51it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 49.44it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 47.78it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 83.79it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 81.08it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 77.16it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 85.84it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 82.80it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 78.29it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 47.73it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 46.77it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 44.87it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 84.75it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 82.04it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 90.99it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 88.13it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 83.06it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 98.12it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 94.59it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 89.33it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 87.68it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 84.94it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 80.01it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 95.73it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 92.40it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 86.67it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 11: 100%|██████████| 1/1 [00:00<00:00, 92.45it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 11: 100%|██████████| 1/1 [00:00<00:00, 89.52it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 11: 100%|██████████| 1/1 [00:00<00:00, 84.45it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 69.63it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 49.16it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 93.18it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.91it/s]\u001b[A\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 86.62it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0, valid_loss=6.2e+7]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0, valid_loss=6.2e+7]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=99.80, train_loss_epoch=99.80, valid_loss=6.2e+7]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 45.58it/s, v_num=0, train_loss_step=99.80, train_loss_epoch=99.80, valid_loss=6.2e+7]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 81.12it/s, v_num=0, train_loss_step=97.70, train_loss_epoch=97.70, valid_loss=6.2e+7]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=97.70, train_loss_epoch=97.70, valid_loss=6.2e+7]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=96.10, train_loss_epoch=96.10, valid_loss=6.2e+7]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=93.40, train_loss_epoch=93.40, valid_loss=6.2e+7]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=89.60, train_loss_epoch=89.60, valid_loss=6.2e+7]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=85.50, train_loss_epoch=85.50, valid_loss=6.2e+7]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=80.70, train_loss_epoch=80.70, valid_loss=6.2e+7]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=75.10, train_loss_epoch=75.10, valid_loss=6.2e+7]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.50, train_loss_epoch=68.50, valid_loss=6.2e+7]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=61.10, train_loss_epoch=61.10, valid_loss=6.2e+7]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=51.70, train_loss_epoch=51.70, valid_loss=6.2e+7]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.20, train_loss_epoch=49.20, valid_loss=6.2e+7]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.00, train_loss_epoch=43.00, valid_loss=6.2e+7]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 91.56it/s, v_num=0, train_loss_step=40.50, train_loss_epoch=41.80, valid_loss=6.2e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.38it/s]\u001b[A\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.60, train_loss_epoch=35.60, valid_loss=2.28e+7]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 84.41it/s, v_num=0, train_loss_step=26.40, train_loss_epoch=26.40, valid_loss=2.28e+7]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60, valid_loss=2.28e+7]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=2.28e+7]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=2.28e+7]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.210, train_loss_epoch=9.210, valid_loss=2.28e+7]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.210, train_loss_epoch=8.210, valid_loss=2.28e+7]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 79.78it/s, v_num=0, train_loss_step=7.370, train_loss_epoch=7.370, valid_loss=2.28e+7]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.890, train_loss_epoch=6.890, valid_loss=2.28e+7]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.450, train_loss_epoch=6.450, valid_loss=2.28e+7]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.190, train_loss_epoch=6.190, valid_loss=2.28e+7]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.030, train_loss_epoch=6.030, valid_loss=2.28e+7]\n",
            "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 40.94it/s, v_num=0, train_loss_step=6.010, train_loss_epoch=6.010, valid_loss=2.28e+7]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.010, train_loss_epoch=6.010, valid_loss=2.28e+7]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.870, train_loss_epoch=5.870, valid_loss=2.28e+7]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750, valid_loss=2.28e+7]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 43.71it/s, v_num=0, train_loss_step=5.730, train_loss_epoch=5.730, valid_loss=2.28e+7]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 91.17it/s, v_num=0, train_loss_step=5.700, train_loss_epoch=5.710, valid_loss=2.28e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.77it/s]\u001b[A\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650, valid_loss=1.15e+6]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=1.15e+6]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.460, valid_loss=1.15e+6]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350, valid_loss=1.15e+6]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.260, train_loss_epoch=5.260, valid_loss=1.15e+6]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=1.15e+6]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 84.13it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.080, valid_loss=1.15e+6]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 44.66it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=1.15e+6]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.040, train_loss_epoch=5.040, valid_loss=1.15e+6]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970, valid_loss=1.15e+6]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.850, train_loss_epoch=4.850, valid_loss=1.15e+6]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.740, train_loss_epoch=4.740, valid_loss=1.15e+6]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 69.37it/s, v_num=0, train_loss_step=4.620, train_loss_epoch=4.620, valid_loss=1.15e+6]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.620, train_loss_epoch=4.620, valid_loss=1.15e+6]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.520, train_loss_epoch=4.520, valid_loss=1.15e+6]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.380, valid_loss=1.15e+6]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.270, train_loss_epoch=4.270, valid_loss=1.15e+6]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 85.81it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.180, valid_loss=1.15e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.66it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=8.51e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=8.51e+5]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 58.14it/s, v_num=0, train_loss_step=3.920, train_loss_epoch=3.920, valid_loss=8.51e+5]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=8.51e+5]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=8.51e+5]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=8.51e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=8.51e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=8.51e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=8.51e+5]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=8.51e+5]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=8.51e+5]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=8.51e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=8.51e+5]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=8.51e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 92.97it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.610, valid_loss=8.51e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.85it/s]\u001b[A\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 32.77it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.610, valid_loss=5.79e+5]\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=5.79e+5]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=5.79e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=5.79e+5]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=5.79e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00, 49.61it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.390, valid_loss=5.79e+5]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00, 31.47it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=5.79e+5]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=5.79e+5]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=5.79e+5]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=5.79e+5]\n",
            "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 37.88it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=5.79e+5]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=5.79e+5]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00, 52.79it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=5.79e+5]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=5.79e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=5.79e+5]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=5.79e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=5.79e+5]\n",
            "Epoch 575: 100%|██████████| 1/1 [00:00<00:00, 62.09it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=5.79e+5]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=5.79e+5]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 80.40it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=5.79e+5]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=5.79e+5]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=5.79e+5]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=5.79e+5]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=5.79e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 73.93it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.950, valid_loss=5.79e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.40it/s]\u001b[A\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=4.6e+5]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=4.6e+5]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=4.6e+5]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=4.6e+5]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.6e+5]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=4.6e+5]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=4.6e+5]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=4.6e+5]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.6e+5]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=4.6e+5]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=4.6e+5]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=4.6e+5]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=4.6e+5]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=4.6e+5]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=4.6e+5]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.6e+5]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=4.6e+5]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=4.6e+5]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=4.6e+5]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=4.6e+5]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=4.6e+5]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=4.6e+5]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=4.6e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 63.91it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=4.6e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.14it/s]\u001b[A\n",
            "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 47.93it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=4.06e+5]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=4.06e+5]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.06e+5]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=4.06e+5]\n",
            "Epoch 718: 100%|██████████| 1/1 [00:00<00:00, 57.36it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.620, valid_loss=4.06e+5]\n",
            "Epoch 718: 100%|██████████| 1/1 [00:00<00:00, 29.97it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.06e+5]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.06e+5]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.06e+5]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=4.06e+5]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=4.06e+5]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=4.06e+5]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=4.06e+5]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=4.06e+5]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=4.06e+5]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=4.06e+5]\n",
            "Epoch 747: 100%|██████████| 1/1 [00:00<00:00, 38.55it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.06e+5]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.06e+5]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.06e+5]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.06e+5]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.06e+5]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.06e+5]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=4.06e+5]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=4.06e+5]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=4.06e+5]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=4.06e+5]\n",
            "Epoch 788: 100%|██████████| 1/1 [00:00<00:00, 50.14it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=4.06e+5]\n",
            "Epoch 788: 100%|██████████| 1/1 [00:00<00:00, 29.60it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=4.06e+5]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=4.06e+5]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=4.06e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 67.29it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=4.06e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.53it/s]\u001b[A\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 43.41it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.84e+5]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.84e+5]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.84e+5]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.84e+5]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.84e+5]\n",
            "Epoch 827: 100%|██████████| 1/1 [00:00<00:00, 72.45it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.84e+5]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.84e+5]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.84e+5]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.84e+5]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.84e+5]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.84e+5]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.84e+5]\n",
            "Epoch 861: 100%|██████████| 1/1 [00:00<00:00, 59.24it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.84e+5]\n",
            "Epoch 861: 100%|██████████| 1/1 [00:00<00:00, 56.67it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.84e+5]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.84e+5]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.84e+5]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.84e+5]\n",
            "Epoch 883: 100%|██████████| 1/1 [00:00<00:00, 47.31it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=3.84e+5]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.84e+5]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.84e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 88.54it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.84e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.21it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.77e+5]\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 27.66it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.77e+5]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.77e+5]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.77e+5]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.77e+5]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.77e+5]\n",
            "Epoch 927: 100%|██████████| 1/1 [00:00<00:00, 47.57it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.77e+5]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.77e+5]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.77e+5]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.77e+5]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.77e+5]\n",
            "Epoch 953: 100%|██████████| 1/1 [00:00<00:00, 45.15it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.77e+5]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.77e+5]        \n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.77e+5]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.77e+5]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.77e+5]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.77e+5]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.77e+5]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.77e+5]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:08:47,221\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 39.38it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 38.74it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 37.64it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]        \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 93.81it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 90.26it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 85.04it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]        \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 88.72it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 85.84it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 80.54it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 87.43it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 84.43it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 79.25it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 84.13it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 81.42it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 76.70it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 69.08it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 67.24it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.77e+5]\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.68it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 26.50it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.79e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 25.73it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.79e+5]\n",
            "\u001b[36m(_train_tune pid=51021)\u001b[0m \rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 18.91it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.79e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51021)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_571aa5b7_3_batch_size=32,context_size=5,decoder_hidden_size=64,encoder_hidden_size=200,h=5,learning_rate=0.0000,loss=r_2024-04-15_12-08-17/lightning_logs\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 2024-04-15 12:09:04.026925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 2024-04-15 12:09:04.026986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 2024-04-15 12:09:04.028857: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 2024-04-15 12:09:05.965122: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 321 K \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 5 | context_adapter | Linear                     | 5.0 K \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 6 | mlp_decoder     | MLP                        | 449   \n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 326 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 326 K     Total params\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m 1.307     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51230)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=0, train_loss_step=106.0]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 74.80it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 71.10it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 67.39it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 79.79it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 73.43it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 66.38it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 44.07it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 74.72it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=100.0, train_loss_epoch=100.0]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.50, train_loss_epoch=98.50]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=96.30, train_loss_epoch=96.30]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=93.40, train_loss_epoch=93.40]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 83.46it/s, v_num=0, train_loss_step=91.90, train_loss_epoch=92.40]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.37it/s]\u001b[A\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=90.80, train_loss_epoch=90.80, valid_loss=5.49e+7]\n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 78.96it/s, v_num=0, train_loss_step=90.30, train_loss_epoch=90.30, valid_loss=5.49e+7]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=89.70, train_loss_epoch=89.70, valid_loss=5.49e+7]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=89.10, train_loss_epoch=89.10, valid_loss=5.49e+7]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.40, train_loss_epoch=88.40, valid_loss=5.49e+7]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=83.30, train_loss_epoch=83.30, valid_loss=5.49e+7]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.70, train_loss_epoch=76.70, valid_loss=5.49e+7]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.70, train_loss_epoch=68.70, valid_loss=5.49e+7]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 40.88it/s, v_num=0, train_loss_step=68.70, train_loss_epoch=68.70, valid_loss=5.49e+7]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=62.10, train_loss_epoch=62.10, valid_loss=5.49e+7]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 36.32it/s, v_num=0, train_loss_step=62.10, train_loss_epoch=62.10, valid_loss=5.49e+7]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.70, train_loss_epoch=60.70, valid_loss=5.49e+7]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=50.00, train_loss_epoch=50.00, valid_loss=5.49e+7]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 66.56it/s, v_num=0, train_loss_step=48.40, train_loss_epoch=48.40, valid_loss=5.49e+7]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.40, train_loss_epoch=48.40, valid_loss=5.49e+7]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.70, train_loss_epoch=38.70, valid_loss=5.49e+7]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 49.59it/s, v_num=0, train_loss_step=37.00, train_loss_epoch=38.70, valid_loss=5.49e+7]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 27.09it/s, v_num=0, train_loss_step=37.00, train_loss_epoch=37.00, valid_loss=5.49e+7]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.50, train_loss_epoch=27.50, valid_loss=5.49e+7]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90, valid_loss=5.49e+7]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 49.23it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=17.10, valid_loss=5.49e+7]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=5.49e+7]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=5.49e+7]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 22.06it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=5.49e+7]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=5.49e+7]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 27.00it/s, v_num=0, train_loss_step=9.840, train_loss_epoch=9.840, valid_loss=5.49e+7]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.840, train_loss_epoch=9.840, valid_loss=5.49e+7]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 56.48it/s, v_num=0, train_loss_step=8.940, train_loss_epoch=8.940, valid_loss=5.49e+7]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 45.50it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=8.790, valid_loss=5.49e+7]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=8.790, valid_loss=5.49e+7]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 49.56it/s, v_num=0, train_loss_step=8.410, train_loss_epoch=8.410, valid_loss=5.49e+7]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 69.42it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.820, valid_loss=5.49e+7]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.240, train_loss_epoch=7.240, valid_loss=5.49e+7]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.850, train_loss_epoch=6.850, valid_loss=5.49e+7]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=5.49e+7]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 45.41it/s, v_num=0, train_loss_step=6.500, train_loss_epoch=6.560, valid_loss=5.49e+7]\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.67it/s]\u001b[A\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=1.54e+6]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.140, train_loss_epoch=6.140, valid_loss=1.54e+6]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960, valid_loss=1.54e+6]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.830, train_loss_epoch=5.830, valid_loss=1.54e+6]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.720, train_loss_epoch=5.720, valid_loss=1.54e+6]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=1.54e+6]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.500, train_loss_epoch=5.500, valid_loss=1.54e+6]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.380, train_loss_epoch=5.380, valid_loss=1.54e+6]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.290, train_loss_epoch=5.290, valid_loss=1.54e+6]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=1.54e+6]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 34.14it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=1.54e+6]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.080, train_loss_epoch=5.080, valid_loss=1.54e+6]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=1.54e+6]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.040, train_loss_epoch=5.040, valid_loss=1.54e+6]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970, valid_loss=1.54e+6]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880, valid_loss=1.54e+6]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 88.00it/s, v_num=0, train_loss_step=4.860, train_loss_epoch=4.860, valid_loss=1.54e+6]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=4.840, valid_loss=1.54e+6]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.810, train_loss_epoch=4.810, valid_loss=1.54e+6]\n",
            "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 72.60it/s, v_num=0, train_loss_step=4.790, train_loss_epoch=4.790, valid_loss=1.54e+6]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=4.690, valid_loss=1.54e+6]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.620, train_loss_epoch=4.620, valid_loss=1.54e+6]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.500, train_loss_epoch=4.500, valid_loss=1.54e+6]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.410, train_loss_epoch=4.410, valid_loss=1.54e+6]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.290, train_loss_epoch=4.290, valid_loss=1.54e+6]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.180, train_loss_epoch=4.180, valid_loss=1.54e+6]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.100, train_loss_epoch=4.100, valid_loss=1.54e+6]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070, valid_loss=1.54e+6]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 48.11it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=1.54e+6]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 50.75it/s, v_num=0, train_loss_step=3.890, train_loss_epoch=3.890, valid_loss=1.54e+6]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 52.54it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.870, valid_loss=1.54e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.80it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.850, valid_loss=8.47e+5]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=8.47e+5]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=8.47e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=8.47e+5]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560, valid_loss=8.47e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470, valid_loss=8.47e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=8.47e+5]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 34.16it/s, v_num=0, train_loss_step=3.370, train_loss_epoch=3.370, valid_loss=8.47e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.290, train_loss_epoch=3.290, valid_loss=8.47e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=8.47e+5]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=8.47e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=8.47e+5]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=8.47e+5]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 42.26it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=8.47e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=8.47e+5]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=8.47e+5]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 52.10it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.730, valid_loss=8.47e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=8.47e+5]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=8.47e+5]\n",
            "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 33.45it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=8.47e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=8.47e+5]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=8.47e+5]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 40.27it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.610, valid_loss=8.47e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=8.47e+5]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=8.47e+5]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 56.29it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=8.47e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=8.47e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=8.47e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=8.47e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 55.48it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.380, valid_loss=8.47e+5]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 53.02it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=8.47e+5]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=8.47e+5]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=8.47e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=8.47e+5]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 36.24it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=8.47e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=8.47e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 50.55it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.270, valid_loss=8.47e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.14it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=5.43e+5]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=5.43e+5]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 59.25it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=5.43e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=5.43e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=5.43e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=5.43e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=5.43e+5]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 81.80it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=5.43e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=5.43e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=5.43e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=5.43e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 63.90it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=5.43e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=5.43e+5]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=5.43e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:09:21,304\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 45.40it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 44.15it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 42.62it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]        \rEpoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 86.88it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 80.94it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 76.48it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]        \rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 92.45it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 84.31it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.800, valid_loss=5.43e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 79.52it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]        \rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 78.53it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 73.21it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 69.62it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]        \rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 81.64it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 78.20it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.790, valid_loss=5.43e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 73.40it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]        \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 73.75it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 68.74it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 65.27it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]        \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 42.39it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 41.61it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 40.33it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]        \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 82.44it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 76.00it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.780, valid_loss=5.43e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 71.85it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]        \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 85.57it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 80.18it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]        \rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 93.21it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 85.55it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.770, valid_loss=5.43e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 80.91it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]        \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 67.26it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 65.49it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 62.34it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]        \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 82.64it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 77.66it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 73.57it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 93.84it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 86.30it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.760, valid_loss=5.43e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 81.45it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 73.45it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 71.53it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51230)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 76.67it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.43e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 74.13it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.750, valid_loss=5.43e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 70.48it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=5.43e+5]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=5.43e+5]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=5.43e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 88.44it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=5.43e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 82.65it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=5.43e+5]\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.53it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51230)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 32.38it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.26e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 31.28it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.26e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 30.12it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.26e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51410)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_4b436eb4_4_batch_size=16,context_size=5,decoder_hidden_size=64,encoder_hidden_size=100,h=5,learning_rate=0.0114,loss=r_2024-04-15_12-09-01/lightning_logs\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 2024-04-15 12:09:35.214305: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 2024-04-15 12:09:35.214367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 2024-04-15 12:09:35.216041: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 2024-04-15 12:09:37.766804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 80.7 K\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 5 | context_adapter | Linear                     | 2.5 K \n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 6 | mlp_decoder     | MLP                        | 449   \n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 83.7 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 83.7 K    Total params\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m 0.335     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51410)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=52.90, train_loss_epoch=52.90]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 67.68it/s, v_num=0, train_loss_step=19.50, train_loss_epoch=19.50]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 82.00it/s, v_num=0, train_loss_step=92.60, train_loss_epoch=93.40]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.50, train_loss_epoch=42.50]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 77.67it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.650, train_loss_epoch=6.650]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 62.59it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 43.22it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 60.65it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.540]\n",
            "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 35.29it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 70.85it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 41.05it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 81.73it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.320]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.56it/s]\u001b[A\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.45e+5]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.45e+5]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.45e+5]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.45e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.45e+5]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:00<00:00, 81.12it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.45e+5]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.45e+5]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.45e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 75.52it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.45e+5]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 41.53it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.45e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.45e+5]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 84.17it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.45e+5]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.45e+5]\n",
            "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 34.51it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.45e+5]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.45e+5]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 36.55it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.45e+5]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.45e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.45e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.45e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 85.50it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.45e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.57it/s]\u001b[A\n",
            "Epoch 202: 100%|██████████| 1/1 [00:00<00:00, 85.31it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.61e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.61e+5]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 74.58it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.61e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.61e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.61e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.61e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.61e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.61e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.61e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.61e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.61e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.61e+5]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 46.07it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.61e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.61e+5]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 38.90it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=3.61e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.61e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.61e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 63.55it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.61e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.71it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 74.46it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.8e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.8e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 41.55it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.8e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.8e+5]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.8e+5]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 51.16it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.8e+5]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.8e+5]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.8e+5]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 73.65it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.8e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.8e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.8e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=3.8e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.8e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=3.8e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=3.8e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=3.8e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=3.8e+5]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=3.8e+5]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 25.34it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=3.8e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=3.8e+5]\n",
            "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 34.51it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=3.8e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=3.8e+5]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.8e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 84.01it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.150, valid_loss=3.8e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.50it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=4.54e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=4.54e+5]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=4.54e+5]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=4.54e+5]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=4.54e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.54e+5]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 52.03it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=4.54e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=4.54e+5]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=4.54e+5]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=4.54e+5]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=4.54e+5]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=4.54e+5]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 84.46it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=4.54e+5]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=4.54e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=4.54e+5]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=4.54e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=4.54e+5]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=4.54e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:09:50,643\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rEpoch 482: 100%|██████████| 1/1 [00:00<00:00, 43.54it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=4.54e+5]\rEpoch 482: 100%|██████████| 1/1 [00:00<00:00, 42.82it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=0.964, valid_loss=4.54e+5]\rEpoch 482: 100%|██████████| 1/1 [00:00<00:00, 41.64it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=4.54e+5]\rEpoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=4.54e+5]        \rEpoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=4.54e+5]\rEpoch 483: 100%|██████████| 1/1 [00:00<00:00, 96.16it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=4.54e+5]\rEpoch 483: 100%|██████████| 1/1 [00:00<00:00, 92.83it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=1.010, valid_loss=4.54e+5]\rEpoch 483: 100%|██████████| 1/1 [00:00<00:00, 86.78it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=4.54e+5]\rEpoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=4.54e+5]        \rEpoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=4.54e+5]\rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 98.74it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=4.54e+5]\rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 95.04it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.958, valid_loss=4.54e+5]\rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 89.43it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]        \rEpoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 99.43it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 96.02it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=4.54e+5]\rEpoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=4.54e+5]        \rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=4.54e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 101.30it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=4.54e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 97.48it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.947, valid_loss=4.54e+5] \rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 91.55it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=4.54e+5]\rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=4.54e+5]        \rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=4.54e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 67.29it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=4.54e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 65.57it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.970, valid_loss=4.54e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 62.71it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=4.54e+5]\rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=4.54e+5]        \rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=4.54e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 71.65it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=4.54e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 69.86it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.954, valid_loss=4.54e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 66.66it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=4.54e+5]\rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=4.54e+5]        \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=4.54e+5]\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 44.20it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=4.54e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 43.49it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.919, valid_loss=4.54e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 42.24it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]        \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 91.78it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 88.82it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 83.95it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.54e+5]\rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.54e+5]        \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.54e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 101.74it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.54e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 97.94it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.950, valid_loss=4.54e+5] \rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 92.02it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=4.54e+5]\rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=4.54e+5]        \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=4.54e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 98.72it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=4.54e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 95.39it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.942, valid_loss=4.54e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 89.83it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]        \rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 99.63it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 96.27it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.920, valid_loss=4.54e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 90.45it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.54e+5]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.54e+5]        \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.54e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 96.73it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.54e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 93.05it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.913, valid_loss=4.54e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 86.84it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=4.54e+5]\rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=4.54e+5]        \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=4.54e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 63.40it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=4.54e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 61.90it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.929, valid_loss=4.54e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 59.25it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=4.54e+5]\rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=4.54e+5]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=4.54e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51410)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 41.23it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=4.54e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 35.81it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.939, valid_loss=4.54e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 34.85it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 88.79it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 85.55it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.924, valid_loss=4.54e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 80.86it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=4.54e+5]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=4.54e+5]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=4.54e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 95.68it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=4.54e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 92.46it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.911, valid_loss=4.54e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 85.75it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.54e+5]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.54e+5]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.54e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 95.24it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.54e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 91.92it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.910, valid_loss=4.54e+5]\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.65it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51410)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 34.37it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.910, valid_loss=4.18e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 33.02it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.18e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 31.56it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.18e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51578)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_30f6bf29_5_batch_size=32,context_size=10,decoder_hidden_size=64,encoder_hidden_size=20,h=5,learning_rate=0.0001,loss=r_2024-04-15_12-09-32/lightning_logs\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 2024-04-15 12:10:00.426638: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 2024-04-15 12:10:00.426717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 2024-04-15 12:10:00.427988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 2024-04-15 12:10:01.651591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 3.3 K \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 5 | context_adapter | Linear                     | 1.1 K \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 6 | mlp_decoder     | MLP                        | 769   \n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 5.2 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 5.2 K     Total params\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m 0.021     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51578)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 72.21it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 53.85it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 52.81it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 94.26it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 91.07it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 32.65it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 100.17it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 67.97it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.73it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0, valid_loss=6.23e+7]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 43.45it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0, valid_loss=6.23e+7]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0, valid_loss=6.23e+7]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0, valid_loss=6.23e+7]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0, valid_loss=6.23e+7]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0, valid_loss=6.23e+7]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=99.70, train_loss_epoch=99.70, valid_loss=6.23e+7]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=97.70, train_loss_epoch=97.70, valid_loss=6.23e+7]\n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 99.94it/s, v_num=0, train_loss_step=95.50, train_loss_epoch=95.80, valid_loss=6.23e+7] \n",
            "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 93.91it/s, v_num=0, train_loss_step=95.50, train_loss_epoch=95.50, valid_loss=6.23e+7]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.10, train_loss_epoch=95.10, valid_loss=6.23e+7]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=92.70, train_loss_epoch=92.70, valid_loss=6.23e+7]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=89.20, train_loss_epoch=89.20, valid_loss=6.23e+7]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 44.63it/s, v_num=0, train_loss_step=84.90, train_loss_epoch=84.90, valid_loss=6.23e+7]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=81.30, train_loss_epoch=81.30, valid_loss=6.23e+7]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=80.50, train_loss_epoch=80.50, valid_loss=6.23e+7]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=75.50, train_loss_epoch=75.50, valid_loss=6.23e+7]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=74.60, train_loss_epoch=74.60, valid_loss=6.23e+7]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=67.70, train_loss_epoch=67.70, valid_loss=6.23e+7]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=59.90, train_loss_epoch=59.90, valid_loss=6.23e+7]\n",
            "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s, v_num=0, train_loss_step=52.60, train_loss_epoch=52.60, valid_loss=6.23e+7]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 78.18it/s, v_num=0, train_loss_step=48.80, train_loss_epoch=50.10, valid_loss=6.23e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.94it/s]\u001b[A\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=47.50, train_loss_epoch=47.50, valid_loss=2.79e+7]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=46.20, train_loss_epoch=46.20, valid_loss=2.79e+7]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.80, train_loss_epoch=39.80, valid_loss=2.79e+7]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.30, train_loss_epoch=32.30, valid_loss=2.79e+7]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=2.79e+7]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=2.79e+7]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=2.79e+7]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.60, train_loss_epoch=23.60, valid_loss=2.79e+7]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 72.14it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90, valid_loss=2.79e+7]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90, valid_loss=2.79e+7]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=2.79e+7]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 93.54it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=2.79e+7] \n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=2.79e+7]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.930, train_loss_epoch=9.930, valid_loss=2.79e+7]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.780, train_loss_epoch=9.780, valid_loss=2.79e+7]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.590, train_loss_epoch=8.590, valid_loss=2.79e+7]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.490, train_loss_epoch=8.490, valid_loss=2.79e+7]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=2.79e+7]\n",
            "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 75.05it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=2.79e+7]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.680, train_loss_epoch=7.680, valid_loss=2.79e+7]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.030, train_loss_epoch=7.030, valid_loss=2.79e+7]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.980, train_loss_epoch=6.980, valid_loss=2.79e+7]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.580, train_loss_epoch=6.580, valid_loss=2.79e+7]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 98.38it/s, v_num=0, train_loss_step=6.470, train_loss_epoch=6.500, valid_loss=2.79e+7] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.46it/s]\u001b[A\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.310, train_loss_epoch=6.310, valid_loss=1.43e+6]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=1.43e+6]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.020, train_loss_epoch=6.020, valid_loss=1.43e+6]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=1.43e+6]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.600, train_loss_epoch=5.600, valid_loss=1.43e+6]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=1.43e+6]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 96.70it/s, v_num=0, train_loss_step=5.410, train_loss_epoch=5.430, valid_loss=1.43e+6] \n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.410, train_loss_epoch=5.410, valid_loss=1.43e+6]\n",
            "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 86.00it/s, v_num=0, train_loss_step=5.250, train_loss_epoch=5.250, valid_loss=1.43e+6]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.250, train_loss_epoch=5.250, valid_loss=1.43e+6]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 99.83it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=1.43e+6] \n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=1.43e+6]\n",
            "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 84.87it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880, valid_loss=1.43e+6]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880, valid_loss=1.43e+6]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.700, train_loss_epoch=4.700, valid_loss=1.43e+6]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.540, train_loss_epoch=4.540, valid_loss=1.43e+6]\n",
            "Epoch 394: 100%|██████████| 1/1 [00:00<00:00, 78.04it/s, v_num=0, train_loss_step=4.520, train_loss_epoch=4.520, valid_loss=1.43e+6]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 119.29it/s, v_num=0, train_loss_step=4.430, train_loss_epoch=4.450, valid_loss=1.43e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.67it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.380, valid_loss=9.42e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220, valid_loss=9.42e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200, valid_loss=9.42e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=9.42e+5]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.170, train_loss_epoch=4.170, valid_loss=9.42e+5]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=9.42e+5]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 95.75it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=9.42e+5] \n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 42.05it/s, v_num=0, trai\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.850, valid_loss=9.42e+5]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=9.42e+5]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560, valid_loss=9.42e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=9.42e+5]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 76.32it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=9.42e+5]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 73.83it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.420, valid_loss=9.42e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400, valid_loss=9.42e+5]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=9.42e+5]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=9.42e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=9.42e+5]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=9.42e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 111.79it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.860, valid_loss=9.42e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.57it/s]\u001b[A\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=6.65e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=6.65e+5]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=6.65e+5]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=6.65e+5]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=6.65e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 71.71it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=6.65e+5]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=6.65e+5]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=6.65e+5]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=6.65e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=6.65e+5]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=6.65e+5]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=6.65e+5]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=6.65e+5]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=6.65e+5]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=6.65e+5]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=6.65e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 124.43it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=6.65e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.16it/s]\u001b[A\n",
            "Epoch 605: 100%|██████████| 1/1 [00:00<00:00, 112.08it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=5.23e+5]\n",
            "Epoch 605: 100%|██████████| 1/1 [00:00<00:00, 71.85it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=5.23e+5] \n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=5.23e+5]\n",
            "Epoch 614: 100%|██████████| 1/1 [00:00<00:00, 83.87it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=5.23e+5]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=5.23e+5]\n",
            "Epoch 624: 100%|██████████| 1/1 [00:00<00:00, 61.75it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=5.23e+5]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=5.23e+5]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=5.23e+5]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=5.23e+5]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=5.23e+5]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=5.23e+5]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=5.23e+5]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=5.23e+5]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=5.23e+5]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=5.23e+5]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=5.23e+5]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=5.23e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 128.63it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=5.23e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 273.73it/s]\u001b[A\n",
            "Epoch 703: 100%|██████████| 1/1 [00:00<00:00, 109.76it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.54e+5]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.54e+5]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.54e+5]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.54e+5]\n",
            "Epoch 716: 100%|██████████| 1/1 [00:00<00:00, 81.43it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.54e+5]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=4.54e+5]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=4.54e+5]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=4.54e+5]\n",
            "Epoch 749: 100%|██████████| 1/1 [00:00<00:00, 103.96it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.54e+5]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=4.54e+5]\n",
            "Epoch 760: 100%|██████████| 1/1 [00:00<00:00, 84.17it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.620, valid_loss=4.54e+5]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=4.54e+5]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=4.54e+5]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=4.54e+5]\n",
            "Epoch 780: 100%|██████████| 1/1 [00:00<00:00, 38.13it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=4.54e+5]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.54e+5]\n",
            "Epoch 790: 100%|██████████| 1/1 [00:00<00:00, 78.44it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.54e+5]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.54e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 95.36it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.54e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.29it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \n",
            "                                                                       \u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.17e+5]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.17e+5]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.17e+5]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=4.17e+5]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=4.17e+5]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=4.17e+5]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=4.17e+5]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=4.17e+5]\n",
            "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 70.15it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=4.17e+5]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=4.17e+5]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=4.17e+5]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=4.17e+5]\n",
            "Epoch 862: 100%|██████████| 1/1 [00:00<00:00, 21.00it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=4.17e+5]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=4.17e+5]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=4.17e+5]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=4.17e+5]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=4.17e+5]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=4.17e+5]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=4.17e+5]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=4.17e+5]\n",
            "Epoch 891: 100%|██████████| 1/1 [00:00<00:00, 76.04it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=4.17e+5]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=4.17e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 82.62it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.400, valid_loss=4.17e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.74it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.94e+5]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.94e+5]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 82.31it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.94e+5]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 77.73it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.94e+5]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.94e+5]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.94e+5]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.94e+5]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.94e+5]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.94e+5]\n",
            "Epoch 950: 100%|██████████| 1/1 [00:00<00:00, 61.04it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.94e+5]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.94e+5]\n",
            "Epoch 960: 100%|██████████| 1/1 [00:00<00:00, 88.38it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.94e+5]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.94e+5]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.94e+5]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.94e+5]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.94e+5]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.94e+5]\n",
            "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 81.10it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.94e+5]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.94e+5]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:10:17,576\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 79.57it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 77.51it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 74.49it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]        \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 122.14it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 117.74it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 111.24it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]         \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 129.10it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 124.21it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 116.51it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]         \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 115.98it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 112.49it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.270, valid_loss=3.94e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 105.87it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]         \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 126.31it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 121.84it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 113.52it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]         \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 124.73it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 119.59it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 112.52it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]         \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 130.80it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 124.54it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.94e+5]\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 244.14it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51578)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 39.27it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.84e+5] \rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 37.44it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.84e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 35.50it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.84e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51730)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_8b776f91_6_batch_size=32,context_size=5,decoder_hidden_size=64,encoder_hidden_size=200,h=5,learning_rate=0.0000,loss=r_2024-04-15_12-09-58/lightning_logs\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 2024-04-15 12:10:27.447051: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 2024-04-15 12:10:27.447123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 2024-04-15 12:10:27.448490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 2024-04-15 12:10:28.694101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 321 K \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 5 | context_adapter | Linear                     | 5.0 K \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 6 | mlp_decoder     | MLP                        | 449   \n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 326 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 326 K     Total params\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m 1.307     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
            "                                                                           \n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51730)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=0, train_loss_step=106.0]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 87.21it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 78.82it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 70.67it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 68.49it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 63.55it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 79.61it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 76.56it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 72.08it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 76.01it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 72.07it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 67.81it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 82.73it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=100.0, train_loss_epoch=100.0]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.20, train_loss_epoch=98.20]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=94.60, train_loss_epoch=94.60]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=89.20, train_loss_epoch=89.20]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=81.30, train_loss_epoch=81.30]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 74.54it/s, v_num=0, train_loss_step=80.20, train_loss_epoch=81.30]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.39it/s]\u001b[A\n",
            "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 71.73it/s, v_num=0, train_loss_step=71.60, train_loss_epoch=71.60, valid_loss=4.75e+7]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=71.60, train_loss_epoch=71.60, valid_loss=4.75e+7]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=55.80, train_loss_epoch=55.80, valid_loss=4.75e+7]        \n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=55.80, train_loss_epoch=55.80, valid_loss=4.75e+7]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 75.78it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90, valid_loss=4.75e+7]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=22.50, valid_loss=4.75e+7]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=4.75e+7]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.900, train_loss_epoch=8.900, valid_loss=4.75e+7]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.770, valid_loss=4.75e+7]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=4.75e+7]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=6.550, valid_loss=4.75e+7]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.100, train_loss_epoch=6.100, valid_loss=4.75e+7]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 89.00it/s, v_num=0, train_loss_step=5.840, train_loss_epoch=5.870, valid_loss=4.75e+7]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.840, train_loss_epoch=5.840, valid_loss=4.75e+7]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=4.75e+7]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=4.75e+7]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s, v_num=0, train_loss_step=5.450, train_loss_epoch=5.480, valid_loss=4.75e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.32it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.290, train_loss_epoch=5.290, valid_loss=1.13e+6]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 41.24it/s, v_num=0, train_loss_step=5.270, train_loss_epoch=5.290, valid_loss=1.13e+6]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.140, train_loss_epoch=5.140, valid_loss=1.13e+6]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970, valid_loss=1.13e+6]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.790, train_loss_epoch=4.790, valid_loss=1.13e+6]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.570, train_loss_epoch=4.570, valid_loss=1.13e+6]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.520, train_loss_epoch=4.520, valid_loss=1.13e+6]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.360, train_loss_epoch=4.360, valid_loss=1.13e+6]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 57.24it/s, v_num=0, train_loss_step=4.340, train_loss_epoch=4.340, valid_loss=1.13e+6]\n",
            "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 72.43it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=1.13e+6]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.010, train_loss_epoch=4.010, valid_loss=1.13e+6]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.840, train_loss_epoch=3.840, valid_loss=1.13e+6]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=1.13e+6]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=1.13e+6]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=1.13e+6]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270, valid_loss=1.13e+6]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 45.52it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.270, valid_loss=1.13e+6]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=1.13e+6]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 88.77it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.980, valid_loss=1.13e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.18it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=6.8e+5]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=6.8e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=6.8e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 65.70it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=6.8e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 62.39it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.720, valid_loss=6.8e+5]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 30.09it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=6.8e+5]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=6.8e+5]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=6.8e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=6.8e+5]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=6.8e+5]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=6.8e+5]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=6.8e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 74.14it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.350, valid_loss=6.8e+5]\n",
            "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 38.61it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=6.8e+5]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=6.8e+5]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=6.8e+5]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=6.8e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=6.8e+5]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 48.46it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=6.8e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=6.8e+5]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=6.8e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=6.8e+5]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=6.8e+5]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=6.8e+5]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=6.8e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 55.22it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.940, valid_loss=6.8e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.56it/s]\u001b[A\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=4.71e+5]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 67.98it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=4.71e+5]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=4.71e+5]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=4.71e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 44.98it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=4.71e+5]\n",
            "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 31.16it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=4.71e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 81.76it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=4.71e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=4.71e+5]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=4.71e+5]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=4.71e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=4.71e+5]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 100.87it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.700, valid_loss=4.71e+5]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=4.71e+5]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=4.71e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=4.71e+5]\n",
            "Epoch 469: 100%|██████████| 1/1 [00:00<00:00, 68.81it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=4.71e+5]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=4.71e+5]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 82.56it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=4.71e+5]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=4.71e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:10:39,049\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 78.45it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=4.71e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 74.38it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.570, valid_loss=4.71e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 71.25it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]        \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 112.93it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 104.82it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 98.82it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5] \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]        \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 114.38it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 104.88it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 99.00it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5] \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]        \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 109.68it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 102.95it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.560, valid_loss=4.71e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 97.49it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5] \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]        \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 113.78it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 104.71it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 98.90it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5] \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]        \rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 117.69it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 107.23it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 101.12it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]         \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 114.63it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 105.38it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 98.76it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5] \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]        \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 116.96it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 108.19it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.550, valid_loss=4.71e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 99.80it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5] \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 70.03it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 68.06it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 64.99it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 67.14it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 65.32it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 60.92it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 59.69it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 58.40it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.540, valid_loss=4.71e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 54.53it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 72.78it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=4.71e+5]\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.82it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51730)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 30.29it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.89e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 29.05it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.89e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 27.44it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.89e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51730)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_b869ecea_7_batch_size=32,context_size=5,decoder_hidden_size=64,encoder_hidden_size=100,h=5,learning_rate=0.0005,loss=r_2024-04-15_12-10-25/lightning_logs\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 2024-04-15 12:10:47.691801: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 2024-04-15 12:10:47.691860: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 2024-04-15 12:10:47.693103: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 2024-04-15 12:10:49.260523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 80.7 K\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 5 | context_adapter | Linear                     | 2.5 K \n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 6 | mlp_decoder     | MLP                        | 449   \n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 83.7 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 83.7 K    Total params\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m 0.335     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51866)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=93.90, train_loss_epoch=93.90]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.250, train_loss_epoch=7.250]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 56.73it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 76.76it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=8.950]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 72.69it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 86.29it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.180, train_loss_epoch=5.180]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.720, train_loss_epoch=4.720]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.250, train_loss_epoch=4.250]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.570, train_loss_epoch=3.570]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 73.93it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.570]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 259.60it/s]\u001b[A\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=7.6e+5]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=7.6e+5]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 27.59it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=7.6e+5]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=7.6e+5]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=7.6e+5]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=7.6e+5]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=7.6e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=7.6e+5]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 74.84it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=7.6e+5]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=7.6e+5]        \n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=7.6e+5]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=7.6e+5]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=7.6e+5]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=7.6e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 119.58it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.140, valid_loss=7.6e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.12it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.58e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.58e+5]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.110, valid_loss=3.58e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.58e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.58e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.58e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.58e+5]        \n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.58e+5]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 82.72it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.58e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.58e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.58e+5]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 78.61it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.58e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.58e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.58e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.58e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.58e+5]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 81.81it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.58e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.58e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 92.62it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.58e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.41it/s]\u001b[A\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.93e+5]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.93e+5]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=3.93e+5]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=3.93e+5]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=3.93e+5]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=3.93e+5]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=3.93e+5]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 62.67it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=3.93e+5]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=3.93e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=3.93e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=3.93e+5]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=3.93e+5]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=3.93e+5]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=3.93e+5]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 56.68it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=3.93e+5]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=3.93e+5]\n",
            "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 65.15it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=3.93e+5]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=3.93e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 86.58it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=3.93e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.40it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=4.24e+5]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 67.23it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=4.24e+5]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.24e+5]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=4.24e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=4.24e+5]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.24e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=4.24e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=4.24e+5]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=4.24e+5]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 93.59it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=4.24e+5] \n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=4.24e+5]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=4.24e+5]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00, 78.51it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.889, valid_loss=4.24e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=4.24e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=4.24e+5]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=4.24e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:10:59,100\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 87.64it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=4.24e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 85.17it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.887, valid_loss=4.24e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 81.62it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=4.24e+5]\rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=4.24e+5]        \rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=4.24e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 117.11it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=4.24e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 111.50it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.897, valid_loss=4.24e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 104.92it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=4.24e+5]\rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=4.24e+5]         \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=4.24e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 126.18it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=4.24e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 121.16it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.888, valid_loss=4.24e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 114.21it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=4.24e+5]\rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=4.24e+5]         \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=4.24e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 122.51it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=4.24e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 116.18it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.870, valid_loss=4.24e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 105.78it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]         \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 95.68it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 92.89it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 88.43it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=4.24e+5]\rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=4.24e+5]        \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=4.24e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 117.94it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=4.24e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 112.80it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.871, valid_loss=4.24e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 104.09it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=4.24e+5]\rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=4.24e+5]         \rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=4.24e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 129.06it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=4.24e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 124.23it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.877, valid_loss=4.24e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 117.03it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=4.24e+5]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=4.24e+5]         \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=4.24e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 117.53it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=4.24e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 113.50it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.872, valid_loss=4.24e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 106.96it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=4.24e+5]\rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=4.24e+5]         \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=4.24e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 97.06it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=4.24e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 93.31it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.861, valid_loss=4.24e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 86.90it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=4.24e+5]\rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=4.24e+5]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=4.24e+5]\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 45.96it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=4.24e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 45.13it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.859, valid_loss=4.24e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 43.74it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 94.41it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 91.47it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.864, valid_loss=4.24e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 87.50it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=4.24e+5]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=4.24e+5]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=4.24e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 123.29it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=4.24e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 118.97it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.866, valid_loss=4.24e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 110.88it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=4.24e+5]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=4.24e+5]         \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=4.24e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 119.30it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=4.24e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 114.91it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.862, valid_loss=4.24e+5]\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 251.67it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51866)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 44.92it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.862, valid_loss=4.28e+5] \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 42.98it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=4.28e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 41.06it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=4.28e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51866)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_01ebb438_8_batch_size=32,context_size=5,decoder_hidden_size=64,encoder_hidden_size=200,h=5,learning_rate=0.0001,loss=r_2024-04-15_12-10-46/lightning_logs\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 2024-04-15 12:11:10.012086: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 2024-04-15 12:11:10.012138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 2024-04-15 12:11:10.013405: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 2024-04-15 12:11:11.287183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 321 K \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 5 | context_adapter | Linear                     | 5.0 K \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 6 | mlp_decoder     | MLP                        | 449   \n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 326 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 326 K     Total params\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m 1.307     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51991)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=0, train_loss_step=106.0]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 96.37it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 88.19it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 82.92it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 89.48it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 83.41it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 79.28it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 112.52it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 95.01it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0] \rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 90.18it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 112.22it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 93.54it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0] \rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 88.80it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 91.69it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 87.14it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=106.0]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 82.61it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 75.82it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 71.37it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 67.32it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 89.00it/s, v_num=0, train_loss_step=96.10, train_loss_epoch=96.90]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=96.10, train_loss_epoch=96.10]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=83.40, train_loss_epoch=83.40]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=81.20, train_loss_epoch=81.20]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 97.78it/s, v_num=0, train_loss_step=49.60, train_loss_epoch=53.60] \n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.60, train_loss_epoch=49.60]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 79.04it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.870, train_loss_epoch=6.870]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.910, train_loss_epoch=6.910]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.950, train_loss_epoch=5.950]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 74.90it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.950]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.920]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 107.08it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.710]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.10it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=1.13e+6]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 57.71it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=1.13e+6]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=1.13e+6]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.260, train_loss_epoch=5.260, valid_loss=1.13e+6]\n",
            "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 77.40it/s, v_num=0, train_loss_step=4.960, train_loss_epoch=4.960, valid_loss=1.13e+6]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.960, train_loss_epoch=4.960, valid_loss=1.13e+6]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.590, train_loss_epoch=4.590, valid_loss=1.13e+6]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 86.18it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.240, valid_loss=1.13e+6]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200, valid_loss=1.13e+6]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=1.13e+6]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 71.55it/s, v_num=0, train_loss_step=4.120, train_loss_epoch=4.120, valid_loss=1.13e+6]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.120, train_loss_epoch=4.120, valid_loss=1.13e+6]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=1.13e+6]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=1.13e+6]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=1.13e+6]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 86.35it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.590, valid_loss=1.13e+6]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=1.13e+6]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=1.13e+6]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 84.36it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.250, valid_loss=1.13e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.42it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=5.37e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=5.37e+5]        \n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=5.37e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=5.37e+5]\n",
            "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 105.64it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.900, valid_loss=5.37e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=5.37e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=5.37e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=5.37e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=5.37e+5]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 54.72it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=5.37e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=5.37e+5]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 79.56it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=5.37e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=5.37e+5]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 76.31it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=5.37e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=5.37e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=5.37e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=5.37e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=5.37e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=5.37e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 111.79it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.350, valid_loss=5.37e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.50it/s]\u001b[A\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.67e+5]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 73.14it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.67e+5]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.67e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.67e+5]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.67e+5]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.67e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.67e+5]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.67e+5]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.67e+5]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 45.98it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.170, valid_loss=3.67e+5]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.67e+5]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 81.27it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.67e+5]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.67e+5]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.67e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.67e+5]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 59.45it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.67e+5]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.67e+5]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.67e+5]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.67e+5]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.67e+5]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.67e+5]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.67e+5]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.67e+5]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.67e+5]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.67e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.67e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.67e+5]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.67e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 87.02it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.67e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.42it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.62e+5]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.62e+5]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 60.34it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.62e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.62e+5]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.62e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.62e+5]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 81.14it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.62e+5]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.62e+5]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.62e+5]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.62e+5]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.62e+5]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=3.62e+5]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=3.62e+5]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 60.37it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=3.62e+5]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=3.62e+5]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=3.62e+5]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=3.62e+5]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 50.79it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=3.62e+5]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 55.43it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=3.62e+5]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=3.62e+5]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 69.76it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.971, valid_loss=3.62e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.97it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=3.86e+5]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=3.86e+5]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=3.86e+5]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 33.31it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=3.86e+5]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=3.86e+5]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=3.86e+5]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=3.86e+5]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 83.75it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=3.86e+5]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=3.86e+5]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 47.32it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=3.86e+5]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=3.86e+5]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 43.31it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=3.86e+5]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=3.86e+5]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:00<00:00, 86.81it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=3.86e+5]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=3.86e+5]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=3.86e+5]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=3.86e+5]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00, 80.54it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=3.86e+5]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=3.86e+5]\n",
            "Epoch 597: 100%|██████████| 1/1 [00:00<00:00, 103.98it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=3.86e+5]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=3.86e+5]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 107.68it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=3.86e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 217.93it/s]\u001b[A\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=3.94e+5]\n",
            "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 77.63it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.921, valid_loss=3.94e+5]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=3.94e+5]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=3.94e+5]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=3.94e+5]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 79.90it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=3.94e+5]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=3.94e+5]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 80.08it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=3.94e+5]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=3.94e+5]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=3.94e+5]\n",
            "Epoch 637: 100%|██████████| 1/1 [00:00<00:00, 69.59it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=3.94e+5]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=3.94e+5]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=3.94e+5]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=3.94e+5]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=3.94e+5]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 67.45it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=3.94e+5]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=3.94e+5]\n",
            "Epoch 666: 100%|██████████| 1/1 [00:00<00:00, 61.11it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=3.94e+5]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=3.94e+5]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=3.94e+5]\n",
            "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 45.01it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=3.94e+5]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=3.94e+5]\n",
            "Epoch 692: 100%|██████████| 1/1 [00:00<00:00, 71.40it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=3.94e+5]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=3.94e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 107.02it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=3.94e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.88it/s]\u001b[A\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=4.07e+5]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=4.07e+5]\n",
            "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 76.52it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=4.07e+5]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=4.07e+5]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=4.07e+5]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 81.57it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=4.07e+5]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=4.07e+5]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=4.07e+5]\n",
            "Epoch 745: 100%|██████████| 1/1 [00:00<00:00, 73.21it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.875, valid_loss=4.07e+5]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=4.07e+5]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=4.07e+5]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=4.07e+5]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=4.07e+5]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=4.07e+5]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=4.07e+5]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=4.07e+5]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=4.07e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 107.78it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=4.07e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.13it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=4.36e+5]\n",
            "Epoch 806: 100%|██████████| 1/1 [00:00<00:00, 32.32it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=4.36e+5]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=4.36e+5]\n",
            "Epoch 816: 100%|██████████| 1/1 [00:00<00:00, 92.52it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.855, valid_loss=4.36e+5]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=4.36e+5]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=4.36e+5]\n",
            "Epoch 825: 100%|██████████| 1/1 [00:00<00:00, 56.47it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=4.36e+5]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=4.36e+5]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=4.36e+5]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=4.36e+5]\n",
            "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 40.83it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.850, valid_loss=4.36e+5]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=4.36e+5]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=4.36e+5]\n",
            "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 67.33it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=4.36e+5]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=4.36e+5]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=4.36e+5]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=4.36e+5]\n",
            "Epoch 873: 100%|██████████| 1/1 [00:00<00:00, 68.13it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=4.36e+5]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=4.36e+5]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=4.36e+5]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=4.36e+5]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=4.36e+5]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=4.36e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 108.28it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=4.36e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.37it/s]\u001b[A\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=4.41e+5]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=4.41e+5]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=4.41e+5]\n",
            "Epoch 921: 100%|██████████| 1/1 [00:00<00:00, 55.71it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=4.41e+5]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=4.41e+5]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=4.41e+5]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=4.41e+5]\n",
            "Epoch 932: 100%|██████████| 1/1 [00:00<00:00, 67.15it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.826, valid_loss=4.41e+5]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=4.41e+5]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=4.41e+5]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=4.41e+5]\n",
            "Epoch 952: 100%|██████████| 1/1 [00:00<00:00, 73.21it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.824, valid_loss=4.41e+5]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=4.41e+5]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=4.41e+5]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=4.41e+5]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=4.41e+5]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=4.41e+5]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.41e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51991)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "2024-04-15 12:11:28,150\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rEpoch 982: 100%|██████████| 1/1 [00:00<00:00, 69.91it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.41e+5]\rEpoch 982: 100%|██████████| 1/1 [00:00<00:00, 68.11it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.811, valid_loss=4.41e+5]\rEpoch 982: 100%|██████████| 1/1 [00:00<00:00, 64.05it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]        \rEpoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 983: 100%|██████████| 1/1 [00:00<00:00, 121.52it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 983: 100%|██████████| 1/1 [00:00<00:00, 110.94it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 983: 100%|██████████| 1/1 [00:00<00:00, 104.67it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]         \rEpoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 984: 100%|██████████| 1/1 [00:00<00:00, 124.38it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 984: 100%|██████████| 1/1 [00:00<00:00, 114.46it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 984: 100%|██████████| 1/1 [00:00<00:00, 107.20it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]         \rEpoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 985: 100%|██████████| 1/1 [00:00<00:00, 126.02it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 985: 100%|██████████| 1/1 [00:00<00:00, 113.80it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 985: 100%|██████████| 1/1 [00:00<00:00, 107.36it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]         \rEpoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 986: 100%|██████████| 1/1 [00:00<00:00, 119.20it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 986: 100%|██████████| 1/1 [00:00<00:00, 113.81it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 986: 100%|██████████| 1/1 [00:00<00:00, 107.43it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]         \rEpoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 987: 100%|██████████| 1/1 [00:00<00:00, 126.37it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 987: 100%|██████████| 1/1 [00:00<00:00, 115.44it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 987: 100%|██████████| 1/1 [00:00<00:00, 108.82it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]         \rEpoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 988: 100%|██████████| 1/1 [00:00<00:00, 115.26it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 988: 100%|██████████| 1/1 [00:00<00:00, 111.70it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 988: 100%|██████████| 1/1 [00:00<00:00, 105.42it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]         \rEpoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 124.65it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 112.74it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 103.44it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]         \rEpoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 85.35it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 82.58it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 76.78it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]        \rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 38.35it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 37.70it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 36.82it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]        \rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 111.20it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 103.87it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 98.44it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5] \rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]        \rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 116.00it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 106.89it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 100.80it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]         \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 117.19it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 107.29it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 100.94it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]         \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 115.14it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 108.37it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.807, valid_loss=4.41e+5]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 102.56it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]         \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 124.52it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 113.03it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.808, valid_loss=4.41e+5]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 106.22it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]         \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 123.06it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 112.13it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.809, valid_loss=4.41e+5]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 105.51it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]         \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 117.45it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 109.31it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.810, valid_loss=4.41e+5]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 103.31it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.41e+5]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.41e+5]         \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.41e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.41e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 103.16it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.41e+5]\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.40it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=51991)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 39.35it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.52e+5] \rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 37.74it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.52e+5]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 35.95it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=4.52e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52154)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_57735ecb_9_batch_size=32,context_size=5,decoder_hidden_size=128,encoder_hidden_size=20,h=5,learning_rate=0.0001,loss=r_2024-04-15_12-11-08/lightning_logs\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 2024-04-15 12:11:39.016082: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 2024-04-15 12:11:39.016144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 2024-04-15 12:11:39.018160: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 2024-04-15 12:11:40.273495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 3.3 K \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 5 | context_adapter | Linear                     | 525   \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 6 | mlp_decoder     | MLP                        | 897   \n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 4.8 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 4.8 K     Total params\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m 0.019     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52154)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 123.70it/s, v_num=0, train_loss_step=100.0, train_loss_epoch=100.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.66it/s]\u001b[A\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=99.70, train_loss_epoch=99.70, valid_loss=6.02e+7]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.20, train_loss_epoch=98.20, valid_loss=6.02e+7]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.00, train_loss_epoch=98.00, valid_loss=6.02e+7]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.90, train_loss_epoch=95.90, valid_loss=6.02e+7]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 90.57it/s, v_num=0, train_loss_step=92.70, train_loss_epoch=92.70, valid_loss=6.02e+7] \n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=92.70, train_loss_epoch=92.70, valid_loss=6.02e+7]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.80, train_loss_epoch=88.80, valid_loss=6.02e+7]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=83.60, train_loss_epoch=83.60, valid_loss=6.02e+7]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=83.00, train_loss_epoch=83.00, valid_loss=6.02e+7]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.20, train_loss_epoch=76.20, valid_loss=6.02e+7]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.80, train_loss_epoch=68.80, valid_loss=6.02e+7]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=59.00, train_loss_epoch=59.00, valid_loss=6.02e+7]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.00, train_loss_epoch=48.00, valid_loss=6.02e+7]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 86.02it/s, v_num=0, train_loss_step=46.90, train_loss_epoch=48.00, valid_loss=6.02e+7]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=46.90, train_loss_epoch=46.90, valid_loss=6.02e+7]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 86.73it/s, v_num=0, train_loss_step=45.70, train_loss_epoch=46.90, valid_loss=6.02e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 268.38it/s]\u001b[A\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.90, train_loss_epoch=39.90, valid_loss=2.57e+7]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=2.57e+7]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 85.39it/s, v_num=0, train_loss_step=27.50, train_loss_epoch=28.60, valid_loss=2.57e+7]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.50, train_loss_epoch=27.50, valid_loss=2.57e+7]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20, valid_loss=2.57e+7]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=2.57e+7]\n",
            "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 86.05it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=2.57e+7]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=2.57e+7]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.520, train_loss_epoch=9.520, valid_loss=2.57e+7]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.830, train_loss_epoch=8.830, valid_loss=2.57e+7]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 73.63it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.420, valid_loss=2.57e+7]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=2.57e+7]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 103.88it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=2.57e+7]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=2.57e+7]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=2.57e+7]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 60.70it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=2.57e+7]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=2.57e+7]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 124.03it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=7.340, valid_loss=2.57e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.16it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=7.310, valid_loss=1.41e+6]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.060, train_loss_epoch=7.060, valid_loss=1.41e+6]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.830, train_loss_epoch=6.830, valid_loss=1.41e+6]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 92.70it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.610, valid_loss=1.41e+6]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 58.60it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590, valid_loss=1.41e+6]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.380, train_loss_epoch=6.380, valid_loss=1.41e+6]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 100.70it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.180, valid_loss=1.41e+6]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.940, train_loss_epoch=5.940, valid_loss=1.41e+6]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650, valid_loss=1.41e+6]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=1.41e+6]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 51.03it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.480, valid_loss=1.41e+6]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 49.11it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.460, valid_loss=1.41e+6]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.460, valid_loss=1.41e+6]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.320, train_loss_epoch=5.320, valid_loss=1.41e+6]\n",
            "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 49.82it/s, v_num=0, train_loss_step=5.300, train_loss_epoch=5.300, valid_loss=1.41e+6]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=1.41e+6]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=1.41e+6]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 34.39it/s, v_num=0, train_loss_step=5.000, train_loss_epoch=5.020, valid_loss=1.41e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.93it/s]\u001b[A\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 52.96it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=4.860, valid_loss=8.91e+5]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.740, train_loss_epoch=4.740, valid_loss=8.91e+5]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.670, train_loss_epoch=4.670, valid_loss=8.91e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.560, train_loss_epoch=4.560, valid_loss=8.91e+5]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.370, train_loss_epoch=4.370, valid_loss=8.91e+5]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220, valid_loss=8.91e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 93.08it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.060, valid_loss=8.91e+5]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 48.43it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=8.91e+5]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.890, train_loss_epoch=3.890, valid_loss=8.91e+5]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=8.91e+5]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=8.91e+5]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.500, valid_loss=8.91e+5]\n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 54.69it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=8.91e+5]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=8.91e+5]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=8.91e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:11:49,005\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rEpoch 483: 100%|██████████| 1/1 [00:00<00:00, 42.83it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=8.91e+5]\rEpoch 483: 100%|██████████| 1/1 [00:00<00:00, 42.16it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.260, valid_loss=8.91e+5]\rEpoch 483: 100%|██████████| 1/1 [00:00<00:00, 41.05it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=8.91e+5]\rEpoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=8.91e+5]        \rEpoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=8.91e+5]\rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 103.97it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=8.91e+5]\rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 99.85it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.250, valid_loss=8.91e+5] \rEpoch 484: 100%|██████████| 1/1 [00:00<00:00, 93.66it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=8.91e+5]\rEpoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=8.91e+5]        \rEpoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=8.91e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 106.44it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=8.91e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 102.38it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.230, valid_loss=8.91e+5]\rEpoch 485: 100%|██████████| 1/1 [00:00<00:00, 96.10it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=8.91e+5] \rEpoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=8.91e+5]        \rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=8.91e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 106.73it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=8.91e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 102.91it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.210, valid_loss=8.91e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 96.08it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=8.91e+5] \rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=8.91e+5]        \rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=8.91e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 105.76it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=8.91e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 101.87it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.200, valid_loss=8.91e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 94.90it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=8.91e+5] \rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=8.91e+5]        \rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=8.91e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 87.75it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=8.91e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 84.86it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.180, valid_loss=8.91e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 80.22it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=8.91e+5]\rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=8.91e+5]        \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=8.91e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 74.65it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=8.91e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 72.36it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.170, valid_loss=8.91e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 69.03it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=8.91e+5]\rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=8.91e+5]        \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=8.91e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 100.60it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=8.91e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 97.22it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.150, valid_loss=8.91e+5] \rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 91.37it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=8.91e+5]\rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=8.91e+5]        \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=8.91e+5]\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 32.45it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=8.91e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 32.08it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.140, valid_loss=8.91e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 31.40it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=8.91e+5]\rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=8.91e+5]        \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=8.91e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 101.27it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=8.91e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 97.82it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.120, valid_loss=8.91e+5] \rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 91.91it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=8.91e+5]\rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=8.91e+5]        \rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=8.91e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=8.91e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 96.33it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.110, valid_loss=8.91e+5] \rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 90.33it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=8.91e+5]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=8.91e+5]        \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=8.91e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 105.99it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=8.91e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 101.85it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.090, valid_loss=8.91e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 95.25it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=8.91e+5] \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=8.91e+5]        \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=8.91e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 101.84it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=8.91e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 97.91it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.080, valid_loss=8.91e+5] \rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 91.21it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=8.91e+5]\rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=8.91e+5]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=8.91e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 101.69it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=8.91e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 98.11it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.060, valid_loss=8.91e+5] \rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 92.27it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=8.91e+5]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=8.91e+5]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=8.91e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 71.63it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=8.91e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 69.83it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.050, valid_loss=8.91e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 66.81it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=8.91e+5]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=8.91e+5]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=8.91e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 98.82it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=8.91e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 95.25it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.030, valid_loss=8.91e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 88.71it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=8.91e+5]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=8.91e+5]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=8.91e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52154)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 47.39it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=8.91e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 46.26it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.020, valid_loss=8.91e+5]\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.11it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52154)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 25.51it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.020, valid_loss=6.28e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 24.82it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=6.28e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 23.82it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=6.28e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52283)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-07-26/_train_tune_2024-04-15_12-07-26/working_dirs/_train_tune_a67348cc_10_batch_size=32,context_size=10,decoder_hidden_size=64,encoder_hidden_size=50,h=5,learning_rate=0.0042,loss=_2024-04-15_12-11-37/lightning_logs\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 2024-04-15 12:11:58.810597: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 2024-04-15 12:11:58.810678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 2024-04-15 12:11:58.811997: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 2024-04-15 12:12:00.029057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m   | Name            | Type                       | Params\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 0 | loss            | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 1 | valid_loss      | MSE                        | 0     \n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 2 | padder          | ConstantPad1d              | 0     \n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 3 | scaler          | TemporalNorm               | 0     \n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 4 | hist_encoder    | TemporalConvolutionEncoder | 20.4 K\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 5 | context_adapter | Linear                     | 2.6 K \n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 6 | mlp_decoder     | MLP                        | 769   \n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m ---------------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 23.7 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 23.7 K    Total params\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m 0.095     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  0.80it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52283)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=0, train_loss_step=106.0]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 72.24it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 70.17it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=106.0]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 66.46it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 67.22it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 65.58it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=105.0]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 62.66it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 83.83it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 72.69it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 53.50it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.320]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.120]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.290, train_loss_epoch=6.290]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 90.09it/s, v_num=0, train_loss_step=5.740, train_loss_epoch=5.190]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 22.71it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 27.64it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.460]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 73.57it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 42.00it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 38.79it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.400]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.54it/s]\u001b[A\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.33e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 64.75it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.33e+5]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 61.59it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.33e+5]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00, 55.32it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.33e+5]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.33e+5]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 58.48it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.33e+5]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.33e+5]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.33e+5]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.33e+5]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.33e+5]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.33e+5]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.33e+5]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.33e+5]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.33e+5]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.33e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 34.13it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.33e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 26.44it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.160, valid_loss=3.33e+5]\n",
            "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 25.90it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.33e+5]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.33e+5]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.33e+5]\n",
            "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 72.97it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.33e+5]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.33e+5]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 109.24it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.33e+5]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.33e+5]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.33e+5]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 56.79it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.33e+5]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.33e+5]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 115.55it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.33e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 247.50it/s]\u001b[A\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]        \n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.68e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.68e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.68e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]        \n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]\n",
            "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.68e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.68e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.68e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.68e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.68e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 54.96it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.68e+5]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 53.55it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.68e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.68e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.68e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.68e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 118.09it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.68e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.91it/s]\u001b[A\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 79.60it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.72e+5]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.72e+5]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.72e+5]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.72e+5]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.72e+5]\n",
            "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 72.61it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.72e+5]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.72e+5]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.72e+5]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.72e+5]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 53.88it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.72e+5]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.72e+5]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.72e+5]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.72e+5]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.72e+5]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.72e+5]\n",
            "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 73.86it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.72e+5]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.72e+5]        \n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.72e+5]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.72e+5]        \n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.72e+5]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.72e+5]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.72e+5]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.72e+5]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.72e+5]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 91.17it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.000, valid_loss=3.72e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 245.45it/s]\u001b[A\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=4.12e+5]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=4.12e+5]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=4.12e+5]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 82.00it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.972, valid_loss=4.12e+5]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=4.12e+5]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 81.79it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=4.12e+5]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=4.12e+5]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 71.38it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=4.12e+5]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=4.12e+5]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=4.12e+5]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 50.75it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=4.12e+5]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=4.12e+5]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=4.12e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:12:10,273\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "2024-04-15 12:12:10,291\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
            "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
            "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
            "2024-04-15 12:12:10,302\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2024-04-15_12-07-26' in 0.0225s.\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 89.70it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=4.12e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 87.43it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.947, valid_loss=4.12e+5]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 83.39it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=4.12e+5]\rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=4.12e+5]        \rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=4.12e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 119.91it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=4.12e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 116.10it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.927, valid_loss=4.12e+5]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 109.48it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=4.12e+5]\rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=4.12e+5]         \rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=4.12e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 121.03it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=4.12e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 117.16it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.909, valid_loss=4.12e+5]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 109.89it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]\rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]         \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 130.66it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 125.82it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.910, valid_loss=4.12e+5]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 118.41it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=4.12e+5]\rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=4.12e+5]         \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=4.12e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 129.06it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=4.12e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 124.71it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.922, valid_loss=4.12e+5]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 117.34it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=4.12e+5]\rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=4.12e+5]         \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=4.12e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 126.82it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=4.12e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 122.10it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.926, valid_loss=4.12e+5]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 114.17it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=4.12e+5]\rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=4.12e+5]         \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=4.12e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 120.44it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=4.12e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 115.71it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.914, valid_loss=4.12e+5]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 109.10it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=4.12e+5]\rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=4.12e+5]         \rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=4.12e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 100.99it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=4.12e+5]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 96.82it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.904, valid_loss=4.12e+5] \rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=4.12e+5]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=4.12e+5]        \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=4.12e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 69.49it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=4.12e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 67.57it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.903, valid_loss=4.12e+5]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 64.33it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]\rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]        \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]\n",
            "\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 48.38it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=4.12e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.910, valid_loss=4.12e+5]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 46.21it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.12e+5]\rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.12e+5]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.12e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 121.17it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.12e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 116.73it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.913, valid_loss=4.12e+5]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 110.12it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=4.12e+5]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=4.12e+5]         \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=4.12e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 118.87it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=4.12e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 115.10it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.908, valid_loss=4.12e+5]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 107.97it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=4.12e+5]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=4.12e+5]         \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=4.12e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 120.69it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=4.12e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 116.59it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.900, valid_loss=4.12e+5]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 109.60it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=4.12e+5]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=4.12e+5]         \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=4.12e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 108.61it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=4.12e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 105.49it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.898, valid_loss=4.12e+5]\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.85it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52283)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 41.48it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.898, valid_loss=4.6e+5]  \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 40.14it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=4.6e+5]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 37.91it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=4.6e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name            | Type                       | Params\n",
            "---------------------------------------------------------------\n",
            "0 | loss            | MSE                        | 0     \n",
            "1 | valid_loss      | MSE                        | 0     \n",
            "2 | padder          | ConstantPad1d              | 0     \n",
            "3 | scaler          | TemporalNorm               | 0     \n",
            "4 | hist_encoder    | TemporalConvolutionEncoder | 80.7 K\n",
            "5 | context_adapter | Linear                     | 2.5 K \n",
            "6 | mlp_decoder     | MLP                        | 449   \n",
            "---------------------------------------------------------------\n",
            "83.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "83.7 K    Total params\n",
            "0.335     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83052c10943f40eca294160d2c0a74e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7071d1d108743a88a5a2f5b499ad907",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6edd5e812a744663800139af707923dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f465cee6db7449dbf3ae185b5100ff4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "590d52c54d384e3dab3d64de9c2b1e68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3292a4360654913a995b32cc5618b50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f235ed60fb024bb28d474e0844de6dc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7a09645618d489e91e8cc9f378f5711",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb9032148b5a42479ce2b15cc7e43115",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29bf837d68144d8e8eb826fd7b49ddcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e74ddcf88c2442109405e57a799884f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6a1bd38861c4e3ea5bb0735fad458b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93042eaa33404375ac99b95ee0e7f549",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/neuralforecast/core.py:184: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
            "  warnings.warn(\n",
            "2024-04-15 12:12:39,694\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2024-04-15_12-12-39   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator                   |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 10                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2024-04-15_12-12-39\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/driver_artifacts`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52533)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_ae46b1ea_1_dropout=0.3000,early_stop_patience_steps=5,ff_dim=128,h=5,input_size=150,learning_rate=0.0016,loss=ref_ph_d_2024-04-15_12-12-39/lightning_logs\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 2024-04-15 12:12:55.610246: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 2024-04-15 12:12:55.610312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 2024-04-15 12:12:55.616118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 2024-04-15 12:12:58.126418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 5 | mixing_layers | Sequential               | 27.9 K\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 6 | out           | Linear                   | 755   \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 28.7 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 28.7 K    Total params\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m 0.115     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52533)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, v_num=0, train_loss_step=4.070]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 56.93it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=4.070]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 53.29it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 67.74it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 65.81it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=2.240]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 62.54it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 40.71it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 40.09it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=1.520]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 39.05it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 43.45it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 42.67it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=3.010]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.78it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 52.14it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 51.09it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.770]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 48.97it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 60.07it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 58.64it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=1.130]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 56.34it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150]\rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150]        \rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 61.70it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=2.150]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 57.60it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 56.02it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=1.060]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 49.06it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 94.80it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=0.806]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 86.98it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.290]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.74it/s]\u001b[A\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 91.94it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=2.040]\n",
            "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 48.05it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=2.350, valid_loss=2.040]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=2.040]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=2.040]\n",
            "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 48.31it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=2.040]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.700, train_loss_epoch=4.700, valid_loss=2.040]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 51.13it/s, v_num=0, train_loss_step=4.600, train_loss_epoch=4.600, valid_loss=2.040]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=4.350, valid_loss=2.040]\n",
            "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 34.67it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=4.350, valid_loss=2.040]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=2.040]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=2.040]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=2.040]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=2.040]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 65.76it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=16.50, valid_loss=2.040]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80, valid_loss=2.040]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 93.01it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=2.040] \n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=2.040]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=2.040]\n",
            "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 71.85it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=2.040]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=2.040]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 24.74it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=17.40, valid_loss=2.040]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.48it/s]\u001b[A\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=8.650]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=8.650]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 79.80it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=8.650]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.590, train_loss_epoch=9.590, valid_loss=8.650]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.930, train_loss_epoch=8.930, valid_loss=8.650]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=8.650]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.60, train_loss_epoch=20.60, valid_loss=8.650]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90, valid_loss=8.650]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 35.81it/s, v_num=0, train_loss_step=33.20, train_loss_epoch=33.20, valid_loss=8.650]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.00, train_loss_epoch=26.00, valid_loss=8.650]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.30, train_loss_epoch=32.30, valid_loss=8.650]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40, valid_loss=8.650]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=8.650]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 93.63it/s, v_num=0, train_loss_step=85.50, train_loss_epoch=61.50, valid_loss=8.650]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 87.52it/s, v_num=0, train_loss_step=85.50, train_loss_epoch=85.50, valid_loss=8.650]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=111.0, train_loss_epoch=111.0, valid_loss=8.650]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 85.37it/s, v_num=0, train_loss_step=250.0, train_loss_epoch=250.0, valid_loss=8.650]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 99.58it/s, v_num=0, train_loss_step=240.0, train_loss_epoch=265.0, valid_loss=8.650] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.85it/s]\u001b[A\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=239.0, train_loss_epoch=239.0, valid_loss=178.0]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=429.0, train_loss_epoch=429.0, valid_loss=178.0]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=538.0, train_loss_epoch=538.0, valid_loss=178.0]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=877.0, train_loss_epoch=877.0, valid_loss=178.0]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=500.0, train_loss_epoch=500.0, valid_loss=178.0]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=977.0, train_loss_epoch=977.0, valid_loss=178.0]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 87.04it/s, v_num=0, train_loss_step=1.13e+3, train_loss_epoch=1.13e+3, valid_loss=178.0]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 46.73it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.13e+3, valid_loss=178.0]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+3, train_loss_epoch=1.33e+3, valid_loss=178.0]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.29e+3, train_loss_epoch=3.29e+3, valid_loss=178.0]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 93.29it/s, v_num=0, train_loss_step=3.19e+3, train_loss_epoch=3.19e+3, valid_loss=178.0]\n",
            "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 46.20it/s, v_num=0, train_loss_step=1.27e+3, train_loss_epoch=1.27e+3, valid_loss=178.0]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+3, train_loss_epoch=3.1e+3, valid_loss=178.0]        \n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+3, train_loss_epoch=3.1e+3, valid_loss=178.0]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=178.0]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+3, train_loss_epoch=2.27e+3, valid_loss=178.0]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+3, train_loss_epoch=1.65e+3, valid_loss=178.0]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 95.28it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=3.39e+12, valid_loss=178.0] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.93it/s]\u001b[A\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.97e+3, train_loss_epoch=3.97e+3, valid_loss=3.15e+3]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.78e+3, train_loss_epoch=3.78e+3, valid_loss=3.15e+3]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.93e+3, train_loss_epoch=9.93e+3, valid_loss=3.15e+3]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.35e+3, train_loss_epoch=9.35e+3, valid_loss=3.15e+3]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.87e+3, train_loss_epoch=9.87e+3, valid_loss=3.15e+3]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.58e+3, train_loss_epoch=9.58e+3, valid_loss=3.15e+3]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 66.41it/s, v_num=0, train_loss_step=7.43e+3, train_loss_epoch=9.58e+3, valid_loss=3.15e+3]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 81.34it/s, v_num=0, train_loss_step=1.17e+4, train_loss_epoch=1.17e+4, valid_loss=3.15e+3]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+4, train_loss_epoch=1.17e+4, valid_loss=3.15e+3]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.81e+3, train_loss_epoch=7.81e+3, valid_loss=3.15e+3]\n",
            "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 83.73it/s, v_num=0, train_loss_step=1.41e+4, train_loss_epoch=1.41e+4, valid_loss=3.15e+3]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=3.15e+3]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 58.32it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=3.15e+3]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 32.20it/s, v_num=0, train_loss_step=1.8e+4, train_loss_epoch=1.8e+4, valid_loss=3.15e+3]  \n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 62.01it/s, v_num=0, train_loss_step=2.07e+4, train_loss_epoch=2.28e+4, valid_loss=3.15e+3]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 39.97it/s, v_num=0, train_loss_step=2.07e+4, train_loss_epoch=2.07e+4, valid_loss=3.15e+3]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.07e+4, train_loss_epoch=2.07e+4, valid_loss=3.15e+3]        \n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.02e+4, train_loss_epoch=2.02e+4, valid_loss=3.15e+3]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.4e+4, train_loss_epoch=1.4e+4, valid_loss=3.15e+3]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+4, train_loss_epoch=1.31e+4, valid_loss=3.15e+3]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+4, train_loss_epoch=1.21e+4, valid_loss=3.15e+3]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+4, train_loss_epoch=1.3e+4, valid_loss=3.15e+3]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 48.51it/s, v_num=0, train_loss_step=1.3e+4, train_loss_epoch=1.3e+4, valid_loss=3.15e+3]\n",
            "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 47.64it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=1.3e+4, valid_loss=3.15e+3]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+4, train_loss_epoch=1.96e+4, valid_loss=3.15e+3]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 80.79it/s, v_num=0, train_loss_step=1.75e+4, train_loss_epoch=4.26e+12, valid_loss=3.15e+3] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.79it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.58e+4, train_loss_epoch=1.58e+4, valid_loss=2.99e+4]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+4, train_loss_epoch=3.04e+4, valid_loss=2.99e+4]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+4, train_loss_epoch=2.3e+4, valid_loss=2.99e+4]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+4, train_loss_epoch=3.03e+4, valid_loss=2.99e+4]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+4, train_loss_epoch=2.64e+4, valid_loss=2.99e+4]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.31e+4, train_loss_epoch=4.31e+4, valid_loss=2.99e+4]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+4, train_loss_epoch=2.74e+4, valid_loss=2.99e+4]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.77e+4, train_loss_epoch=1.77e+4, valid_loss=2.99e+4]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+4, train_loss_epoch=1.49e+4, valid_loss=2.99e+4]\n",
            "Epoch 563: 100%|██████████| 1/1 [00:00<00:00, 61.16it/s, v_num=0, train_loss_step=1.71e+4, train_loss_epoch=1.49e+4, valid_loss=2.99e+4]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.04e+4, train_loss_epoch=2.04e+4, valid_loss=2.99e+4]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00, 59.65it/s, v_num=0, train_loss_step=8.88e+12, train_loss_epoch=2.9e+4, valid_loss=2.99e+4]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00, 56.97it/s, v_num=0, train_loss_step=8.88e+12, train_loss_epoch=8.88e+12, valid_loss=2.99e+4]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.88e+12, train_loss_epoch=8.88e+12, valid_loss=2.99e+4]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00, 91.54it/s, v_num=0, train_loss_step=4.67e+12, train_loss_epoch=4.67e+12, valid_loss=2.99e+4]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00, 88.19it/s, v_num=0, train_loss_step=4.39e+4, train_loss_epoch=4.67e+12, valid_loss=2.99e+4] \n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=2.99e+4]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+5, train_loss_epoch=1.39e+5, valid_loss=2.99e+4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:13:12,879\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 29.28it/s, v_num=0, train_loss_step=1.39e+5, train_loss_epoch=1.39e+5, valid_loss=2.99e+4]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 24.52it/s, v_num=0, train_loss_step=1.64e+5, train_loss_epoch=1.39e+5, valid_loss=2.99e+4]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 23.97it/s, v_num=0, train_loss_step=1.64e+5, train_loss_epoch=1.64e+5, valid_loss=2.99e+4]\rEpoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+5, train_loss_epoch=1.64e+5, valid_loss=2.99e+4]        \rEpoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+5, train_loss_epoch=1.64e+5, valid_loss=2.99e+4]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 82.29it/s, v_num=0, train_loss_step=1.64e+5, train_loss_epoch=1.64e+5, valid_loss=2.99e+4]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 79.78it/s, v_num=0, train_loss_step=7.49e+4, train_loss_epoch=1.64e+5, valid_loss=2.99e+4]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 75.36it/s, v_num=0, train_loss_step=7.49e+4, train_loss_epoch=7.49e+4, valid_loss=2.99e+4]\rEpoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.49e+4, train_loss_epoch=7.49e+4, valid_loss=2.99e+4]        \rEpoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.49e+4, train_loss_epoch=7.49e+4, valid_loss=2.99e+4]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 90.86it/s, v_num=0, train_loss_step=7.49e+4, train_loss_epoch=7.49e+4, valid_loss=2.99e+4]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 87.54it/s, v_num=0, train_loss_step=1.19e+5, train_loss_epoch=7.49e+4, valid_loss=2.99e+4]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 82.65it/s, v_num=0, train_loss_step=1.19e+5, train_loss_epoch=1.19e+5, valid_loss=2.99e+4]\rEpoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+5, train_loss_epoch=1.19e+5, valid_loss=2.99e+4]        \rEpoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+5, train_loss_epoch=1.19e+5, valid_loss=2.99e+4]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 60.47it/s, v_num=0, train_loss_step=1.19e+5, train_loss_epoch=1.19e+5, valid_loss=2.99e+4]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 58.98it/s, v_num=0, train_loss_step=1.34e+5, train_loss_epoch=1.19e+5, valid_loss=2.99e+4]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 56.58it/s, v_num=0, train_loss_step=1.34e+5, train_loss_epoch=1.34e+5, valid_loss=2.99e+4]\rEpoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+5, train_loss_epoch=1.34e+5, valid_loss=2.99e+4]        \rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+5, train_loss_epoch=1.34e+5, valid_loss=2.99e+4]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 99.34it/s, v_num=0, train_loss_step=1.34e+5, train_loss_epoch=1.34e+5, valid_loss=2.99e+4]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 95.68it/s, v_num=0, train_loss_step=1.12e+5, train_loss_epoch=1.34e+5, valid_loss=2.99e+4]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s, v_num=0, train_loss_step=1.12e+5, train_loss_epoch=1.12e+5, valid_loss=2.99e+4]\rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+5, train_loss_epoch=1.12e+5, valid_loss=2.99e+4]        \rEpoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+5, train_loss_epoch=1.12e+5, valid_loss=2.99e+4]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 63.69it/s, v_num=0, train_loss_step=1.12e+5, train_loss_epoch=1.12e+5, valid_loss=2.99e+4]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 62.02it/s, v_num=0, train_loss_step=8.76e+4, train_loss_epoch=1.12e+5, valid_loss=2.99e+4]\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.82it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52533)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 17.64it/s, v_num=0, train_loss_step=8.76e+4, train_loss_epoch=1.12e+5, valid_loss=1.87e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=0, train_loss_step=8.76e+4, train_loss_epoch=8.76e+4, valid_loss=1.87e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 16.96it/s, v_num=0, train_loss_step=8.76e+4, train_loss_epoch=8.76e+4, valid_loss=1.87e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52710)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_8f018867_2_dropout=0.3000,early_stop_patience_steps=5,ff_dim=32,h=5,input_size=150,learning_rate=0.0000,loss=ref_ph_de_2024-04-15_12-12-52/lightning_logs\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 2024-04-15 12:13:28.329423: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 2024-04-15 12:13:28.329481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 2024-04-15 12:13:28.331185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 2024-04-15 12:13:30.171304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 5 | mixing_layers | Sequential               | 106 K \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 6 | out           | Linear                   | 755   \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 107 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 107 K     Total params\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m 0.430     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52710)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.940, train_loss_epoch=3.940]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.320, train_loss_epoch=3.320]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 57.78it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, v_num=0, train_loss_step=4.140, train_loss_epoch=2.920]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.140, train_loss_epoch=4.140]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.290, train_loss_epoch=3.290]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 26.39it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 18.63it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.710]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.54it/s]\u001b[A\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 31.46it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=1.160]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=1.160]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.990, train_loss_epoch=3.990, valid_loss=1.160]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=1.160]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=1.160]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.160]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=1.160]\n",
            "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.230, valid_loss=1.160]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=1.160]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 20.87it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.930, valid_loss=1.160]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=1.160]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 23.00it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=1.160]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=1.160]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 61.47it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=1.160]\n",
            "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 38.05it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.160]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 54.20it/s, v_num=0, train_loss_step=4.67e+12, train_loss_epoch=4.67e+12, valid_loss=1.160]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.67e+12, train_loss_epoch=4.67e+12, valid_loss=1.160]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.160]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 38.20it/s, v_num=0, train_loss_step=4.010, train_loss_epoch=4.010, valid_loss=1.160]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.010, train_loss_epoch=4.010, valid_loss=1.160]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=1.160]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=1.160]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=1.160]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 54.54it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=1.160]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=1.160]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=1.160]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 52.21it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=1.160]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=1.160]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=1.160]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=1.160]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.160]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 50.80it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=1.160]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.160]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 48.56it/s, v_num=0, train_loss_step=4.100, train_loss_epoch=3.020, valid_loss=1.160]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.49it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.100, train_loss_epoch=4.100, valid_loss=1.180]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.510, train_loss_epoch=4.510, valid_loss=1.180]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=1.180]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=1.180]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.180]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.180]\n",
            "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.180]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.180]        \n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.180]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 58.31it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.610, valid_loss=1.180]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=1.180]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.79e+12, train_loss_epoch=3.79e+12, valid_loss=1.180]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=1.180]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 25.82it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=1.180]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=1.180]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=1.180]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880, valid_loss=1.180]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=1.180]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 45.66it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.040, valid_loss=1.180]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=1.180]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.180]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=1.180]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=1.180]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=1.180]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=1.180]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=1.180]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.390, train_loss_epoch=4.390, valid_loss=1.180]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 30.55it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=4.390, valid_loss=1.180]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.33it/s]\u001b[A\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.210]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=1.210]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 30.54it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=2.390, valid_loss=1.210]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=1.210]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 34.35it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=1.210]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=1.210]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=1.210]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=1.210]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=1.210]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12, valid_loss=1.210]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=1.210]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=1.210]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=1.210]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 40.82it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=1.210]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=1.210]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=1.210]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.810, train_loss_epoch=4.810, valid_loss=1.210]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=1.210]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=1.210]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.210]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 37.32it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=1.300, valid_loss=1.210]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=1.210]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=1.210]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=1.210]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=1.210]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 30.81it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=3.39e+12, valid_loss=1.210]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.78it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=1.120]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.120]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=1.120]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=1.120]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=1.120]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=1.120]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=1.120]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=1.120]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.120]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=1.120]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=1.120]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 41.15it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.220, valid_loss=1.120]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 27.63it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.120]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=1.120]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.800, train_loss_epoch=3.800, valid_loss=1.120]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=1.120]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=1.120]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=1.120]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=1.120]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=1.120]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=1.120]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=1.120]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.120]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.120]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:13:48,419\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 28.41it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.120]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 28.00it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=1.420, valid_loss=1.120]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 27.36it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=1.120]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=1.120]        \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=1.120]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 45.26it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=1.120]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 44.37it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=4.190, valid_loss=1.120]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 42.78it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=1.120]\rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=1.120]        \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=1.120]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 58.86it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=1.120]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 57.20it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.390, valid_loss=1.120]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 55.07it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=1.120]\rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=1.120]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=1.120]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 59.63it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=1.120]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 58.23it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.840, valid_loss=1.120]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 56.13it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.120]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.120]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.120]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 44.57it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.120]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 43.64it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=2.020, valid_loss=1.120]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 42.18it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.120]\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.120]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.120]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 56.75it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.120]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 55.34it/s, v_num=0, train_loss_step=4.26e+12, train_loss_epoch=1.670, valid_loss=1.120]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 53.11it/s, v_num=0, train_loss_step=4.26e+12, train_loss_epoch=4.26e+12, valid_loss=1.120]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.26e+12, train_loss_epoch=4.26e+12, valid_loss=1.120]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.26e+12, train_loss_epoch=4.26e+12, valid_loss=1.120]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 58.40it/s, v_num=0, train_loss_step=4.26e+12, train_loss_epoch=4.26e+12, valid_loss=1.120]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 56.92it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=4.26e+12, valid_loss=1.120]   \n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.56it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52710)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 24.98it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=4.26e+12, valid_loss=1.220]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 24.31it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.220]   \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 23.56it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.220]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52710)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_727f75f4_3_dropout=0.9000,early_stop_patience_steps=5,ff_dim=64,h=5,input_size=300,learning_rate=0.0000,loss=ref_ph_de_2024-04-15_12-13-25/lightning_logs\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 2024-04-15 12:14:04.470745: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 2024-04-15 12:14:04.470825: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 2024-04-15 12:14:04.472966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 2024-04-15 12:14:06.446835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 5 | mixing_layers | Sequential               | 98.3 K\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 6 | out           | Linear                   | 1.5 K \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 99.9 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 99.9 K    Total params\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m 0.399     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52902)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=5.930]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 73.56it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 71.45it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.930]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 68.22it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 94.00it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.090]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 85.47it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750]\rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 89.35it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 86.36it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=5.750]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 81.52it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 87.99it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 85.22it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=7.600]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 80.85it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350]\rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350]        \rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 95.63it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 92.28it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=5.350]\rEpoch 5: 100%|██████████| 1/1 [00:00<00:00, 85.67it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900]\rEpoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900]        \rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900]\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 34.84it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 34.32it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=4.900]\rEpoch 6: 100%|██████████| 1/1 [00:00<00:00, 33.48it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=6.970]\rEpoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=6.970]        \rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=6.970]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 64.59it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=6.970]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 62.71it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=6.970]\rEpoch 7: 100%|██████████| 1/1 [00:00<00:00, 59.88it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210]\rEpoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210]        \rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 80.04it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 64.14it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=5.210]\rEpoch 8: 100%|██████████| 1/1 [00:00<00:00, 61.02it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970]\rEpoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970]        \rEpoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 39.53it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, v_num=0, train_loss_step=7.130, train_loss_epoch=4.970]\rEpoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.76it/s, v_num=0, train_loss_step=7.130, train_loss_epoch=7.130]\rEpoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.130, train_loss_epoch=7.130]        \rEpoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.130, train_loss_epoch=7.130]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 40.69it/s, v_num=0, train_loss_step=7.130, train_loss_epoch=7.130]\rEpoch 10: 100%|██████████| 1/1 [00:00<00:00, 39.97it/s, v_num=0, train_loss_step=4.870, train_loss_epoch=7.130]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 25.52it/s, v_num=0, train_loss_step=4.870, train_loss_epoch=4.870]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 49.53it/s, v_num=0, train_loss_step=5.860, train_loss_epoch=5.860]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 27.45it/s, v_num=0, train_loss_step=4.830, train_loss_epoch=4.830]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.830, train_loss_epoch=4.830]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.730, train_loss_epoch=4.730]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 39.14it/s, v_num=0, train_loss_step=4.310, train_loss_epoch=4.310]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.310, train_loss_epoch=4.310]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 79.92it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=6.060]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.780, train_loss_epoch=4.780]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 31.03it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=4.780]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.890, train_loss_epoch=4.890]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 35.92it/s, v_num=0, train_loss_step=4.750, train_loss_epoch=4.750]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.600, train_loss_epoch=4.600]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.180, train_loss_epoch=4.180]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.420, train_loss_epoch=4.420]\n",
            "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 62.37it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=5.760]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=5.760]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.290, train_loss_epoch=6.290]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.510, train_loss_epoch=5.510]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=4.840]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 90.36it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=3.230]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.03it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.920, train_loss_epoch=3.920, valid_loss=1.290]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=1.290]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.570, train_loss_epoch=3.570, valid_loss=1.290]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 63.21it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=1.290]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 44.40it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.910, valid_loss=1.290]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=1.290]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.540, train_loss_epoch=4.540, valid_loss=1.290]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=1.290]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=1.290]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=1.290]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=1.290]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.910, train_loss_epoch=4.910, valid_loss=1.290]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=1.290]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=1.290]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=1.290]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=1.290]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=1.290]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.500, valid_loss=1.290]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=1.290]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.310, train_loss_epoch=4.310, valid_loss=1.290]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 40.16it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=4.310, valid_loss=1.290]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.55it/s]\u001b[A\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=1.270]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.260, train_loss_epoch=4.260, valid_loss=1.270]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=1.270]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=1.270]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=1.270]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=1.270]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=1.270]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=1.270]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=1.270]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=1.270]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=1.270]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=1.270]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=1.270]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880, valid_loss=1.270]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 27.34it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=1.270]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=1.270]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 47.96it/s, v_num=0, train_loss_step=3.320, train_loss_epoch=3.130, valid_loss=1.270]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=1.270]\n",
            "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 43.70it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=1.270]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=1.270]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=1.270]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 76.86it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=1.270]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=1.270]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=1.270]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 84.99it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=1.270]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.57it/s]\u001b[A\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=1.200]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=1.200]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=1.200]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=1.200]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=1.200]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=1.200]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=1.200]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 44.37it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=3.050, valid_loss=1.200]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=1.200]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=1.200]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 41.03it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.930, valid_loss=1.200]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=1.200]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=1.200]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=1.200]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=1.200]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 51.80it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=1.200]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 36.75it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.940, valid_loss=1.200]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=1.200]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=1.200]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=1.200]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 45.72it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=1.200]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=1.200]\n",
            "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 85.55it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=1.200]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 78.22it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.520, valid_loss=1.200]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.18it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=1.060]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=1.060]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=1.060]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 77.15it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=1.060]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=1.060]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 81.50it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.060]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=1.060]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=1.060]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=1.060]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 73.75it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410, valid_loss=1.060]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410, valid_loss=1.060]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.060]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=1.060]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 78.97it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.630, valid_loss=1.060]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=1.060]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 46.89it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=1.060]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=1.060]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=1.060]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=1.060]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=1.060]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=1.060]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 38.29it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=1.060]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=1.060]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=1.060]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=1.060]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=1.060]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 66.45it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.060]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.060]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=1.060]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 74.27it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=1.060]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=1.060]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=1.060]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=1.060]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 92.29it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.010, valid_loss=1.060]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 51.53it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=1.060]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=1.060]        \n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.060]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=1.060]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 39.30it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=1.060]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=1.060]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 86.41it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.060, valid_loss=1.060]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.70it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.985]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00, 74.78it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=2.250, valid_loss=0.985]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.985]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.985]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.985]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.985]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.985]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.985]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.985]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.985]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 38.89it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.985]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.985]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.985]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.985]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.985]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 90.23it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.990, valid_loss=0.985]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.41it/s]\u001b[A\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 31.14it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.990, valid_loss=0.980]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 22.70it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.980]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.980]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.980]\n",
            "Epoch 613: 100%|██████████| 1/1 [00:00<00:00, 46.28it/s, v_num=0, train_loss_step=4.590, train_loss_epoch=2.200, valid_loss=0.980]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.980]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.980]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.980]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.980]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.980]\n",
            "Epoch 652: 100%|██████████| 1/1 [00:00<00:00, 83.49it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.980]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.980]\n",
            "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 58.44it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.980]\n",
            "Epoch 666: 100%|██████████| 1/1 [00:00<00:00, 90.44it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=2.230, valid_loss=0.980]\n",
            "Epoch 666: 100%|██████████| 1/1 [00:00<00:00, 39.63it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.980]\n",
            "Epoch 673: 100%|██████████| 1/1 [00:00<00:00, 93.45it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.980]\n",
            "Epoch 673: 100%|██████████| 1/1 [00:00<00:00, 89.78it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.090, valid_loss=0.980]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.980]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.980]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.980]\n",
            "Epoch 693: 100%|██████████| 1/1 [00:00<00:00, 62.10it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.980]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 98.70it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.070, valid_loss=0.980] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.41it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.879]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.879]\n",
            "Epoch 705: 100%|██████████| 1/1 [00:00<00:00, 43.73it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=2.600, valid_loss=0.879]\n",
            "Epoch 712: 100%|██████████| 1/1 [00:00<00:00, 85.44it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.590, valid_loss=0.879]\n",
            "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 61.56it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.879]\n",
            "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 34.95it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.879]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.879]\n",
            "Epoch 732: 100%|██████████| 1/1 [00:00<00:00, 75.22it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.480, valid_loss=0.879]\n",
            "Epoch 732: 100%|██████████| 1/1 [00:00<00:00, 37.28it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.879]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=0.879]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.879]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.879]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.879]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 42.10it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.870, valid_loss=0.879]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 40.82it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.879]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.879]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.879]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.879]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.879]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.879]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.879]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.879]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.879]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.879]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.879]\n",
            "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 45.72it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.879]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.879]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.879]\n",
            "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 31.87it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.879]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 55.45it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.780, valid_loss=0.879]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.66it/s]\u001b[A\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.780, valid_loss=0.807]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.807]\n",
            "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 67.47it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.807]\n",
            "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 37.38it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.807]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 68.61it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.807]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.807]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.807]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.807]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.807]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.807]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.807]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.807]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.807]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.807]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.807]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.807]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.807]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.807]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.807]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.807]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.807]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.807]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 57.21it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.420, valid_loss=0.807]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.31it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.770]\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 30.20it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.770]\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 29.85it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.500, valid_loss=0.770]\n",
            "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 19.14it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.770]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.770]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.770]\n",
            "Epoch 915: 100%|██████████| 1/1 [00:00<00:00, 34.67it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.770]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.770]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.770]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.770]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.770]\n",
            "Epoch 940: 100%|██████████| 1/1 [00:00<00:00, 63.08it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.360, valid_loss=0.770]\n",
            "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 87.33it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.770]\n",
            "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 47.19it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.610, valid_loss=0.770]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.770]\n",
            "Epoch 955: 100%|██████████| 1/1 [00:00<00:00, 45.80it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.770]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.770]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=0.770]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.770]        \n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.770]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.770]\n",
            "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 45.53it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.770]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.770]\n",
            "Epoch 986: 100%|██████████| 1/1 [00:00<00:00, 57.92it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.430, valid_loss=0.770]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=0.770]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.770]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:14:31,902\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 39.42it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.770]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 38.74it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=1.780, valid_loss=0.770]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 36.48it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.770]\rEpoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.770]        \rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.770]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 42.32it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.770]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 41.53it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=2.440, valid_loss=0.770]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 40.27it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.770]\rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.770]        \rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.770]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 43.39it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.770]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 42.46it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.390, valid_loss=0.770]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 41.11it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.770]\rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.770]        \rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.770]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 47.87it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.770]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 46.96it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.290, valid_loss=0.770]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 45.25it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.770]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.770]        \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.770]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 67.29it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.770]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 65.49it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.230, valid_loss=0.770]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 56.11it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.770]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.770]        \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.770]\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 38.81it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.770]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 38.18it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.380, valid_loss=0.770]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 37.18it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.770]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.770]        \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.770]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 75.27it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.770]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 64.82it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.330, valid_loss=0.770]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 61.74it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.770]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.770]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.770]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 74.07it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.770]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 71.70it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.210, valid_loss=0.770]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 68.08it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.770]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.770]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.770]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 65.64it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.770]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 63.89it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=1.360, valid_loss=0.770]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 57.60it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.770]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.770]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.770]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 70.26it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.770]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 68.43it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=2.230, valid_loss=0.770]\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52902)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.60it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52902)\u001b[0m \r                                                                      \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 18.10it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=2.230, valid_loss=0.751]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 17.72it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.751]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.751]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53126)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_b32649e0_4_dropout=0.1000,early_stop_patience_steps=5,ff_dim=64,h=5,input_size=30,learning_rate=0.0028,loss=ref_ph_de8_2024-04-15_12-14-01/lightning_logs\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 2024-04-15 12:14:47.293272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 2024-04-15 12:14:47.293334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 2024-04-15 12:14:47.295421: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 2024-04-15 12:14:49.523474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 5 | mixing_layers | Sequential               | 14.9 K\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 6 | out           | Linear                   | 155   \n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 15.1 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 15.1 K    Total params\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m 0.060     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53126)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 25.74it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 32.62it/s, v_num=0, train_loss_step=3.600, train_loss_epoch=3.600]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.720, train_loss_epoch=4.720]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.320, train_loss_epoch=6.320]\n",
            "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 27.66it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 44.92it/s, v_num=0, train_loss_step=8.780, train_loss_epoch=9.730]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 43.40it/s, v_num=0, train_loss_step=8.780, train_loss_epoch=8.780]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 47.35it/s, v_num=0, train_loss_step=20.40, train_loss_epoch=20.40]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.30, train_loss_epoch=21.30]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=38.10]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=38.10]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=67.00, train_loss_epoch=67.00]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=123.0, train_loss_epoch=123.0]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=191.0, train_loss_epoch=191.0]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=217.0, train_loss_epoch=217.0]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=261.0, train_loss_epoch=261.0]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=301.0, train_loss_epoch=301.0]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 44.36it/s, v_num=0, train_loss_step=259.0, train_loss_epoch=287.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.05it/s]\u001b[A\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 27.21it/s, v_num=0, train_loss_step=289.0, train_loss_epoch=259.0, valid_loss=485.0]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=239.0, train_loss_epoch=239.0, valid_loss=485.0]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=295.0, train_loss_epoch=295.0, valid_loss=485.0]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=373.0, train_loss_epoch=373.0, valid_loss=485.0]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=445.0, train_loss_epoch=445.0, valid_loss=485.0]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=492.0, train_loss_epoch=492.0, valid_loss=485.0]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=474.0, train_loss_epoch=474.0, valid_loss=485.0]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=520.0, train_loss_epoch=520.0, valid_loss=485.0]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=429.0, train_loss_epoch=429.0, valid_loss=485.0]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 33.02it/s, v_num=0, train_loss_step=435.0, train_loss_epoch=435.0, valid_loss=485.0]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=435.0, train_loss_epoch=435.0, valid_loss=485.0]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=508.0, train_loss_epoch=508.0, valid_loss=485.0]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=385.0, train_loss_epoch=385.0, valid_loss=485.0]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 31.78it/s, v_num=0, train_loss_step=441.0, train_loss_epoch=441.0, valid_loss=485.0]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 24.65it/s, v_num=0, train_loss_step=425.0, train_loss_epoch=425.0, valid_loss=485.0]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=0, train_loss_step=391.0, train_loss_epoch=391.0, valid_loss=485.0]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 40.09it/s, v_num=0, train_loss_step=286.0, train_loss_epoch=334.0, valid_loss=485.0]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 25.78it/s, v_num=0, train_loss_step=286.0, train_loss_epoch=286.0, valid_loss=485.0]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=298.0, train_loss_epoch=298.0, valid_loss=485.0]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=341.0, train_loss_epoch=341.0, valid_loss=485.0]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=264.0, train_loss_epoch=264.0, valid_loss=485.0]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=279.0, train_loss_epoch=279.0, valid_loss=485.0]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 49.48it/s, v_num=0, train_loss_step=299.0, train_loss_epoch=350.0, valid_loss=485.0]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 29.56it/s, v_num=0, train_loss_step=299.0, train_loss_epoch=299.0, valid_loss=485.0]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=368.0, train_loss_epoch=368.0, valid_loss=485.0]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 31.47it/s, v_num=0, train_loss_step=477.0, train_loss_epoch=368.0, valid_loss=485.0]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=467.0, train_loss_epoch=467.0, valid_loss=485.0]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 27.23it/s, v_num=0, train_loss_step=631.0, train_loss_epoch=566.0, valid_loss=485.0]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 19.95it/s, v_num=0, train_loss_step=631.0, train_loss_epoch=631.0, valid_loss=485.0]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=620.0, train_loss_epoch=620.0, valid_loss=485.0]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=444.0, train_loss_epoch=444.0, valid_loss=485.0]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=620.0, train_loss_epoch=620.0, valid_loss=485.0]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=537.0, train_loss_epoch=537.0, valid_loss=485.0]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 29.16it/s, v_num=0, train_loss_step=537.0, train_loss_epoch=537.0, valid_loss=485.0]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 39.74it/s, v_num=0, train_loss_step=697.0, train_loss_epoch=871.0, valid_loss=485.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.99it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=697.0, train_loss_epoch=697.0, valid_loss=1.24e+3]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=907.0, train_loss_epoch=907.0, valid_loss=1.24e+3]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=784.0, train_loss_epoch=784.0, valid_loss=1.24e+3]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 34.37it/s, v_num=0, train_loss_step=733.0, train_loss_epoch=784.0, valid_loss=1.24e+3]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=1.24e+3]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+3, train_loss_epoch=1.29e+3, valid_loss=1.24e+3]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3, valid_loss=1.24e+3]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.39e+3, valid_loss=1.24e+3]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+3, train_loss_epoch=1.42e+3, valid_loss=1.24e+3]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=0, train_loss_step=1.18e+3, train_loss_epoch=1.18e+3, valid_loss=1.24e+3]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+3, train_loss_epoch=1e+3, valid_loss=1.24e+3]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 34.75it/s, v_num=0, train_loss_step=1.52e+3, train_loss_epoch=4.67e+12, valid_loss=1.24e+3] \n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 29.39it/s, v_num=0, train_loss_step=1.52e+3, train_loss_epoch=1.52e+3, valid_loss=1.24e+3] \n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.52e+3, train_loss_epoch=1.52e+3, valid_loss=1.24e+3]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e+3, train_loss_epoch=1.73e+3, valid_loss=1.24e+3]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.77e+3, train_loss_epoch=1.77e+3, valid_loss=1.24e+3]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.06e+3, train_loss_epoch=2.06e+3, valid_loss=1.24e+3]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.06e+3, train_loss_epoch=2.06e+3, valid_loss=1.24e+3]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=1.24e+3]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=1.24e+3]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.05e+12, train_loss_epoch=6.05e+12, valid_loss=1.24e+3]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=1.24e+3]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.36e+3, train_loss_epoch=3.36e+3, valid_loss=1.24e+3]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=1.24e+3]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+3, train_loss_epoch=3.76e+3, valid_loss=1.24e+3]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.39e+3, train_loss_epoch=4.39e+3, valid_loss=1.24e+3]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.37e+3, train_loss_epoch=5.37e+3, valid_loss=1.24e+3]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.99e+3, train_loss_epoch=4.99e+3, valid_loss=1.24e+3]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.38e+3, train_loss_epoch=4.38e+3, valid_loss=1.24e+3]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.95e+3, train_loss_epoch=3.95e+3, valid_loss=1.24e+3]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.3e+3, train_loss_epoch=4.3e+3, valid_loss=1.24e+3]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.69e+3, train_loss_epoch=5.69e+3, valid_loss=1.24e+3]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.63e+3, train_loss_epoch=6.63e+3, valid_loss=1.24e+3]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 36.23it/s, v_num=0, train_loss_step=5.52e+3, train_loss_epoch=8.23e+3, valid_loss=1.24e+3]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 27.80it/s, v_num=0, train_loss_step=5.52e+3, train_loss_epoch=5.52e+3, valid_loss=1.24e+3]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 16.61it/s, v_num=0, train_loss_step=5.95e+3, train_loss_epoch=5.95e+3, valid_loss=1.24e+3]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.95e+3, train_loss_epoch=5.95e+3, valid_loss=1.24e+3]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.75e+3, train_loss_epoch=4.75e+3, valid_loss=1.24e+3]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.66e+3, train_loss_epoch=1.66e+3, valid_loss=1.24e+3]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.59e+3, train_loss_epoch=7.59e+3, valid_loss=1.24e+3]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=1.24e+3]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 20.69it/s, v_num=0, train_loss_step=7.55e+3, train_loss_epoch=3.84e+12, valid_loss=1.24e+3] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.67it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+3, train_loss_epoch=3.05e+3, valid_loss=1.01e+3]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+4, train_loss_epoch=1.19e+4, valid_loss=1.01e+3]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.02e+3, train_loss_epoch=5.02e+3, valid_loss=1.01e+3]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+4, train_loss_epoch=1.49e+4, valid_loss=1.01e+3]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+4, train_loss_epoch=1.64e+4, valid_loss=1.01e+3]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+4, train_loss_epoch=1.86e+4, valid_loss=1.01e+3]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+4, train_loss_epoch=2.49e+4, valid_loss=1.01e+3]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+4, train_loss_epoch=1.09e+4, valid_loss=1.01e+3]\n",
            "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 30.85it/s, v_num=0, train_loss_step=9.39e+3, train_loss_epoch=9.39e+3, valid_loss=1.01e+3]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.39e+3, train_loss_epoch=9.39e+3, valid_loss=1.01e+3]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.66e+3, train_loss_epoch=6.66e+3, valid_loss=1.01e+3]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+4, train_loss_epoch=1.96e+4, valid_loss=1.01e+3]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.03e+4, train_loss_epoch=2.03e+4, valid_loss=1.01e+3]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.91e+3, train_loss_epoch=7.91e+3, valid_loss=1.01e+3]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 32.69it/s, v_num=0, train_loss_step=5.32e+3, train_loss_epoch=5.32e+3, valid_loss=1.01e+3]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+4, train_loss_epoch=2.25e+4, valid_loss=1.01e+3]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+4, train_loss_epoch=1.34e+4, valid_loss=1.01e+3]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+4, train_loss_epoch=2.1e+4, valid_loss=1.01e+3]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 27.61it/s, v_num=0, train_loss_step=1.06e+4, train_loss_epoch=1.06e+4, valid_loss=1.01e+3]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.76e+4, train_loss_epoch=1.76e+4, valid_loss=1.01e+3]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.22e+4, train_loss_epoch=2.22e+4, valid_loss=1.01e+3]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.57e+3, train_loss_epoch=8.57e+3, valid_loss=1.01e+3]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.1e+3, train_loss_epoch=4.1e+3, valid_loss=1.01e+3]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+4, train_loss_epoch=1.11e+4, valid_loss=1.01e+3]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.99e+3, train_loss_epoch=5.99e+3, valid_loss=1.01e+3]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.83e+3, train_loss_epoch=4.83e+3, valid_loss=1.01e+3]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.21e+3, train_loss_epoch=3.21e+3, valid_loss=1.01e+3]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+4, train_loss_epoch=1.11e+4, valid_loss=1.01e+3]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.41e+3, train_loss_epoch=5.41e+3, valid_loss=1.01e+3]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.77e+3, train_loss_epoch=3.77e+3, valid_loss=1.01e+3]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+3, train_loss_epoch=3.45e+3, valid_loss=1.01e+3]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=1.01e+3]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.28e+3, train_loss_epoch=6.28e+3, valid_loss=1.01e+3]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+3, train_loss_epoch=2.19e+3, valid_loss=1.01e+3]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.24e+3, train_loss_epoch=9.24e+3, valid_loss=1.01e+3]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 20.39it/s, v_num=0, train_loss_step=7.77e+3, train_loss_epoch=7.77e+3, valid_loss=1.01e+3]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 18.25it/s, v_num=0, train_loss_step=1.12e+4, train_loss_epoch=7.77e+3, valid_loss=1.01e+3]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+4, train_loss_epoch=1.12e+4, valid_loss=1.01e+3]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+4, train_loss_epoch=1.32e+4, valid_loss=1.01e+3]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.17e+3, train_loss_epoch=6.17e+3, valid_loss=1.01e+3]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+4, train_loss_epoch=1.33e+4, valid_loss=1.01e+3]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.84e+3, train_loss_epoch=4.84e+3, valid_loss=1.01e+3]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16913.5, train_loss_epoch=16913.5, valid_loss=1.01e+3]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=1.81e+4, valid_loss=1.01e+3]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 32.00it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=9.34e+3, valid_loss=1.01e+3]\n",
            "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 25.52it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12, valid_loss=1.01e+3]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 46.87it/s, v_num=0, train_loss_step=5.87e+3, train_loss_epoch=2.29e+12, valid_loss=1.01e+3] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.98it/s]\u001b[A\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4, valid_loss=1.91e+4]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e+4, train_loss_epoch=1.73e+4, valid_loss=1.91e+4]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+4, train_loss_epoch=1.86e+4, valid_loss=1.91e+4]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+4, train_loss_epoch=1.1e+4, valid_loss=1.91e+4]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+4, train_loss_epoch=1.03e+4, valid_loss=1.91e+4]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 29.70it/s, v_num=0, train_loss_step=1.03e+4, train_loss_epoch=1.03e+4, valid_loss=1.91e+4]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=972.0, train_loss_epoch=972.0, valid_loss=1.91e+4]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+4, train_loss_epoch=1.28e+4, valid_loss=1.91e+4]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+3, train_loss_epoch=3.85e+3, valid_loss=1.91e+4]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.12e+4, train_loss_epoch=3.12e+4, valid_loss=1.91e+4]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+4, train_loss_epoch=2.62e+4, valid_loss=1.91e+4]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.28e+4, train_loss_epoch=3.28e+4, valid_loss=1.91e+4]\n",
            "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 48.12it/s, v_num=0, train_loss_step=3.28e+4, train_loss_epoch=3.28e+4, valid_loss=1.91e+4]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.54e+4, train_loss_epoch=4.54e+4, valid_loss=1.91e+4]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+4, train_loss_epoch=2.9e+4, valid_loss=1.91e+4]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 43.72it/s, v_num=0, train_loss_step=3.4e+4, train_loss_epoch=2.11e+4, valid_loss=1.91e+4] \n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.69e+3, train_loss_epoch=9.69e+3, valid_loss=1.91e+4]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=1.91e+4]\n",
            "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 43.90it/s, v_num=0, train_loss_step=9.45e+3, train_loss_epoch=9.45e+3, valid_loss=1.91e+4]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+3, train_loss_epoch=5.87e+3, valid_loss=1.91e+4]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+4, train_loss_epoch=3.6e+4, valid_loss=1.91e+4]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 30.89it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=1.91e+4]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+3, train_loss_epoch=1.36e+3, valid_loss=1.91e+4]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 31.33it/s, v_num=0, train_loss_step=1.85e+4, train_loss_epoch=1.85e+4, valid_loss=1.91e+4]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.85e+4, train_loss_epoch=1.85e+4, valid_loss=1.91e+4]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+4, train_loss_epoch=2.52e+4, valid_loss=1.91e+4]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.67e+12, train_loss_epoch=4.67e+12, valid_loss=1.91e+4]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 39.47it/s, v_num=0, train_loss_step=1.63e+5, train_loss_epoch=1.63e+5, valid_loss=1.91e+4]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.53e+5, train_loss_epoch=3.53e+5, valid_loss=1.91e+4]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 28.19it/s, v_num=0, train_loss_step=1.94e+5, train_loss_epoch=1.94e+5, valid_loss=1.91e+4]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.94e+5, train_loss_epoch=1.94e+5, valid_loss=1.91e+4]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=1.91e+4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53126)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "2024-04-15 12:15:11,276\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 30.33it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=1.91e+4]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 29.72it/s, v_num=0, train_loss_step=6.24e+4, train_loss_epoch=1.35e+4, valid_loss=1.91e+4]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 29.03it/s, v_num=0, train_loss_step=6.24e+4, train_loss_epoch=6.24e+4, valid_loss=1.91e+4]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.24e+4, train_loss_epoch=6.24e+4, valid_loss=1.91e+4]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.24e+4, train_loss_epoch=6.24e+4, valid_loss=1.91e+4]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 49.40it/s, v_num=0, train_loss_step=6.24e+4, train_loss_epoch=6.24e+4, valid_loss=1.91e+4]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 48.32it/s, v_num=0, train_loss_step=3.07e+4, train_loss_epoch=6.24e+4, valid_loss=1.91e+4]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 46.44it/s, v_num=0, train_loss_step=3.07e+4, train_loss_epoch=3.07e+4, valid_loss=1.91e+4]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+4, train_loss_epoch=3.07e+4, valid_loss=1.91e+4]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+4, train_loss_epoch=3.07e+4, valid_loss=1.91e+4]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 49.78it/s, v_num=0, train_loss_step=3.07e+4, train_loss_epoch=3.07e+4, valid_loss=1.91e+4]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 48.80it/s, v_num=0, train_loss_step=5.87e+4, train_loss_epoch=3.07e+4, valid_loss=1.91e+4]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 47.00it/s, v_num=0, train_loss_step=5.87e+4, train_loss_epoch=5.87e+4, valid_loss=1.91e+4]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+4, train_loss_epoch=5.87e+4, valid_loss=1.91e+4]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+4, train_loss_epoch=5.87e+4, valid_loss=1.91e+4]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 49.52it/s, v_num=0, train_loss_step=5.87e+4, train_loss_epoch=5.87e+4, valid_loss=1.91e+4]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 48.36it/s, v_num=0, train_loss_step=3.32e+4, train_loss_epoch=5.87e+4, valid_loss=1.91e+4]\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.24it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53126)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 22.89it/s, v_num=0, train_loss_step=3.32e+4, train_loss_epoch=5.87e+4, valid_loss=905.0]  \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 22.26it/s, v_num=0, train_loss_step=3.32e+4, train_loss_epoch=3.32e+4, valid_loss=905.0]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 21.58it/s, v_num=0, train_loss_step=3.32e+4, train_loss_epoch=3.32e+4, valid_loss=905.0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53333)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_60bfc461_5_dropout=0.9000,early_stop_patience_steps=5,ff_dim=64,h=5,input_size=300,learning_rate=0.0034,loss=ref_ph_de_2024-04-15_12-14-44/lightning_logs\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 2024-04-15 12:15:27.864511: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 2024-04-15 12:15:27.864578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 2024-04-15 12:15:27.866356: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 2024-04-15 12:15:29.809772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 5 | mixing_layers | Sequential               | 393 K \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 6 | out           | Linear                   | 1.5 K \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 394 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 394 K     Total params\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m 1.579     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "                                                                           \n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53333)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=16.40]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310]\n",
            "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 42.44it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689]\n",
            "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 34.00it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 52.77it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 51.69it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.571]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 26.75it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 46.38it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 49.25it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 52.62it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.636]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.53it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 40.53it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.809, valid_loss=0.407]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.407]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 35.86it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.407]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.407]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.407]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.407]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.407]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.407]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.407]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 34.70it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.565, valid_loss=0.407]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 30.80it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.407]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.407]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.407]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 31.29it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.567, valid_loss=0.407]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.407]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.407]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.726, valid_loss=0.407]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.407]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.407]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.407]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.407]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.407]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 33.61it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.407]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.407]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.407]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.407]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.407]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.407]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.407]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.407]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.407]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.407]\n",
            "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 31.54it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.407]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.407]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.407]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.407]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.407]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.407]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 25.72it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.407]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.407]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 24.48it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.906, valid_loss=0.407]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.03it/s]\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.350]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.350]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.350]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.350]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.350]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=0.350]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.350]\n",
            "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 30.69it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.350]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.350]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.350]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.350]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.350]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.350]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.350]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=0.350]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.350]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.350]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.350]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.350]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.350]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.350]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.350]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.350]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.350]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.350]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.350]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.350]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.350]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.350]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.350]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 49.23it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.470, valid_loss=0.350]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.350]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 52.11it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.350]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.350]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.350]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.350]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 55.83it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.452, valid_loss=0.350]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.62it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.341]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.341]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.341]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.341]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.341]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.341]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.341]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.341]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.341]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.341]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 51.49it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.341]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.341]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.341]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.341]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 26.07it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.341]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.341]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.481, valid_loss=0.341]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.341]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.341]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.341]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 33.60it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.341]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.341]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.341]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.341]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.341]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=0.341]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.341]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.341]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 48.86it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.350, valid_loss=0.341]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.30it/s]\u001b[A\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.393]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.393]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.393]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.393]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.393]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.393]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.393]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.393]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.393]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.393]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.393]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.393]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.393]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.393]\n",
            "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 55.46it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.393]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.393]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.393]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.393]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 57.61it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.393]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.393]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 33.32it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.385, valid_loss=0.393]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.393]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.393]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 55.79it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.279, valid_loss=0.393]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.33it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.288]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.288]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.288]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.288]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.288]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 42.43it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.358, valid_loss=0.288]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.288]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.288]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.288]\n",
            "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 42.16it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.288]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.288]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.288]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.288]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.288]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 46.96it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.288]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.288]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.288]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.288]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.288]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.288]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00, 51.68it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.251, valid_loss=0.288]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00, 34.27it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.288]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.288]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.288]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 46.50it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.376, valid_loss=0.288]\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.70it/s]\u001b[A\n",
            "Epoch 602: 100%|██████████| 1/1 [00:00<00:00, 54.42it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.213, valid_loss=0.303]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.303]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.303]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.303]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.303]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 56.13it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.303]\n",
            "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 36.84it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.337, valid_loss=0.303]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.303]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.778, train_loss_epoch=0.778, valid_loss=0.303]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.303]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 52.78it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.290, valid_loss=0.303]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 50.79it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.303]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.303]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.303]\n",
            "Epoch 651: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.325, valid_loss=0.303]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.303]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.303]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.303]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.303]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.303]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.303]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.303]\n",
            "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 21.06it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.303]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.303]\n",
            "Epoch 680: 100%|██████████| 1/1 [00:00<00:00, 31.52it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.392, valid_loss=0.303]\n",
            "Epoch 680: 100%|██████████| 1/1 [00:00<00:00, 17.94it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.303]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.303]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.303]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 33.28it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.303]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.303]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.303]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.303]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.303]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.303]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.303]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 32.68it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.307, valid_loss=0.303]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.19it/s]\u001b[A\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.272]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.272]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.272]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.272]\n",
            "Epoch 711: 100%|██████████| 1/1 [00:00<00:00, 25.93it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.272]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.272]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 13.50it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.272]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=0.272]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.272]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.272]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.272]\n",
            "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 26.10it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.272]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.272]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.272]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.272]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.272]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.272]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.272]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.272]\n",
            "Epoch 742: 100%|██████████| 1/1 [00:00<00:00, 23.05it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.272]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.272]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.272]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.272]\n",
            "Epoch 755: 100%|██████████| 1/1 [00:00<00:00, 41.27it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.251, valid_loss=0.272]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.272]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.272]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.272]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.272]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 24.83it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.283, valid_loss=0.272]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 20.28it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.272]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 29.31it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.357, valid_loss=0.272]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.272]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.272]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.272]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.272]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.272]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 35.31it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.272]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 34.63it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.239, valid_loss=0.272]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.272]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.272]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.272]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.272]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.272]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.272]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.272]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 34.08it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.589, valid_loss=0.272]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.57it/s]\u001b[A\n",
            "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 28.78it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.258]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.258]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.258]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.258]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.258]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.258]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.258]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.258]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.258]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.258]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.258]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.258]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.258]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.258]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.258]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.258]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.258]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.258]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.258]\n",
            "Epoch 852: 100%|██████████| 1/1 [00:00<00:00, 53.15it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.365, valid_loss=0.258]\n",
            "Epoch 852: 100%|██████████| 1/1 [00:00<00:00, 32.78it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.258]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.258]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.258]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.258]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.258]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.258]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.258]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 40.99it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.258]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 30.58it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.221, valid_loss=0.258]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.258]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.258]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.258]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.258]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 30.97it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.226, valid_loss=0.258]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.95it/s]\u001b[A\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.235]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.235]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.235]\n",
            "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 34.70it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.226, valid_loss=0.235]\n",
            "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 23.58it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=0.235]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.235]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.235]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.235]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.235]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.235]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.235]\n",
            "Epoch 936: 100%|██████████| 1/1 [00:00<00:00, 36.97it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.306, valid_loss=0.235]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.235]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.235]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.235]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.235]\n",
            "Epoch 954: 100%|██████████| 1/1 [00:00<00:00, 49.09it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.235]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.235]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.235]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.235]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.235]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.235]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.235]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.235]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.235]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.235]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:16:05,431\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 32.20it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.235]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 31.67it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.600, valid_loss=0.235]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 30.88it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.235]\rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.235]        \rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.235]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 51.84it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.235]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 50.69it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.257, valid_loss=0.235]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.235]\rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.235]        \rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.235]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 45.80it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.235]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 44.81it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.239, valid_loss=0.235]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 43.30it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.235]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.235]        \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.235]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 38.37it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.235]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 37.65it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.262, valid_loss=0.235]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 36.52it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.235]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.235]        \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.235]\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 29.65it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.235]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 29.22it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.308, valid_loss=0.235]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 28.60it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.235]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.235]        \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.235]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 56.12it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.235]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 54.57it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.208, valid_loss=0.235]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 52.40it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.235]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.235]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.235]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.235]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 52.62it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.244, valid_loss=0.235]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 50.47it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.235]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.235]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.235]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 55.31it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.235]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.260, valid_loss=0.235]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 51.87it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.235]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.235]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.235]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 59.19it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.235]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 57.66it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.624, valid_loss=0.235]\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53333)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.05it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53333)\u001b[0m \r                                                                      \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.624, valid_loss=0.249]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.249]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.249]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53603)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_582f3e14_6_dropout=0.1000,early_stop_patience_steps=5,ff_dim=32,h=5,input_size=150,learning_rate=0.0012,loss=ref_ph_de_2024-04-15_12-15-25/lightning_logs\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 2024-04-15 12:16:21.792996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 2024-04-15 12:16:21.793045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 2024-04-15 12:16:21.794759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 2024-04-15 12:16:23.652971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 5 | mixing_layers | Sequential               | 106 K \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 6 | out           | Linear                   | 755   \n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 107 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 107 K     Total params\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m 0.430     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53603)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.590, train_loss_epoch=4.590]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 56.94it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.743]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12]\n",
            "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 58.96it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 36.41it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.670]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 58.53it/s, v_num=0, train_loss_step=3.840, train_loss_epoch=3.840]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 57.00it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=3.840]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 28.43it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 63.00it/s, v_num=0, train_loss_step=8.390, train_loss_epoch=7.230]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.82it/s]\u001b[A\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.430, train_loss_epoch=8.430, valid_loss=2.980]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.940, train_loss_epoch=8.940, valid_loss=2.980]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=2.980]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=2.980]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=2.980]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=2.980]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80, valid_loss=2.980]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 36.60it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60, valid_loss=2.980]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60, valid_loss=2.980]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=2.980]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=2.980]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=22.50, valid_loss=2.980]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=2.980]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.20, train_loss_epoch=39.20, valid_loss=2.980]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30, valid_loss=2.980]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 30.82it/s, v_num=0, train_loss_step=37.70, train_loss_epoch=34.30, valid_loss=2.980]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.70, train_loss_epoch=37.70, valid_loss=2.980]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.90, train_loss_epoch=36.90, valid_loss=2.980]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=44.50, train_loss_epoch=44.50, valid_loss=2.980]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=46.30, train_loss_epoch=46.30, valid_loss=2.980]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=45.80, train_loss_epoch=45.80, valid_loss=2.980]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.80, train_loss_epoch=53.80, valid_loss=2.980]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.40, train_loss_epoch=53.40, valid_loss=2.980]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=51.30, train_loss_epoch=51.30, valid_loss=2.980]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.70, train_loss_epoch=63.70, valid_loss=2.980]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=44.20, train_loss_epoch=44.20, valid_loss=2.980]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=44.80, train_loss_epoch=44.80, valid_loss=2.980]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.40, train_loss_epoch=48.40, valid_loss=2.980]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90, valid_loss=2.980]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 43.68it/s, v_num=0, train_loss_step=35.40, train_loss_epoch=43.50, valid_loss=2.980]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.40, train_loss_epoch=35.40, valid_loss=2.980]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=46.20, train_loss_epoch=46.20, valid_loss=2.980]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00, valid_loss=2.980]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.20, train_loss_epoch=36.20, valid_loss=2.980]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.00, train_loss_epoch=39.00, valid_loss=2.980]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 27.42it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=39.00, valid_loss=2.980]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.30, train_loss_epoch=33.30, valid_loss=2.980]\n",
            "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 21.20it/s, v_num=0, train_loss_step=35.30, train_loss_epoch=35.30, valid_loss=2.980]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.30, train_loss_epoch=35.30, valid_loss=2.980]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=2.980]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.10, train_loss_epoch=25.10, valid_loss=2.980]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 31.44it/s, v_num=0, train_loss_step=25.10, train_loss_epoch=25.10, valid_loss=2.980]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00, valid_loss=2.980]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 30.99it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=35.30, valid_loss=2.980]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.96it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80, valid_loss=9.600]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=9.600]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 29.44it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=9.600]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.30, train_loss_epoch=25.30, valid_loss=9.600]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=21.70, valid_loss=9.600]\n",
            "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 31.05it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10, valid_loss=9.600]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10, valid_loss=9.600]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.60, train_loss_epoch=26.60, valid_loss=9.600]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10, valid_loss=9.600]\n",
            "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 27.24it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10, valid_loss=9.600]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.80, train_loss_epoch=26.80, valid_loss=9.600]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20, valid_loss=9.600]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.30, train_loss_epoch=23.30, valid_loss=9.600]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=9.600]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 42.81it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=9.600]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=9.600]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40, valid_loss=9.600]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20, valid_loss=9.600]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=54.10, train_loss_epoch=54.10, valid_loss=9.600]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=124.0, train_loss_epoch=124.0, valid_loss=9.600]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=137.0, train_loss_epoch=137.0, valid_loss=9.600]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=0, train_loss_step=137.0, train_loss_epoch=137.0, valid_loss=9.600]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s, v_num=0, train_loss_step=146.0, train_loss_epoch=146.0, valid_loss=9.600]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=146.0, train_loss_epoch=146.0, valid_loss=9.600]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=113.0, train_loss_epoch=113.0, valid_loss=9.600]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.80, train_loss_epoch=78.80, valid_loss=9.600]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=70.20, train_loss_epoch=70.20, valid_loss=9.600]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=82.60, train_loss_epoch=82.60, valid_loss=9.600]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=61.30, train_loss_epoch=61.30, valid_loss=9.600]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.70, train_loss_epoch=78.70, valid_loss=9.600]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 56.49it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12, valid_loss=9.600]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=269.0, train_loss_epoch=269.0, valid_loss=9.600]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 54.52it/s, v_num=0, train_loss_step=382.0, train_loss_epoch=3.39e+12, valid_loss=9.600]   \n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 36.20it/s, v_num=0, train_loss_step=382.0, train_loss_epoch=382.0, valid_loss=9.600]   \n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=629.0, train_loss_epoch=629.0, valid_loss=9.600]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 61.09it/s, v_num=0, train_loss_step=747.0, train_loss_epoch=498.0, valid_loss=9.600]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.33it/s]\u001b[A\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 53.65it/s, v_num=0, train_loss_step=572.0, train_loss_epoch=747.0, valid_loss=741.0]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12, valid_loss=741.0]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=975.0, train_loss_epoch=975.0, valid_loss=741.0]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.39e+3, valid_loss=741.0]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 42.55it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.39e+3, valid_loss=741.0]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+3, train_loss_epoch=1.51e+3, valid_loss=741.0]\n",
            "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 50.63it/s, v_num=0, train_loss_step=1.49e+3, train_loss_epoch=1.49e+3, valid_loss=741.0]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+3, train_loss_epoch=1.49e+3, valid_loss=741.0]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+3, train_loss_epoch=1.61e+3, valid_loss=741.0]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+3, train_loss_epoch=1.51e+3, valid_loss=741.0]\n",
            "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 46.57it/s, v_num=0, train_loss_step=1.85e+3, train_loss_epoch=1.4e+3, valid_loss=741.0]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=741.0]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.28e+3, train_loss_epoch=3.28e+3, valid_loss=741.0]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.68e+3, train_loss_epoch=3.68e+3, valid_loss=741.0]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=4.21e+12, valid_loss=741.0]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.84e+3, train_loss_epoch=4.84e+3, valid_loss=741.0]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.21e+3, train_loss_epoch=7.21e+3, valid_loss=741.0]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+3, train_loss_epoch=3.4e+3, valid_loss=741.0]\n",
            "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 57.63it/s, v_num=0, train_loss_step=5.84e+3, train_loss_epoch=5.84e+3, valid_loss=741.0]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.47e+3, train_loss_epoch=4.47e+3, valid_loss=741.0]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+3, train_loss_epoch=2.96e+3, valid_loss=741.0]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=741.0]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.32e+3, train_loss_epoch=3.32e+3, valid_loss=741.0]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+3, train_loss_epoch=5.85e+3, valid_loss=741.0]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=741.0]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.22e+3, train_loss_epoch=5.22e+3, valid_loss=741.0]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 57.25it/s, v_num=0, train_loss_step=4.13e+3, train_loss_epoch=3.39e+12, valid_loss=741.0] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.69it/s]\u001b[A\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+3, train_loss_epoch=7.95e+3, valid_loss=7.84e+3]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+4, train_loss_epoch=1.28e+4, valid_loss=7.84e+3]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 57.61it/s, v_num=0, train_loss_step=1.21e+4, train_loss_epoch=1.27e+4, valid_loss=7.84e+3]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+4, train_loss_epoch=1.03e+4, valid_loss=7.84e+3]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+4, train_loss_epoch=1.31e+4, valid_loss=7.84e+3]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.75e+3, train_loss_epoch=6.75e+3, valid_loss=7.84e+3]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, v_num=0, train_loss_step=6.33e+3, train_loss_epoch=3.76e+12, valid_loss=7.84e+3] \n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 27.49it/s, v_num=0, train_loss_step=6.33e+3, train_loss_epoch=6.33e+3, valid_loss=7.84e+3] \n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+4, train_loss_epoch=1.61e+4, valid_loss=7.84e+3]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=7.84e+3]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.63e+4, train_loss_epoch=1.63e+4, valid_loss=7.84e+3]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=7.84e+3]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+4, train_loss_epoch=1.36e+4, valid_loss=7.84e+3]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.63e+4, train_loss_epoch=1.63e+4, valid_loss=7.84e+3]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+3, train_loss_epoch=3.1e+3, valid_loss=7.84e+3]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+4, train_loss_epoch=1.07e+4, valid_loss=7.84e+3]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+4, train_loss_epoch=1.13e+4, valid_loss=7.84e+3]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+3, train_loss_epoch=3.98e+3, valid_loss=7.84e+3]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.99e+3, train_loss_epoch=6.99e+3, valid_loss=7.84e+3]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+4, train_loss_epoch=2.52e+4, valid_loss=7.84e+3]\n",
            "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 33.73it/s, v_num=0, train_loss_step=2.52e+4, train_loss_epoch=2.52e+4, valid_loss=7.84e+3]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=7.84e+3]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e+4, train_loss_epoch=1.73e+4, valid_loss=7.84e+3]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 39.21it/s, v_num=0, train_loss_step=4.68e+4, train_loss_epoch=4.68e+4, valid_loss=7.84e+3]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.68e+4, train_loss_epoch=4.68e+4, valid_loss=7.84e+3]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.35e+4, train_loss_epoch=3.35e+4, valid_loss=7.84e+3]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 59.18it/s, v_num=0, train_loss_step=2.54e+4, train_loss_epoch=4.26e+12, valid_loss=7.84e+3] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.60it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+4, train_loss_epoch=3.39e+4, valid_loss=4.26e+4]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=4.26e+4]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=4.26e+4]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.78e+4, train_loss_epoch=5.78e+4, valid_loss=4.26e+4]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.98e+3, train_loss_epoch=9.98e+3, valid_loss=4.26e+4]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.84e+4, train_loss_epoch=1.84e+4, valid_loss=4.26e+4]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=4.21e+12, valid_loss=4.26e+4]\n",
            "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 45.89it/s, v_num=0, train_loss_step=2.97e+3, train_loss_epoch=1.64e+4, valid_loss=4.26e+4]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+4, train_loss_epoch=1.26e+4, valid_loss=4.26e+4]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00, 44.97it/s, v_num=0, train_loss_step=2.57e+4, train_loss_epoch=2.57e+4, valid_loss=4.26e+4]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+4, train_loss_epoch=2.29e+4, valid_loss=4.26e+4]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 36.93it/s, v_num=0, train_loss_step=9e+3, train_loss_epoch=2.29e+4, valid_loss=4.26e+4]   \n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+4, train_loss_epoch=1.51e+4, valid_loss=4.26e+4]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.09e+3, train_loss_epoch=4.09e+3, valid_loss=4.26e+4]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.9e+3, train_loss_epoch=5.9e+3, valid_loss=4.26e+4]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.7e+3, train_loss_epoch=3.7e+3, valid_loss=4.26e+4]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.35e+4, train_loss_epoch=8.35e+4, valid_loss=4.26e+4]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.59e+4, train_loss_epoch=4.59e+4, valid_loss=4.26e+4]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.4e+4, train_loss_epoch=5.4e+4, valid_loss=4.26e+4]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+4, train_loss_epoch=2.59e+4, valid_loss=4.26e+4]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:00<00:00, 36.54it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=2.59e+4, valid_loss=4.26e+4]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+4, train_loss_epoch=2.73e+4, valid_loss=4.26e+4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:16:44,581\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rEpoch 592: 100%|██████████| 1/1 [00:00<00:00, 30.45it/s, v_num=0, train_loss_step=2.73e+4, train_loss_epoch=2.73e+4, valid_loss=4.26e+4]\rEpoch 592: 100%|██████████| 1/1 [00:00<00:00, 30.04it/s, v_num=0, train_loss_step=3.24e+4, train_loss_epoch=2.73e+4, valid_loss=4.26e+4]\rEpoch 592: 100%|██████████| 1/1 [00:00<00:00, 29.28it/s, v_num=0, train_loss_step=3.24e+4, train_loss_epoch=3.24e+4, valid_loss=4.26e+4]\rEpoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+4, train_loss_epoch=3.24e+4, valid_loss=4.26e+4]        \rEpoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+4, train_loss_epoch=3.24e+4, valid_loss=4.26e+4]\rEpoch 593: 100%|██████████| 1/1 [00:00<00:00, 61.60it/s, v_num=0, train_loss_step=3.24e+4, train_loss_epoch=3.24e+4, valid_loss=4.26e+4]\rEpoch 593: 100%|██████████| 1/1 [00:00<00:00, 59.98it/s, v_num=0, train_loss_step=3.3e+4, train_loss_epoch=3.24e+4, valid_loss=4.26e+4] \rEpoch 593: 100%|██████████| 1/1 [00:00<00:00, 57.33it/s, v_num=0, train_loss_step=3.3e+4, train_loss_epoch=3.3e+4, valid_loss=4.26e+4] \rEpoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.3e+4, train_loss_epoch=3.3e+4, valid_loss=4.26e+4]        \rEpoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.3e+4, train_loss_epoch=3.3e+4, valid_loss=4.26e+4]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 53.42it/s, v_num=0, train_loss_step=3.3e+4, train_loss_epoch=3.3e+4, valid_loss=4.26e+4]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 51.75it/s, v_num=0, train_loss_step=4.34e+4, train_loss_epoch=3.3e+4, valid_loss=4.26e+4]\rEpoch 594: 100%|██████████| 1/1 [00:00<00:00, 48.90it/s, v_num=0, train_loss_step=4.34e+4, train_loss_epoch=4.34e+4, valid_loss=4.26e+4]\rEpoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.34e+4, train_loss_epoch=4.34e+4, valid_loss=4.26e+4]        \rEpoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.34e+4, train_loss_epoch=4.34e+4, valid_loss=4.26e+4]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 46.89it/s, v_num=0, train_loss_step=4.34e+4, train_loss_epoch=4.34e+4, valid_loss=4.26e+4]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 45.93it/s, v_num=0, train_loss_step=2.89e+4, train_loss_epoch=4.34e+4, valid_loss=4.26e+4]\rEpoch 595: 100%|██████████| 1/1 [00:00<00:00, 44.21it/s, v_num=0, train_loss_step=2.89e+4, train_loss_epoch=2.89e+4, valid_loss=4.26e+4]\rEpoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+4, train_loss_epoch=2.89e+4, valid_loss=4.26e+4]        \rEpoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+4, train_loss_epoch=2.89e+4, valid_loss=4.26e+4]\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 56.09it/s, v_num=0, train_loss_step=2.89e+4, train_loss_epoch=2.89e+4, valid_loss=4.26e+4]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 36.17it/s, v_num=0, train_loss_step=7.69e+4, train_loss_epoch=2.89e+4, valid_loss=4.26e+4]\rEpoch 596: 100%|██████████| 1/1 [00:00<00:00, 35.01it/s, v_num=0, train_loss_step=7.69e+4, train_loss_epoch=7.69e+4, valid_loss=4.26e+4]\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rEpoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.69e+4, train_loss_epoch=7.69e+4, valid_loss=4.26e+4]        \rEpoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.69e+4, train_loss_epoch=7.69e+4, valid_loss=4.26e+4]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 55.03it/s, v_num=0, train_loss_step=7.69e+4, train_loss_epoch=7.69e+4, valid_loss=4.26e+4]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 53.62it/s, v_num=0, train_loss_step=7.38e+4, train_loss_epoch=7.69e+4, valid_loss=4.26e+4]\rEpoch 597: 100%|██████████| 1/1 [00:00<00:00, 51.43it/s, v_num=0, train_loss_step=7.38e+4, train_loss_epoch=7.38e+4, valid_loss=4.26e+4]\rEpoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.38e+4, train_loss_epoch=7.38e+4, valid_loss=4.26e+4]        \rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.38e+4, train_loss_epoch=7.38e+4, valid_loss=4.26e+4]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 58.39it/s, v_num=0, train_loss_step=7.38e+4, train_loss_epoch=7.38e+4, valid_loss=4.26e+4]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 56.97it/s, v_num=0, train_loss_step=3.61e+4, train_loss_epoch=7.38e+4, valid_loss=4.26e+4]\rEpoch 598: 100%|██████████| 1/1 [00:00<00:00, 54.51it/s, v_num=0, train_loss_step=3.61e+4, train_loss_epoch=3.61e+4, valid_loss=4.26e+4]\rEpoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.61e+4, train_loss_epoch=3.61e+4, valid_loss=4.26e+4]        \rEpoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.61e+4, train_loss_epoch=3.61e+4, valid_loss=4.26e+4]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 59.33it/s, v_num=0, train_loss_step=3.61e+4, train_loss_epoch=3.61e+4, valid_loss=4.26e+4]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 57.95it/s, v_num=0, train_loss_step=2.16e+4, train_loss_epoch=3.61e+4, valid_loss=4.26e+4]\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.27it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53603)\u001b[0m \r                                                                       \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 24.01it/s, v_num=0, train_loss_step=2.16e+4, train_loss_epoch=3.61e+4, valid_loss=1.33e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s, v_num=0, train_loss_step=2.16e+4, train_loss_epoch=2.16e+4, valid_loss=1.33e+5]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00, 22.09it/s, v_num=0, train_loss_step=2.16e+4, train_loss_epoch=2.16e+4, valid_loss=1.33e+5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53808)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_be91428e_7_dropout=0.9000,early_stop_patience_steps=5,ff_dim=128,h=5,input_size=300,learning_rate=0.0019,loss=ref_ph_d_2024-04-15_12-16-19/lightning_logs\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 2024-04-15 12:17:00.988306: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 2024-04-15 12:17:00.988364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 2024-04-15 12:17:00.991142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 2024-04-15 12:17:03.010848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 5 | mixing_layers | Sequential               | 99.2 K\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 6 | out           | Linear                   | 1.5 K \n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 100 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 100 K     Total params\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m 0.403     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53808)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.700, train_loss_epoch=4.700]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.990, train_loss_epoch=5.990]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978]\n",
            "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 27.83it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.978]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 51.15it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.465]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 51.67it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 56.29it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.372]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.91it/s]\u001b[A\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 32.43it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.365]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.365]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.365]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.365]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.365]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 44.82it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.365]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.365]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.365]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.365]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.365]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 83.68it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.365]\n",
            "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 43.08it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.365]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.365]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.365]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.365]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.365]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.365]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.365]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.365]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 86.45it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.365]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 47.26it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.365]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.365]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.365]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 45.12it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.365]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.365]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 66.56it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.466, valid_loss=0.365]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.10it/s]\u001b[A\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 26.74it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.466, valid_loss=0.307]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 20.47it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.307]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.307]\n",
            "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 79.99it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.307]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.307]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.307]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.307]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.307]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.307]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.307]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.307]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 66.54it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.307]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.307]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.307]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 40.75it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.307]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 40.13it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.287, valid_loss=0.307]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.307]\n",
            "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 51.59it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.307]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.307]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=0.307]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.307]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 42.12it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.302, valid_loss=0.307]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.87it/s]\u001b[A\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 75.25it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.287]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.287]\n",
            "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 77.77it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.287]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.287]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.287]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.287]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 74.07it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.287]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.287]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 83.99it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.238, valid_loss=0.287]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 44.30it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.287]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.287]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 87.55it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.287]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.287]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.287]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 44.74it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.287]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.287]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 80.58it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.287]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 55.14it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.287]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.287]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 88.10it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.260, valid_loss=0.287]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.67it/s]\u001b[A\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.314]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.314]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.314]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.314]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.314]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 49.87it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.513, valid_loss=0.314]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.314]\n",
            "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 89.46it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.314]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.314]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.314]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.314]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 81.44it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.314]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.314]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.314]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.314]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 91.43it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.213, valid_loss=0.314]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.98it/s]\u001b[A\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.230]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.230]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.230]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.230]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.230]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.230]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.230]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.230]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00, 79.81it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.230]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00, 86.05it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.230]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.230]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00, 59.80it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.228, valid_loss=0.230]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.230]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.230]\n",
            "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 68.40it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.230]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.230]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.230]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.230]\n",
            "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 51.99it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.149, valid_loss=0.230]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.230]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 88.36it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.270, valid_loss=0.230]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.45it/s]\u001b[A\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.250]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730, valid_loss=0.250]\n",
            "Epoch 616: 100%|██████████| 1/1 [00:00<00:00, 64.39it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.511, valid_loss=0.250]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.250]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.250]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.250]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.250]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.250]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.250]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.250]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.250]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.250]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.250]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.250]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.250]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.250]\n",
            "Epoch 693: 100%|██████████| 1/1 [00:00<00:00, 30.05it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.250]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.250]        \n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.250]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 79.49it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.264, valid_loss=0.250]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.14it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \n",
            "Epoch 705: 100%|██████████| 1/1 [00:00<00:00, 68.83it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.355, valid_loss=0.257]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.257]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.257]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.257]\n",
            "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 42.19it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.218, valid_loss=0.257]\n",
            "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 40.90it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.257]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.257]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.257]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.257]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.257]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.257]\n",
            "Epoch 739: 100%|██████████| 1/1 [00:00<00:00, 34.47it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.611, valid_loss=0.257]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.257]\n",
            "Epoch 747: 100%|██████████| 1/1 [00:00<00:00, 38.56it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.257]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.257]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.257]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.257]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.257]\n",
            "Epoch 767: 100%|██████████| 1/1 [00:00<00:00, 58.31it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.257]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.257]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.257]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.257]\n",
            "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 80.78it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.257]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.257]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.257]\n",
            "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 58.49it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.288, valid_loss=0.257]\n",
            "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 32.73it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.257]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.257]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 48.17it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.481, valid_loss=0.257]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.18it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.247]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.247]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.247]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.247]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.247]\n",
            "Epoch 822: 100%|██████████| 1/1 [00:00<00:00, 52.89it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.247]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.247]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.247]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.247]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.247]\n",
            "Epoch 833: 100%|██████████| 1/1 [00:00<00:00, 43.75it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.247]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.247]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.247]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.247]\n",
            "Epoch 850: 100%|██████████| 1/1 [00:00<00:00, 61.61it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.247]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.247]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.247]\n",
            "Epoch 864: 100%|██████████| 1/1 [00:00<00:00, 67.86it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.247]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.247]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.247]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.247]\n",
            "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 32.79it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.247]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.247]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.247]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.247]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.247]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 88.70it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.212, valid_loss=0.247]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.29it/s]\u001b[A\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.257]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.257]\n",
            "Epoch 913: 100%|██████████| 1/1 [00:00<00:00, 53.93it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.257]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.257]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.257]\n",
            "Epoch 922: 100%|██████████| 1/1 [00:00<00:00, 44.82it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.186, valid_loss=0.257]\n",
            "Epoch 922: 100%|██████████| 1/1 [00:00<00:00, 32.41it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.257]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.257]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.257]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.257]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.257]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.257]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.257]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.257]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.257]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.257]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.257]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.257]\n",
            "Epoch 965: 100%|██████████| 1/1 [00:00<00:00, 43.98it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.257]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.257]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.257]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.257]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.257]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:17:28,605\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rEpoch 985: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.257]\rEpoch 985: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.321, valid_loss=0.257]\rEpoch 985: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.257]\rEpoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.257]        \rEpoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.257]\rEpoch 986: 100%|██████████| 1/1 [00:00<00:00, 50.32it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.257]\rEpoch 986: 100%|██████████| 1/1 [00:00<00:00, 49.37it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.264, valid_loss=0.257]\rEpoch 986: 100%|██████████| 1/1 [00:00<00:00, 47.76it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.257]\rEpoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.257]        \rEpoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.257]\rEpoch 987: 100%|██████████| 1/1 [00:00<00:00, 58.23it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.257]\rEpoch 987: 100%|██████████| 1/1 [00:00<00:00, 56.93it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.245, valid_loss=0.257]\rEpoch 987: 100%|██████████| 1/1 [00:00<00:00, 54.65it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.257]\rEpoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.257]        \rEpoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.257]\rEpoch 988: 100%|██████████| 1/1 [00:00<00:00, 76.39it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.257]\rEpoch 988: 100%|██████████| 1/1 [00:00<00:00, 74.19it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.209, valid_loss=0.257]\rEpoch 988: 100%|██████████| 1/1 [00:00<00:00, 70.26it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.257]\rEpoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.257]        \rEpoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.257]\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 41.21it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.257]\rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 40.54it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.168, valid_loss=0.257]\rEpoch 989: 100%|██████████| 1/1 [00:00<00:00, 39.42it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.257]\rEpoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.257]        \rEpoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.257]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 93.72it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.257]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 90.49it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.338, valid_loss=0.257]\rEpoch 990: 100%|██████████| 1/1 [00:00<00:00, 79.48it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.257]\rEpoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.257]        \rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.257]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 97.86it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.257]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 94.13it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.473, valid_loss=0.257]\rEpoch 991: 100%|██████████| 1/1 [00:00<00:00, 88.36it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.257]\rEpoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.257]        \rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.257]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 95.09it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.257]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 82.09it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.255, valid_loss=0.257]\rEpoch 992: 100%|██████████| 1/1 [00:00<00:00, 77.62it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]\rEpoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]        \rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 91.70it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 88.83it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.242, valid_loss=0.257]\rEpoch 993: 100%|██████████| 1/1 [00:00<00:00, 83.69it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.257]\rEpoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.257]        \rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.257]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 92.10it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.257]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 89.06it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.244, valid_loss=0.257]\rEpoch 994: 100%|██████████| 1/1 [00:00<00:00, 84.02it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.257]\rEpoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.257]        \rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.257]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 98.26it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.257]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 94.73it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.233, valid_loss=0.257]\rEpoch 995: 100%|██████████| 1/1 [00:00<00:00, 88.04it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.257]\rEpoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.257]        \rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.257]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 98.74it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.257]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 95.07it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.188, valid_loss=0.257]\rEpoch 996: 100%|██████████| 1/1 [00:00<00:00, 89.32it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.257]\rEpoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.257]        \rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.257]\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 68.63it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.257]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 66.92it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.202, valid_loss=0.257]\rEpoch 997: 100%|██████████| 1/1 [00:00<00:00, 63.65it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]\rEpoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]        \rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53808)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 50.25it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.257]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 49.09it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.242, valid_loss=0.257]\rEpoch 998: 100%|██████████| 1/1 [00:00<00:00, 47.40it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.257]\rEpoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.257]        \rEpoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.257]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 84.66it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.257]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 81.83it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.529, valid_loss=0.257]\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.02it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=53808)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 29.62it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.529, valid_loss=0.243]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 28.65it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.243]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00, 26.64it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.243]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54033)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_41082c12_8_dropout=0.1000,early_stop_patience_steps=5,ff_dim=128,h=5,input_size=300,learning_rate=0.0004,loss=ref_ph_d_2024-04-15_12-16-58/lightning_logs\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 2024-04-15 12:17:44.439383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 2024-04-15 12:17:44.439446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 2024-04-15 12:17:44.443750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 2024-04-15 12:17:46.773877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 5 | mixing_layers | Sequential               | 198 K \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 6 | out           | Linear                   | 1.5 K \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 199 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 199 K     Total params\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m 0.799     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54033)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54033)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.180, train_loss_epoch=4.180]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 64.43it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=1.150]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 45.85it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 44.60it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 67.35it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.398]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.65it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m \n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.460]\n",
            "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 39.21it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.289, valid_loss=0.460]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.460]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.460]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.460]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.460]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.460]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.460]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.460]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.460]\n",
            "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 46.49it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.460]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.460]\n",
            "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 73.44it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.460]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.460]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.460]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.460]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.460]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.460]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 51.42it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.482, valid_loss=0.460]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.02it/s]\u001b[A\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.434]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 70.33it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.235, valid_loss=0.434]\n",
            "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 40.93it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.434]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.434]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.434]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.434]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.434]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 71.59it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.434]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.434]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.434]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.434]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 59.11it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.434]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.434]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.434]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.434]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 39.59it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.228, valid_loss=0.434]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.434]\n",
            "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 42.05it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.219, valid_loss=0.434]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=0.434]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.434]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.434]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 43.94it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.434]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.434]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 43.12it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.331, valid_loss=0.434]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.434]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.257, valid_loss=0.434]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.14it/s]\u001b[A\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.386]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.386]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.386]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.386]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.386]\n",
            "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 59.03it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.386]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.386]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 56.54it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.369, valid_loss=0.386]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.386]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.386]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.386]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.386]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.386]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.386]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.386]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.386]        \n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.386]\n",
            "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 45.04it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.386]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.386]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.386]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.386]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.386]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.386]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.386]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 45.32it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.158, valid_loss=0.386]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 33.88it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.386]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.386]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.386]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.386]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.386]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.386]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 50.25it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.276, valid_loss=0.386]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.05it/s]\u001b[A\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.537]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.537]\n",
            "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 46.75it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.210, valid_loss=0.537]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.537]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.537]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.537]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.537]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.537]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.537]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.537]\n",
            "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 40.55it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.351, valid_loss=0.537]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.537]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.537]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.537]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.537]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.537]\n",
            "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 42.28it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.249, valid_loss=0.537]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.537]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.537]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.537]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.537]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.537]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.537]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.537]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.537]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.537]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 48.64it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.150, valid_loss=0.537]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:18:02,034\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54033)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.38it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54033)\u001b[0m \r                                                                      \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.150, valid_loss=0.348]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.348]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.348]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54211)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_90f260e4_9_dropout=0.5000,early_stop_patience_steps=5,ff_dim=32,h=5,input_size=30,learning_rate=0.0020,loss=ref_ph_de8_2024-04-15_12-17-41/lightning_logs\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 2024-04-15 12:18:15.702926: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 2024-04-15 12:18:15.702980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 2024-04-15 12:18:15.704723: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 2024-04-15 12:18:17.674239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 5 | mixing_layers | Sequential               | 16.6 K\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 6 | out           | Linear                   | 155   \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 16.7 K    Trainable params\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 16.7 K    Total params\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m 0.067     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  0.59it/s]\n",
            "Training: |          | 0/? [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54211)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s, v_num=0, train_loss_step=5.370]\rEpoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370]\rEpoch 0:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370]        \rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 29.30it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 28.88it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=5.370]\rEpoch 1: 100%|██████████| 1/1 [00:00<00:00, 28.28it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\rEpoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]        \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=3.76e+12]   \rEpoch 2: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=5.570]   \rEpoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=5.570]        \rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=5.570]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 36.06it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=5.570]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 35.48it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=5.570]\rEpoch 3: 100%|██████████| 1/1 [00:00<00:00, 34.27it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12]\rEpoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12]        \rEpoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 31.85it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12]\rEpoch 4: 100%|██████████| 1/1 [00:00<00:00, 31.43it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=3.39e+12]   \n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 25.19it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=4.800]   \n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.940, train_loss_epoch=4.940]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.690]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.050, train_loss_epoch=5.050]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 31.60it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=6.550]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=6.550]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.590, train_loss_epoch=4.590]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.100, train_loss_epoch=4.100]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.890, train_loss_epoch=3.890]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.150, train_loss_epoch=5.150]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 25.10it/s, v_num=0, train_loss_step=4.510, train_loss_epoch=4.510]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.700, train_loss_epoch=4.700]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.700, train_loss_epoch=5.700]\n",
            "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 23.67it/s, v_num=0, train_loss_step=4.910, train_loss_epoch=4.910]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.910, train_loss_epoch=4.910]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 42.79it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 30.65it/s, v_num=0, train_loss_step=6.400, train_loss_epoch=4.070]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.530, train_loss_epoch=5.530]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=6.060]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.640, train_loss_epoch=4.640]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.390, train_loss_epoch=5.390]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.510, train_loss_epoch=4.510]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.43e+12, train_loss_epoch=8.43e+12]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.460, train_loss_epoch=8.460]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.710, train_loss_epoch=8.710]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.250, train_loss_epoch=9.250]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 36.09it/s, v_num=0, train_loss_step=9.160, train_loss_epoch=9.160]\n",
            "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 25.61it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 41.66it/s, v_num=0, train_loss_step=9.620, train_loss_epoch=11.20]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.60it/s]\u001b[A\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=8.170]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=8.170]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=8.170]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=8.170]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=8.170]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90, valid_loss=8.170]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=8.170]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30, valid_loss=8.170]        \n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30, valid_loss=8.170]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70, valid_loss=8.170]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 30.26it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=19.70, valid_loss=8.170]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=8.170]\n",
            "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 41.07it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30, valid_loss=8.170]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30, valid_loss=8.170]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.10, train_loss_epoch=21.10, valid_loss=8.170]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=8.170]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.00, train_loss_epoch=21.00, valid_loss=8.170]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60, valid_loss=8.170]\n",
            "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 23.95it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60, valid_loss=8.170]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00, valid_loss=8.170]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=8.170]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70, valid_loss=8.170]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=8.170]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=8.170]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=8.170]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90, valid_loss=8.170]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.30, train_loss_epoch=21.30, valid_loss=8.170]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.20, train_loss_epoch=23.20, valid_loss=8.170]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.10, train_loss_epoch=25.10, valid_loss=8.170]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.50, train_loss_epoch=26.50, valid_loss=8.170]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=8.170]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 21.60it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=28.30, valid_loss=8.170]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10, valid_loss=8.170]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.70, train_loss_epoch=24.70, valid_loss=8.170]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=8.170]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 32.51it/s, v_num=0, train_loss_step=33.40, train_loss_epoch=31.20, valid_loss=8.170]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.75it/s]\u001b[A\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.70, train_loss_epoch=37.70, valid_loss=28.40]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 38.49it/s, v_num=0, train_loss_step=37.30, train_loss_epoch=37.30, valid_loss=28.40]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.10, train_loss_epoch=39.10, valid_loss=28.40]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.50, train_loss_epoch=42.50, valid_loss=28.40]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=51.50, train_loss_epoch=51.50, valid_loss=28.40]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.10, train_loss_epoch=56.10, valid_loss=28.40]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 37.31it/s, v_num=0, train_loss_step=53.30, train_loss_epoch=53.30, valid_loss=28.40]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 24.97it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=60.00, valid_loss=28.40]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.30, train_loss_epoch=63.30, valid_loss=28.40]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=64.50, train_loss_epoch=64.50, valid_loss=28.40]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 24.13it/s, v_num=0, train_loss_step=62.70, train_loss_epoch=64.50, valid_loss=28.40]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.90, train_loss_epoch=68.90, valid_loss=28.40]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.67e+12, train_loss_epoch=4.67e+12, valid_loss=28.40]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=72.50, train_loss_epoch=72.50, valid_loss=28.40]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=97.70, train_loss_epoch=97.70, valid_loss=28.40]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=113.0, train_loss_epoch=113.0, valid_loss=28.40]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=114.0, train_loss_epoch=114.0, valid_loss=28.40]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=143.0, train_loss_epoch=143.0, valid_loss=28.40]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.05e+12, train_loss_epoch=6.05e+12, valid_loss=28.40]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=220.0, train_loss_epoch=220.0, valid_loss=28.40]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=254.0, train_loss_epoch=254.0, valid_loss=28.40]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=253.0, train_loss_epoch=253.0, valid_loss=28.40]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=298.0, train_loss_epoch=298.0, valid_loss=28.40]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=291.0, train_loss_epoch=291.0, valid_loss=28.40]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=302.0, train_loss_epoch=302.0, valid_loss=28.40]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=327.0, train_loss_epoch=327.0, valid_loss=28.40]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=301.0, train_loss_epoch=301.0, valid_loss=28.40]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=344.0, train_loss_epoch=344.0, valid_loss=28.40]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=452.0, train_loss_epoch=452.0, valid_loss=28.40]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=458.0, train_loss_epoch=458.0, valid_loss=28.40]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=403.0, train_loss_epoch=403.0, valid_loss=28.40]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=485.0, train_loss_epoch=485.0, valid_loss=28.40]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=643.0, train_loss_epoch=643.0, valid_loss=28.40]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s, v_num=0, train_loss_step=704.0, train_loss_epoch=704.0, valid_loss=28.40]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=704.0, train_loss_epoch=704.0, valid_loss=28.40]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 16.73it/s, v_num=0, train_loss_step=728.0, train_loss_epoch=3.84e+12, valid_loss=28.40]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 27.69it/s]\u001b[A\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=630.0, train_loss_epoch=630.0, valid_loss=791.0]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=794.0, train_loss_epoch=794.0, valid_loss=791.0]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=782.0, train_loss_epoch=782.0, valid_loss=791.0]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=834.0, train_loss_epoch=834.0, valid_loss=791.0]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3, valid_loss=791.0]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 20.64it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=791.0] \n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=791.0]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+3, train_loss_epoch=1.19e+3, valid_loss=791.0]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+3, train_loss_epoch=1.22e+3, valid_loss=791.0]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.68e+3, valid_loss=791.0]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+3, train_loss_epoch=1.44e+3, valid_loss=791.0]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+3, train_loss_epoch=1.42e+3, valid_loss=791.0]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+3, train_loss_epoch=1.47e+3, valid_loss=791.0]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.43e+3, train_loss_epoch=1.43e+3, valid_loss=791.0]\n",
            "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 17.57it/s, v_num=0, train_loss_step=1.4e+3, train_loss_epoch=1.43e+3, valid_loss=791.0] \n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.4e+3, train_loss_epoch=1.4e+3, valid_loss=791.0]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.6e+3, train_loss_epoch=1.6e+3, valid_loss=791.0]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.68e+3, valid_loss=791.0]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+3, train_loss_epoch=1.2e+3, valid_loss=791.0]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+3, train_loss_epoch=1.24e+3, valid_loss=791.0]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=959.0, train_loss_epoch=959.0, valid_loss=791.0]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 41.00it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.33e+3, valid_loss=791.0]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.71e+3, train_loss_epoch=1.71e+3, valid_loss=791.0]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.4e+3, train_loss_epoch=1.4e+3, valid_loss=791.0]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+3, train_loss_epoch=1.16e+3, valid_loss=791.0]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 26.21it/s, v_num=0, train_loss_step=1.36e+3, train_loss_epoch=1.36e+3, valid_loss=791.0]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+3, train_loss_epoch=1.36e+3, valid_loss=791.0]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3, valid_loss=791.0]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+3, train_loss_epoch=1.26e+3, valid_loss=791.0]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+3, train_loss_epoch=1.19e+3, valid_loss=791.0]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=0, train_loss_step=906.0, train_loss_epoch=906.0, valid_loss=791.0]  \n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=906.0, train_loss_epoch=906.0, valid_loss=791.0]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+3, train_loss_epoch=1.14e+3, valid_loss=791.0]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+3, train_loss_epoch=1.03e+3, valid_loss=791.0]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3, valid_loss=791.0]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=791.0]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=997.0, train_loss_epoch=997.0, valid_loss=791.0]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=905.0, train_loss_epoch=905.0, valid_loss=791.0]\n",
            "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 21.13it/s, v_num=0, train_loss_step=833.0, train_loss_epoch=833.0, valid_loss=791.0]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=833.0, train_loss_epoch=833.0, valid_loss=791.0]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=791.0]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=919.0, train_loss_epoch=919.0, valid_loss=791.0]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=997.0, train_loss_epoch=997.0, valid_loss=791.0]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=791.0]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=791.0]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.06e+3, valid_loss=791.0]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3, valid_loss=791.0]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.06e+3, valid_loss=791.0]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3, valid_loss=791.0]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12, valid_loss=791.0]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=0, train_loss_step=884.0, train_loss_epoch=2.29e+12, valid_loss=791.0]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.25it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=884.0, train_loss_epoch=884.0, valid_loss=1.74e+3]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+3, train_loss_epoch=1.34e+3, valid_loss=1.74e+3]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+3, train_loss_epoch=1.44e+3, valid_loss=1.74e+3]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, v_num=0, train_loss_step=1.61e+3, train_loss_epoch=1.61e+3, valid_loss=1.74e+3]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+3, train_loss_epoch=1.61e+3, valid_loss=1.74e+3]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e+3, train_loss_epoch=1.62e+3, valid_loss=1.74e+3]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.77e+3, train_loss_epoch=1.77e+3, valid_loss=1.74e+3]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+3, train_loss_epoch=1.81e+3, valid_loss=1.74e+3]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 25.53it/s, v_num=0, train_loss_step=1.55e+3, train_loss_epoch=1.55e+3, valid_loss=1.74e+3]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.55e+3, train_loss_epoch=1.55e+3, valid_loss=1.74e+3]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.53e+3, train_loss_epoch=1.53e+3, valid_loss=1.74e+3]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.53e+3, train_loss_epoch=1.53e+3, valid_loss=1.74e+3]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.08e+3, train_loss_epoch=2.08e+3, valid_loss=1.74e+3]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.87e+3, train_loss_epoch=1.87e+3, valid_loss=1.74e+3]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.53e+3, train_loss_epoch=1.53e+3, valid_loss=1.74e+3]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.18e+3, train_loss_epoch=2.18e+3, valid_loss=1.74e+3]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=1.74e+3]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=1.74e+3]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.22e+3, train_loss_epoch=2.22e+3, valid_loss=1.74e+3]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=1.74e+3]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s, v_num=0, train_loss_step=3.04e+3, train_loss_epoch=3.04e+3, valid_loss=1.74e+3]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+3, train_loss_epoch=3.04e+3, valid_loss=1.74e+3]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=1.74e+3]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 33.76it/s, v_num=0, train_loss_step=3.98e+3, train_loss_epoch=3.98e+3, valid_loss=1.74e+3]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+3, train_loss_epoch=3.98e+3, valid_loss=1.74e+3]        \n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+3, train_loss_epoch=3.98e+3, valid_loss=1.74e+3]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.51e+3, train_loss_epoch=3.51e+3, valid_loss=1.74e+3]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+3, train_loss_epoch=3.24e+3, valid_loss=1.74e+3]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.32e+3, train_loss_epoch=3.32e+3, valid_loss=1.74e+3]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.11e+3, train_loss_epoch=4.11e+3, valid_loss=1.74e+3]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+3, train_loss_epoch=3.11e+3, valid_loss=1.74e+3]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.27e+3, train_loss_epoch=4.27e+3, valid_loss=1.74e+3]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.31e+3, train_loss_epoch=4.31e+3, valid_loss=1.74e+3]\n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 33.23it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=4.67e+12, valid_loss=1.74e+3] \n",
            "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 26.50it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=1.74e+3] \n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.91e+3, train_loss_epoch=6.91e+3, valid_loss=1.74e+3]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.06e+3, train_loss_epoch=6.06e+3, valid_loss=1.74e+3]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.11e+3, train_loss_epoch=7.11e+3, valid_loss=1.74e+3]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.62e+3, train_loss_epoch=9.62e+3, valid_loss=1.74e+3]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+4, train_loss_epoch=1.24e+4, valid_loss=1.74e+3]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+4, train_loss_epoch=1.26e+4, valid_loss=1.74e+3]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+4, train_loss_epoch=1.31e+4, valid_loss=1.74e+3]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:18:42,434\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 21.12it/s, v_num=0, train_loss_step=1.31e+4, train_loss_epoch=1.31e+4, valid_loss=1.74e+3]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 20.90it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.31e+4, valid_loss=1.74e+3]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 20.57it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4, valid_loss=1.74e+3]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4, valid_loss=1.74e+3]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4, valid_loss=1.74e+3]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 36.66it/s, v_num=0, train_loss_step=1.54e+4, train_loss_epoch=1.54e+4, valid_loss=1.74e+3]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 35.97it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.54e+4, valid_loss=1.74e+3]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 34.92it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=1.74e+3]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=1.74e+3]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=1.74e+3]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 34.51it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=1.74e+3]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 33.87it/s, v_num=0, train_loss_step=1.29e+4, train_loss_epoch=1.27e+4, valid_loss=1.74e+3]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 32.91it/s, v_num=0, train_loss_step=1.29e+4, train_loss_epoch=1.29e+4, valid_loss=1.74e+3]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+4, train_loss_epoch=1.29e+4, valid_loss=1.74e+3]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+4, train_loss_epoch=1.29e+4, valid_loss=1.74e+3]\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 21.52it/s, v_num=0, train_loss_step=1.29e+4, train_loss_epoch=1.29e+4, valid_loss=1.74e+3]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 21.26it/s, v_num=0, train_loss_step=1.5e+4, train_loss_epoch=1.29e+4, valid_loss=1.74e+3] \n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.87it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54211)\u001b[0m \r                                                                      \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, v_num=0, train_loss_step=1.5e+4, train_loss_epoch=1.29e+4, valid_loss=3.47e+4]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s, v_num=0, train_loss_step=1.5e+4, train_loss_epoch=1.5e+4, valid_loss=3.47e+4] \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.75it/s, v_num=0, train_loss_step=1.5e+4, train_loss_epoch=1.5e+4, valid_loss=3.47e+4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54211)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m GPU available: True (cuda), used: True\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m Missing logger folder: /tmp/ray/session_2024-04-15_09-24-41_765139_1296/artifacts/2024-04-15_12-12-39/_train_tune_2024-04-15_12-12-39/working_dirs/_train_tune_23810e9c_10_dropout=0.3000,early_stop_patience_steps=5,ff_dim=32,h=5,input_size=30,learning_rate=0.0000,loss=ref_ph_de_2024-04-15_12-18-12/lightning_logs\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 2024-04-15 12:18:57.619517: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 2024-04-15 12:18:57.619574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 2024-04-15 12:18:57.621329: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 2024-04-15 12:18:59.551283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m   | Name          | Type                     | Params\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 0 | loss          | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 1 | valid_loss    | MSE                      | 0     \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 2 | padder        | ConstantPad1d            | 0     \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 3 | scaler        | TemporalNorm             | 0     \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 5 | mixing_layers | Sequential               | 8.3 K \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 6 | out           | Linear                   | 155   \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m -----------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 8.5 K     Trainable params\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 8.5 K     Total params\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m 0.034     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54424)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.770, train_loss_epoch=3.770]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 40.89it/s, v_num=0, train_loss_step=3.770, train_loss_epoch=3.770]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
            "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 48.00it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.140, train_loss_epoch=4.140]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.070, train_loss_epoch=5.070]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.410, train_loss_epoch=4.410]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.120, train_loss_epoch=4.120]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.230, train_loss_epoch=4.230]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780]\n",
            "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 30.32it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=3.780]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.630, train_loss_epoch=5.630]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.43e+12, train_loss_epoch=8.43e+12]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.590, train_loss_epoch=4.590]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 59.82it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=6.080]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.24it/s]\u001b[A\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=1.930]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.700, train_loss_epoch=5.700, valid_loss=1.930]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=1.930]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 35.29it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=3.820, valid_loss=1.930]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=1.930]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.730, train_loss_epoch=4.730, valid_loss=1.930]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=1.930]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.850, train_loss_epoch=4.850, valid_loss=1.930]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.730, train_loss_epoch=5.730, valid_loss=1.930]\n",
            "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 34.05it/s, v_num=0, train_loss_step=5.730, train_loss_epoch=5.730, valid_loss=1.930]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 56.38it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=3.320, valid_loss=1.930]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 35.03it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=1.930]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 61.80it/s, v_num=0, train_loss_step=4.480, train_loss_epoch=4.480, valid_loss=1.930]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 60.21it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=4.480, valid_loss=1.930]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=1.930]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=1.930]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=1.930]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=1.930]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=1.930]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070, valid_loss=1.930]\n",
            "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 45.76it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070, valid_loss=1.930]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=1.930]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.570, train_loss_epoch=3.570, valid_loss=1.930]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=1.930]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=1.930]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=1.930]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.470, train_loss_epoch=5.470, valid_loss=1.930]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=1.930]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.260, train_loss_epoch=4.260, valid_loss=1.930]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 26.09it/s, v_num=0, train_loss_step=4.060, train_loss_epoch=4.260, valid_loss=1.930]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.66it/s]\u001b[A\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=1.940]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.440, train_loss_epoch=4.440, valid_loss=1.940]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+12, train_loss_epoch=3.39e+12, valid_loss=1.940]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.830, train_loss_epoch=4.830, valid_loss=1.940]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.630, train_loss_epoch=4.630, valid_loss=1.940]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=1.940]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=1.940]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540, valid_loss=1.940]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.370, train_loss_epoch=4.370, valid_loss=1.940]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=1.940]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=4.350, valid_loss=1.940]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=4.800, valid_loss=1.940]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.150, train_loss_epoch=4.150, valid_loss=1.940]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.810, train_loss_epoch=4.810, valid_loss=1.940]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 65.56it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=4.530, valid_loss=1.940]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 42.50it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=1.940]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=1.940]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=1.940]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=1.940]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=1.940]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.080, train_loss_epoch=6.080, valid_loss=1.940]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=1.940]        \n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=1.940]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 46.56it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=1.940]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=1.940]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=1.940]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=1.940]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=1.940]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 49.82it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560, valid_loss=1.940]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560, valid_loss=1.940]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880, valid_loss=1.940]\n",
            "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 28.73it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12, valid_loss=1.940]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=2.29e+12, valid_loss=1.940]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=1.940]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 37.78it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.84e+12, valid_loss=1.940]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.95it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=2.030]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=2.030]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.400, train_loss_epoch=6.400, valid_loss=2.030]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.530, train_loss_epoch=4.530, valid_loss=2.030]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=2.030]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=2.030]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.400, train_loss_epoch=4.400, valid_loss=2.030]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=2.030]\n",
            "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 53.41it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=3.430, valid_loss=2.030]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=3.430, valid_loss=2.030]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590, valid_loss=2.030]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.500, train_loss_epoch=4.500, valid_loss=2.030]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 38.40it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=2.030]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200, valid_loss=2.030]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 52.01it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=2.030]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=2.030]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970, valid_loss=2.030]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.980, train_loss_epoch=4.980, valid_loss=2.030]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 35.88it/s, v_num=0, train_loss_step=3.990, train_loss_epoch=3.990, valid_loss=2.030]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=2.030]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=5.760, valid_loss=2.030]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=2.030]\n",
            "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 36.59it/s, v_num=0, train_loss_step=4.100, train_loss_epoch=4.100, valid_loss=2.030]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.100, train_loss_epoch=4.100, valid_loss=2.030]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.940, train_loss_epoch=3.940, valid_loss=2.030]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=2.030]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540, valid_loss=2.030]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.440, train_loss_epoch=4.440, valid_loss=2.030]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.100, train_loss_epoch=5.100, valid_loss=2.030]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 81.79it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=2.29e+12, valid_loss=2.030]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.72it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.720, train_loss_epoch=4.720, valid_loss=2.010]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.920, train_loss_epoch=3.920, valid_loss=2.010]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.270, train_loss_epoch=6.270, valid_loss=2.010]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 62.08it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.880, valid_loss=2.010]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=2.010]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.360, train_loss_epoch=4.360, valid_loss=2.010]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.600, train_loss_epoch=3.600, valid_loss=2.010]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.410, train_loss_epoch=6.410, valid_loss=2.010]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=2.010]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350, valid_loss=2.010]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+12, train_loss_epoch=3.76e+12, valid_loss=2.010]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=2.010]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=2.010]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=2.010]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200, valid_loss=2.010]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-15 12:19:14,946\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "2024-04-15 12:19:14,964\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
            "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
            "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
            "2024-04-15 12:19:14,974\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2024-04-15_12-12-39' in 0.0232s.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 61.57it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200, valid_loss=2.010]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 60.46it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=4.200, valid_loss=2.010]\rEpoch 486: 100%|██████████| 1/1 [00:00<00:00, 58.54it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=4.21e+12, valid_loss=2.010]\rEpoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=4.21e+12, valid_loss=2.010]        \rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=4.21e+12, valid_loss=2.010]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 90.81it/s, v_num=0, train_loss_step=4.21e+12, train_loss_epoch=4.21e+12, valid_loss=2.010]\rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 88.50it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.21e+12, valid_loss=2.010]   \rEpoch 487: 100%|██████████| 1/1 [00:00<00:00, 84.56it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=2.010]   \rEpoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=2.010]        \rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=2.010]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 84.42it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=2.010]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 82.23it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=4.090, valid_loss=2.010]\rEpoch 488: 100%|██████████| 1/1 [00:00<00:00, 78.91it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=2.010]\rEpoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=2.010]        \rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=2.010]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 69.47it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=2.010]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 67.47it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=3.520, valid_loss=2.010]\rEpoch 489: 100%|██████████| 1/1 [00:00<00:00, 64.41it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=2.010]\rEpoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=2.010]        \rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=2.010]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 58.32it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=2.010]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 57.27it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.880, valid_loss=2.010]\rEpoch 490: 100%|██████████| 1/1 [00:00<00:00, 55.38it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=2.010]\rEpoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=2.010]        \rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=2.010]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 84.76it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=2.010]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 82.61it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=2.860, valid_loss=2.010]\rEpoch 491: 100%|██████████| 1/1 [00:00<00:00, 79.39it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=2.010]\rEpoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=2.010]        \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=2.010]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 62.32it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=2.010]\rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 60.78it/s, v_num=0, train_loss_step=6.790, train_loss_epoch=3.870, valid_loss=2.010]\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rEpoch 492: 100%|██████████| 1/1 [00:00<00:00, 34.84it/s, v_num=0, train_loss_step=6.790, train_loss_epoch=6.790, valid_loss=2.010]\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rEpoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.790, train_loss_epoch=6.790, valid_loss=2.010]        \rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.790, train_loss_epoch=6.790, valid_loss=2.010]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 63.38it/s, v_num=0, train_loss_step=6.790, train_loss_epoch=6.790, valid_loss=2.010]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 62.07it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=6.790, valid_loss=2.010]\rEpoch 493: 100%|██████████| 1/1 [00:00<00:00, 60.07it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=2.010]\rEpoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=2.010]        \rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=2.010]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 62.95it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=2.010]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 61.63it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=3.420, valid_loss=2.010]\rEpoch 494: 100%|██████████| 1/1 [00:00<00:00, 59.67it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=2.010]\rEpoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=2.010]        \rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=2.010]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 79.93it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=2.010]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 77.74it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=2.920, valid_loss=2.010]\rEpoch 495: 100%|██████████| 1/1 [00:00<00:00, 74.14it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=2.010]\rEpoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=2.010]        \rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=2.010]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 82.35it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=2.010]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 80.24it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=7.780, valid_loss=2.010]\rEpoch 496: 100%|██████████| 1/1 [00:00<00:00, 76.88it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=2.010]\rEpoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=2.010]        \rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=2.010]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 77.19it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=2.010]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=3.130, valid_loss=2.010]\rEpoch 497: 100%|██████████| 1/1 [00:00<00:00, 71.92it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=2.010]\rEpoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=2.010]        \rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=2.010]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 82.07it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=2.010]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 79.86it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=4.660, valid_loss=2.010]\rEpoch 498: 100%|██████████| 1/1 [00:00<00:00, 76.35it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=2.010]\rEpoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=2.010]        \rEpoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=2.010]\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 59.44it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=2.010]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 58.07it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=2.790, valid_loss=2.010]\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.07it/s]\u001b[A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'valid_loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['valid_loss'])`.\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 1\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name          | Type                     | Params\n",
            "-----------------------------------------------------------\n",
            "0 | loss          | MSE                      | 0     \n",
            "1 | valid_loss    | MSE                      | 0     \n",
            "2 | padder        | ConstantPad1d            | 0     \n",
            "3 | scaler        | TemporalNorm             | 0     \n",
            "4 | norm          | ReversibleInstanceNorm1d | 12    \n",
            "5 | mixing_layers | Sequential               | 99.2 K\n",
            "6 | out           | Linear                   | 1.5 K \n",
            "-----------------------------------------------------------\n",
            "100 K     Trainable params\n",
            "0         Non-trainable params\n",
            "100 K     Total params\n",
            "0.403     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=54424)\u001b[0m \r                                                                       \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 23.76it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=2.790, valid_loss=2.070]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=2.070]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00, 22.70it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=2.070]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a140332c0764fef98a300fd6c54d057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63494692fc354b04a8d269a0bb666a56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d5a07512d00481f955b3c87c892770f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a90e910cb1465c984ed916c3dea0f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7715a83e0bf54c7ba69c139366c0b5a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6259321f98884886b95e431a43896461",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "884e4b212b94415e8a1edf40889cc3d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "380b45d6faa94335b4eec61f281cbe61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "165dbfc2a6ea4a44bd790132e6dfd0eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "996b2692601143ff84db735baf1c52c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23c44ebcad244fa18ec3d6897600968d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9deb334bf524c6faa5bf064a4e9fe93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36c90458ff3e4e30a831b5833a8ee040",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_size': 300, 'max_steps': 1000, 'val_check_steps': 100, 'early_stop_patience_steps': 5, 'learning_rate': 0.001935241312009601, 'n_block': 1, 'dropout': 0.9, 'ff_dim': 128, 'scaler_type': 'standard', 'n_series': 6, 'h': 5, 'loss': MSE(), 'valid_loss': MSE()}\n",
            "{'input_size': 30, 'hidden_size': 128, 'learning_rate': 1.679945606424186e-05, 'max_steps': 1000, 'batch_size': 32, 'scaler_type': 'standard', 'hist_exog_list': ('Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'), 'val_check_steps': 100, 'early_stop_patience_steps': 5, 'h': 5, 'loss': MSE(), 'valid_loss': MSE()}\n",
            "{'encoder_hidden_size': 100, 'context_size': 5, 'decoder_hidden_size': 64, 'learning_rate': 2.8343136523250105e-05, 'max_steps': 1000, 'batch_size': 32, 'h': 5, 'loss': MSE(), 'valid_loss': MSE()}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/neuralforecast/core.py:184: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from ray import tune\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "from neuralforecast.auto import AutoTSMixer, AutoTFT, AutoLSTM, AutoTCN\n",
        "from neuralforecast.losses.numpy import mse, mae\n",
        "\n",
        "horizon = 5 # prediction length\n",
        "\n",
        "TFT_config = {\n",
        "    \"input_size\": tune.choice([20, 30, 60, 90, 150, 300]),\n",
        "    # \"h\": horizon,\n",
        "    \"hidden_size\": tune.choice([64, 128]),\n",
        "    \"learning_rate\": tune.loguniform(1e-5, 1e-2),\n",
        "    \"max_steps\": tune.choice([ 1000]),\n",
        "    \"batch_size\": tune.choice([16, 32]),\n",
        "    \"scaler_type\": 'standard',\n",
        "    \"hist_exog_list\": ['Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'],\n",
        "    \"val_check_steps\": 100,                                                   # Compute validation every x steps\n",
        "    \"early_stop_patience_steps\": 5\n",
        "}\n",
        "\n",
        "LSTM_config = {\n",
        "    # \"input_size\": tune.choice([15, 30, 60, 90, 150, 300]),\n",
        "    # \"context_size\": tune.choice([5, 15, 30, 90, 200]),\n",
        "    # \"inference_input_size\": tune.choice([5, 15, 30, 90, 200]),\n",
        "\n",
        "    \"encoder_hidden_size\": tune.choice([20, 50, 100, 200]),\n",
        "    \"encoder_n_layers\": tune.choice([2, 3, 4]),\n",
        "    \"decoder_hidden_size\": tune.choice([30, 64, 128, 200]),\n",
        "    \"decoder_layers\": tune.choice([2, 3, 4]),\n",
        "    \"learning_rate\": tune.loguniform(1e-5, 1e-2),\n",
        "    \"max_steps\": tune.choice([ 1000]),\n",
        "    \"batch_size\": tune.choice([16, 32]),\n",
        "    \"scaler_type\": 'standard',\n",
        "    \"hist_exog_list\": ['Close', 'Open', 'High', 'Low', 'Volume', 'Marketcap'],\n",
        "    \"val_check_steps\": 100,                                                   # Compute validation every x steps\n",
        "    \"early_stop_patience_steps\": 5\n",
        "}\n",
        "\n",
        "TCN_config = {\n",
        "    \"encoder_hidden_size\": tune.choice([20, 50, 100, 200]),\n",
        "    \"context_size\": tune.choice([5, 10, 50]),\n",
        "    \"decoder_hidden_size\": tune.choice([64, 128]),\n",
        "    \"learning_rate\": tune.loguniform(1e-5, 1e-1),\n",
        "    \"max_steps\": tune.choice([500, 1000]),\n",
        "    \"batch_size\": tune.choice([16, 32]),\n",
        "}\n",
        "\n",
        "tsmixer_config = {\n",
        "    # \"h\": tune.choice([96,192]),\n",
        "    \"input_size\": tune.choice([15, 20, 30, 60, 90, 150, 300]),\n",
        "    \"max_steps\": tune.choice([500, 1000]),                             \n",
        "    \"val_check_steps\": 100,                                            \n",
        "    \"early_stop_patience_steps\": 5,                                    \n",
        "    \"learning_rate\": tune.loguniform(1e-5, 1e-2),                      \n",
        "    \"n_block\": tune.choice([1, 2, 4, 6, 8]),                           \n",
        "    \"dropout\": tune.choice([0.1, 0.3, 0.5, 0.9]),                      \n",
        "    \"ff_dim\": tune.choice([32, 64, 128]),                              \n",
        "    \"scaler_type\": 'standard',\n",
        "    \"n_series\": 6\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "model_TFT = AutoTFT(\n",
        "    h = horizon,\n",
        "    loss=MSE(),\n",
        "    config=TFT_config,\n",
        "    num_samples=10,\n",
        "    search_alg=HyperOptSearch(),\n",
        "    backend='ray',\n",
        "    valid_loss = MSE(),\n",
        ")\n",
        "\n",
        "model_LSTM = AutoLSTM(\n",
        "    h=horizon,\n",
        "    loss=MSE(),\n",
        "    config=LSTM_config,\n",
        "    num_samples=10,\n",
        "    search_alg=HyperOptSearch(),\n",
        "    backend='ray',\n",
        "    valid_loss = MSE(),\n",
        ")\n",
        "\n",
        "model_TCN = AutoTCN(\n",
        "    h = horizon,\n",
        "    loss=MSE(),\n",
        "    config = TCN_config,\n",
        "    num_samples=10,\n",
        "    search_alg=HyperOptSearch(),\n",
        "    backend='ray',\n",
        "    valid_loss = MSE(),\n",
        ")\n",
        "# tsmixerx_config = tsmixer_config.copy()\n",
        "model = AutoTSMixer(h=horizon,\n",
        "                    n_series=6,\n",
        "                    loss=MSE(),\n",
        "                    config=tsmixer_config,\n",
        "                    num_samples=10,\n",
        "                    search_alg=HyperOptSearch(),\n",
        "                    backend='ray',\n",
        "                    valid_loss=MSE())\n",
        "\n",
        "nf = NeuralForecast(models=[model], freq='D')\n",
        "nf_hist = NeuralForecast(models=[model_TFT, model_TCN], freq='D')\n",
        "\n",
        "df_hat_hist = nf_hist.cross_validation(df=df_hist, val_size=val_size,test_size=test_size, n_windows=None)\n",
        "df_hat = nf.cross_validation(df=df, val_size=val_size,test_size=test_size, n_windows=None)\n",
        "\n",
        "print(nf.models[0].results.get_best_result().config) # TSMIxer\n",
        "\n",
        "for model in nf_hist.models:\n",
        "    print(model.results.get_best_result().config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "AX4adPTmsOG-",
        "outputId": "f82dbe44-4e3f-48e8-e449-bb66b902f668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE TSMixer: 4557.103\n",
            "MSE TSMixer: 40657197.901\n",
            "MAE TFT: 2160.099\n",
            "MSE TFT: 10126363.741\n",
            "MAE TCN: 2265.218\n",
            "MSE TCN: 10097831.320\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_hat = df_hat.reset_index()\n",
        "df_hat = df_hat[df_hat[\"unique_id\"] == \"Close\"]\n",
        "\n",
        "df_hat_hist = df_hat_hist.reset_index()\n",
        "df_hat_hist = df_hat_hist[df_hat_hist['unique_id']=='Close']\n",
        "\n",
        "y_true = df_hat.y.values\n",
        "y_true_hist = df_hat_hist.y.values\n",
        "y_hat_tsmixer = df_hat['AutoTSMixer'].values\n",
        "\n",
        "y_hat_TFT = df_hat_hist['AutoTFT'].values\n",
        "y_hat_LSTM = df_hat_hist['AutoTCN'].values\n",
        "\n",
        "print(f'MAE TSMixer: {mae(y_hat_tsmixer, y_true):.3f}')\n",
        "print(f'MSE TSMixer: {mse(y_hat_tsmixer, y_true):.3f}')\n",
        "print(f'MAE TFT: {mae(y_hat_TFT, y_true_hist):.3f}')\n",
        "print(f'MSE TFT: {mse(y_hat_TFT, y_true_hist):.3f}')\n",
        "print(f'MAE TCN: {mae(y_hat_LSTM, y_true_hist):.3f}')\n",
        "print(f'MSE TCN: {mse(y_hat_LSTM, y_true_hist):.3f}')\n",
        "\n",
        "nf.save(path='/content/drive/MyDrive/Colab Notebooks/checkpoints',\n",
        "        model_index=None,\n",
        "        overwrite=True,\n",
        "        save_dataset=True)\n",
        "\n",
        "\n",
        "Y_plot = df_hat[df_hat['unique_id']=='Close']\n",
        "cutoffs = df_hat['cutoff'].unique()[::horizon]\n",
        "Y_plot = Y_plot[df_hat['cutoff'].isin(cutoffs)]\n",
        "\n",
        "Y_plot_hist = df_hat_hist[df_hat_hist['unique_id']=='Close']\n",
        "cutoffs_hist = df_hat_hist['cutoff'].unique()[::horizon]\n",
        "Y_plot_hist = Y_plot_hist[df_hat_hist['cutoff'].isin(cutoffs_hist)]\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(Y_plot['ds'], Y_plot['y'], label='True')\n",
        "plt.plot(Y_plot['ds'], Y_plot['AutoTSMixer'], label='TSMixer')\n",
        "plt.plot(Y_plot['ds'], Y_plot_hist['AutoTFT'], label='TFT')\n",
        "plt.plot(Y_plot['ds'], Y_plot_hist['AutoTCN'], label='TCN')\n",
        "plt.xlabel(f'Datestamp with horizon = {horizon}')\n",
        "plt.ylabel('Close')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01c0258d0be244f59ac78a4b52a40ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f2fa71e5264449b89d2b2b3f9937905",
            "placeholder": "​",
            "style": "IPY_MODEL_7bfafc935af9491e9f897adb8ec90b02",
            "value": " 1/1 [00:00&lt;00:00, 21.67it/s]"
          }
        },
        "0243f6e217064362890ad570a2e2d3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0392aed543b445bcb66b90a2577a29e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76dfc5e3bce24d18858c5b6105926169",
            "placeholder": "​",
            "style": "IPY_MODEL_e87970266d334b84836d87d528eb3d96",
            "value": " 1/1 [00:00&lt;00:00, 89.46it/s]"
          }
        },
        "03d47cd6dfe0404d92c2579cbe57189d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "03ec87dec3f945abb70e865657139d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05f87bf5978c4a08826e92a58fd81602": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061e647c50a24bc08357c69de8f09354": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375a0ec91b004d3aa211aec683338b66",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_417108b53a8d4de6a99407d21abd76c3",
            "value": 1
          }
        },
        "06459e421d064d71887b77cd3a08ac47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d3176fc3184a09b97f89cb36a99c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6a17a042ccc4587a6762cd409719539",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76b593bed29948898776d16bb92198c2",
            "value": 1
          }
        },
        "089e2a876b604830b09cf574e1c15058": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9530810832cf413a8d3059b7dd834b99",
            "placeholder": "​",
            "style": "IPY_MODEL_76a23162de3247e880e28af6ce3522c3",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "08a18304fc1f4f1b8595381981d5006e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "09f3466c17d6452696052e90117446cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a140332c0764fef98a300fd6c54d057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67c4f5be243b4ff69667a36649e564ec",
              "IPY_MODEL_ccbaa8ef204a4fbe9098842ef7717ff6",
              "IPY_MODEL_82d5478a31f846819368c15e6a8ac16e"
            ],
            "layout": "IPY_MODEL_4f35946222964c8e8f91bfee6c7bf64e"
          }
        },
        "0a7bf938b9094a8289b0f918a632c2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37399682634648c382ab395941c5a9a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f475abd6e69343fab625f4cd9ce4cf51",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "0ad70785c37e41eca3e039f140eb9662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b10a8a343de4707b701b235b12cdf03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cbfde68abe64cc98bd2f1a7b297bd32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "0d87d95890854bbc90db37b2e8733152": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9be86c646140d6806542120810db86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0efabcaa90f248fda543b46c76977ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0a7649d328343d5ab8ad921ef22f621",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac276a1b8ad34a3f92d4b8d2a282ae9f",
            "value": 1
          }
        },
        "0f4579a3222c404b8ceea69844f904fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "11bc24de762a4b4f958bd664c4457abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b558589adcc34a29ae2e56626f245ab0",
            "placeholder": "​",
            "style": "IPY_MODEL_a0b1830e6109429faf422115ba502e2e",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "14415c83a38f4455aace4d6b5f57631a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f903862487d64139805e0dfbe52ca145",
            "placeholder": "​",
            "style": "IPY_MODEL_c1a825e9a1c7458fa32d5e6f6345646d",
            "value": " 1/1 [00:00&lt;00:00, 19.02it/s]"
          }
        },
        "14c40ec992bd40de94632eab31afe895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4114a7ef656c4eadb22beab53dedf911",
            "placeholder": "​",
            "style": "IPY_MODEL_20c6db04a7c64c1a84eecafed7632c79",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "14df87c7082d4ae490c2439473cfe2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9148c9fc52a425aa33b534c60b7aefc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4053f5f90a5f487889063f13520bbb96",
            "value": 1
          }
        },
        "151ef0c93a1a438c80cecb7e579c3bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4794f0316094b31964f49c4199c690b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89ff8fbb64e84600baea748215525e9e",
            "value": 1
          }
        },
        "153986e96841451c93b60248f2b285be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "16487311acee4fccb6a25860125e1846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c598fb294fa3454faeff04e8e5a1c1c2",
            "placeholder": "​",
            "style": "IPY_MODEL_bfdf750c48cd4dfcaa211d60446b3d1c",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "165dbfc2a6ea4a44bd790132e6dfd0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14c40ec992bd40de94632eab31afe895",
              "IPY_MODEL_2bd94e82d7e54cf9b35230360e9196a4",
              "IPY_MODEL_9b6b4ca2b8f34eb0975e0481116f78ce"
            ],
            "layout": "IPY_MODEL_63a39cd4cf2e4eeabb8621b06600456b"
          }
        },
        "178c1f9180a04894868ec23758d80953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a09d36e9916468b911970627d51714d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40d4a56348c742a599f1cd2b7164cd90",
            "value": 1
          }
        },
        "1810e9efc4d74f1eae286129cb485115": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "18267b0f10d047dea212da683cb60122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc3a3853768f4172a4c907c5e66ff278",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7292b7c981b41478109befb78b9503f",
            "value": 1
          }
        },
        "1838634f5c0b4554a3dccb3fc889478c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6bfe2f318dc4f02a9bc1c677bfa0ecb",
            "placeholder": "​",
            "style": "IPY_MODEL_808601e8d8bb418a862546fb12c20d70",
            "value": " 1/1 [00:00&lt;00:00, 10.14it/s, v_num=12, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.237]"
          }
        },
        "18e69d6698d9473d84b5c051b3578731": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d58801668ea74c6c87774e1dd348362d",
              "IPY_MODEL_901e6d1d2572496e8291a15db6a9841a",
              "IPY_MODEL_a40057fe9eca49e292489bf26a34fc67"
            ],
            "layout": "IPY_MODEL_e9155b59d10741bcb764ed18fad52ff5"
          }
        },
        "1904736262054fb99e553e74814a568e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d00f667624584c39820e44c45547d000",
            "placeholder": "​",
            "style": "IPY_MODEL_9ba221c0cc47458fa428d83976bcb28e",
            "value": "Epoch 999: 100%"
          }
        },
        "1a22c48c7e4e4fbba1799998ef1f6269": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "1afd6a8292d44193bebf7e2c30e07ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d846d1029ff47848f6a07f39b237edf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1edc3b3e658b4bbe85e2ed2ad28493fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fb34c34a3024169858017da48f50675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ea4c80e99c4c3e8853158efc1507af",
            "placeholder": "​",
            "style": "IPY_MODEL_944b2f39224d4f19b737dce9f8534026",
            "value": " 1/1 [00:00&lt;00:00, 98.92it/s]"
          }
        },
        "1fcb6c8a4ca741b3bf044100d4d16b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd9ba496bca4a28a951b03aad04cd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_418df34098364a79b5b79abfc79df558",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9cf9e7d360d47219535e5d6220f9697",
            "value": 1
          }
        },
        "20c6db04a7c64c1a84eecafed7632c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20d6fa072b1545a3b2b9e85b0ea2d1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21596f8530654b65b80549efdf076b27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220028e6fa83441eb886e50753b99ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234ccc43194344109b9d67a6d0cfb054": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c44ebcad244fa18ec3d6897600968d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_646e19c5ca4a4035922a5f4dcf3a8b0c",
              "IPY_MODEL_151ef0c93a1a438c80cecb7e579c3bc5",
              "IPY_MODEL_93718e94a846405ab6b7da0c7ec8d402"
            ],
            "layout": "IPY_MODEL_c89569f61eab4f6993f48dba53473b2a"
          }
        },
        "244b08b3a47c4e799e4a4e72a5587031": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248a9c52405b4caa8c0432abcf20e60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2637d0594e6d428f9280f63bf15b0a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4f7dbe8a184e2ea20e710028440057",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_900d57413de0498389f1353184a1ddd2",
            "value": 1
          }
        },
        "26717562be6c41cda806e5ca45b67e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2694e5b3d20b4cb6a1ad8cf4e6d009f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26dc641655c242c788f321da2045a526": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2741a2e820a240ce9cb0e634dd7ccb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a767ae701f4c41f0ae0c54b07359b685",
            "placeholder": "​",
            "style": "IPY_MODEL_38de685e8f844c9ca7ae6afaf5933009",
            "value": " 1/1 [00:00&lt;00:00, 105.21it/s]"
          }
        },
        "27679796363742db811e5539149a3b81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "27c8c91c01f24872b8237f72605192af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21596f8530654b65b80549efdf076b27",
            "placeholder": "​",
            "style": "IPY_MODEL_7fc36ba62d0a4b329308438b5f7cd956",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "2832d58105744a9db3c91b114ec27ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28b2a575b3c445e7ad2a9e1767834f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7211dc11c5654e198a30a93a5f7e8cde",
              "IPY_MODEL_99e86865a30f472f86faf1f10c5d2453",
              "IPY_MODEL_560b1a3533ee45f9aa4a5ad3dd731d77"
            ],
            "layout": "IPY_MODEL_c60d681f07fa4cef9c4d98982d6c3363"
          }
        },
        "2921b4e0b0cf426ea272e72e287bcec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d759a4fc9fe4f6b97349c1d4c619363",
            "placeholder": "​",
            "style": "IPY_MODEL_fdcaf8601ac74fbf967567c94b401f65",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "29bf837d68144d8e8eb826fd7b49ddcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27c8c91c01f24872b8237f72605192af",
              "IPY_MODEL_4487f430654946fa9d2a42085a82446f",
              "IPY_MODEL_2741a2e820a240ce9cb0e634dd7ccb7e"
            ],
            "layout": "IPY_MODEL_f4dbfa859f0b4923bf768d01eb1483dc"
          }
        },
        "29d3389e4973405ab5f12145742e991e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bca14345673c42cd9397081c1395497a",
              "IPY_MODEL_e1de86e5a1ed41f981fa01ba3e131d3c",
              "IPY_MODEL_749c5eaefa1843919661b84f40fc57aa"
            ],
            "layout": "IPY_MODEL_f30674e2ae4f450995c7da77a4db8cb4"
          }
        },
        "29fa1e8d0c2d4039b84aa140798f7d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a099d1dcf3b4c3fa47a83878d15d63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29fa1e8d0c2d4039b84aa140798f7d7f",
            "placeholder": "​",
            "style": "IPY_MODEL_2d80fe25601d42f086d5445a4bb13f7f",
            "value": " 1/1 [00:00&lt;00:00, 97.82it/s]"
          }
        },
        "2b5859bae48b4d29807d6fb6db116164": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e6c8d964d147169f17bea79e8ed11e",
            "placeholder": "​",
            "style": "IPY_MODEL_943ed872d8c942eca0e38ed2f94c0e4b",
            "value": " 1/1 [00:00&lt;00:00, 39.94it/s]"
          }
        },
        "2bd94e82d7e54cf9b35230360e9196a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce12a43e1023423586a6d9331c658781",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3931e9ba6c8b4c8da9dd6451f2fb1ebb",
            "value": 1
          }
        },
        "2d4a4728476744da9381dd9c03673ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ff65c9c98545c397294c2e68954402",
            "placeholder": "​",
            "style": "IPY_MODEL_0e9be86c646140d6806542120810db86",
            "value": " 1/1 [00:00&lt;00:00, 22.27it/s]"
          }
        },
        "2d80fe25601d42f086d5445a4bb13f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2da55f14dc0a437393217d20c53686d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16487311acee4fccb6a25860125e1846",
              "IPY_MODEL_734fb725e3e346269a277b2e1e1110a6",
              "IPY_MODEL_14415c83a38f4455aace4d6b5f57631a"
            ],
            "layout": "IPY_MODEL_ef59f0614c334de388d1dbfb5a78ad40"
          }
        },
        "2dceac5e3f804d46bffa43138937fa29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4660413d43b34a638179efa0d937768e",
            "placeholder": "​",
            "style": "IPY_MODEL_de3cbd9cf06746a88fd1096bbc790313",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "2df14cda66d4410aafb03c3dd82dfeac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb514b7b7894c28b5a4eb10717700d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3f595794bb4df2b098c48a91abebdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fbe924419fb45688951bbc25c182e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "315aed6536ae418093ec5f8f9deb95b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "330e130fcd7947828ae247ad6f57939c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "336c1523c65944c79779037f4c07e1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33c94829601346e1b2882afddfcf44eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ae544d591a4b6a9514c9f77678a382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d80299d5e9ab4b3b9b52a4452cc5fc12",
            "placeholder": "​",
            "style": "IPY_MODEL_3c65d0d66aa148cdbb1b7d75abd33184",
            "value": " 1/1 [00:00&lt;00:00, 10.51it/s, v_num=10, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.8e+5]"
          }
        },
        "369d1e19491d435d80576b423ffb2f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_472f8a80cd8e4f3aa4c07d1a0ef8ce24",
            "placeholder": "​",
            "style": "IPY_MODEL_ab9ef85eba744c26a74d843735647d23",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "36c90458ff3e4e30a831b5833a8ee040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f62ea21bec114fad99a0973514658c45",
              "IPY_MODEL_2637d0594e6d428f9280f63bf15b0a7c",
              "IPY_MODEL_cd8e4da88dc14e468be8481024c07780"
            ],
            "layout": "IPY_MODEL_d3b055d443384b7a954eb0404a0aa354"
          }
        },
        "37399682634648c382ab395941c5a9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375a0ec91b004d3aa211aec683338b66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380b45d6faa94335b4eec61f281cbe61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6438971840d44b1906122c69019d69e",
              "IPY_MODEL_1fd9ba496bca4a28a951b03aad04cd70",
              "IPY_MODEL_d1bb9d9efae94b45943752acbb036b30"
            ],
            "layout": "IPY_MODEL_6fdc77b6b0814d04a2d1e2cbc66f06f8"
          }
        },
        "38de685e8f844c9ca7ae6afaf5933009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3931e9ba6c8b4c8da9dd6451f2fb1ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b4f7dbe8a184e2ea20e710028440057": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c65d0d66aa148cdbb1b7d75abd33184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c875707602d4a83a624eed3be821145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8127e5af5446f0a41340f79a9f4093",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d14d424a3364a0f8f8156a60a7d5373",
            "value": 1
          }
        },
        "3cba65e025154b0caa7f2ff6093862be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d14d424a3364a0f8f8156a60a7d5373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d572eb78c3b4bfe9c2cdd19bb2bb0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d759a4fc9fe4f6b97349c1d4c619363": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa3871e5a9540f1aed3676a452e52be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3d164637f04dcdaeb7c7cf192b51f4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d1430f2047243f68b55802312cea44f",
            "value": 1
          }
        },
        "3fc9b122eb1045d3be60f091414d8aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4053f5f90a5f487889063f13520bbb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40d4a56348c742a599f1cd2b7164cd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4114a7ef656c4eadb22beab53dedf911": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417108b53a8d4de6a99407d21abd76c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "418df34098364a79b5b79abfc79df558": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424879471988468395f4b3c436a2d38d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439badf400f444f6bd2f934a3d329e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "43de3ff5f5f04af491d2d16bad0d4a47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4487f430654946fa9d2a42085a82446f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bde38cecf5b9413792be89ef1628ca64",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_336c1523c65944c79779037f4c07e1e2",
            "value": 1
          }
        },
        "45cdd59829a34c5b9b330358747ac571": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4660413d43b34a638179efa0d937768e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468faca8d58e417696ac24a8d01289bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "472f8a80cd8e4f3aa4c07d1a0ef8ce24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47450da0f1b442be96063d203780ed11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480316054bdd4de6ac8ce41fd1f8878c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a90e910cb1465c984ed916c3dea0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53a0ebfc26f94540adf398b634a3cbba",
              "IPY_MODEL_de02f0211cde4193827e0f21501365af",
              "IPY_MODEL_2a099d1dcf3b4c3fa47a83878d15d63b"
            ],
            "layout": "IPY_MODEL_03d47cd6dfe0404d92c2579cbe57189d"
          }
        },
        "49ebec869eda402eb08ca11c8ffb6110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a7671f093c1412db740ee2f6c45ce17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1d64ce5d294b75a252224e7c84ed90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "4c628ed35b264f88b15b51595f07cac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cca7fd00604480da1f7472a0336f10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2694e5b3d20b4cb6a1ad8cf4e6d009f3",
            "placeholder": "​",
            "style": "IPY_MODEL_8e3326f74d10465b970a87b0d0bbd343",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "4d4d2d17d7f94a64838fec097db7e257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dbf54ba20614cab8469d8f6dc08b10f",
            "placeholder": "​",
            "style": "IPY_MODEL_248a9c52405b4caa8c0432abcf20e60b",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "4dc0c3788f10444eb1a088d3c813973b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e3a4adefd2d4a63ab7c4f46e01e9e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e53e62f358541ecb670674aa8722686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ee99e8e0e55441599e6d5b520ca38d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2fa71e5264449b89d2b2b3f9937905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f35946222964c8e8f91bfee6c7bf64e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "4f465cee6db7449dbf3ae185b5100ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b37bfb9315204c5aa9d0117c12558818",
              "IPY_MODEL_b72cec6baa8547fb9b8eab9d475d7959",
              "IPY_MODEL_a3ae553d48004c2ca3d8c4c22557bce7"
            ],
            "layout": "IPY_MODEL_c4b6f13e10884b6bb85ccd10f8ef2725"
          }
        },
        "4f64956bac0a4adeaf906099a0d4967d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0a21911fbc044878bd2921bba0dd38b",
            "placeholder": "​",
            "style": "IPY_MODEL_ab93933f7a844dbbabdbfc83c739042b",
            "value": " 1/1 [00:00&lt;00:00, 69.30it/s]"
          }
        },
        "50f8b469487242989b68a28d4a5b2a92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b23169f4a943a8a02292646ed5a92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53118e1332d340a2846eb4f43cdcc651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e610b376ba492b84b7038375737854",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ed17e6eafcc4988b579c958ddf7089b",
            "value": 1
          }
        },
        "53a0ebfc26f94540adf398b634a3cbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fcb6c8a4ca741b3bf044100d4d16b3a",
            "placeholder": "​",
            "style": "IPY_MODEL_8367cfedbfc648df8b3b0627c14332a1",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "54a454f89eae4132934dd16975e282c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54db724c799d406c81fe4b5e9c23d8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "560b1a3533ee45f9aa4a5ad3dd731d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910d27c8e79345559a55cc198a3ca627",
            "placeholder": "​",
            "style": "IPY_MODEL_fc19db9f545b4f85ac249946c39305df",
            "value": " 1/1 [00:00&lt;00:00, 20.25it/s]"
          }
        },
        "5721536c88b7442790eb3ccea33208b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "585b588e976f492aba8f9a4ec36195ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5909522787004abca779581282006e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cba65e025154b0caa7f2ff6093862be",
            "placeholder": "​",
            "style": "IPY_MODEL_20d6fa072b1545a3b2b9e85b0ea2d1b3",
            "value": " 1/1 [00:00&lt;00:00, 17.22it/s]"
          }
        },
        "590d52c54d384e3dab3d64de9c2b1e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd78a12011f2488c89904dbf3ce7ad52",
              "IPY_MODEL_178c1f9180a04894868ec23758d80953",
              "IPY_MODEL_eaa88f098e044ebfb37eaa0e69500b50"
            ],
            "layout": "IPY_MODEL_153986e96841451c93b60248f2b285be"
          }
        },
        "5985885d001b4ddfb650b5a83fae62aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59f8a2b5e30e4788bc8a1ca8dc173f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a09d36e9916468b911970627d51714d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a27d834d1394d0197d5cca2f7455a71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3d164637f04dcdaeb7c7cf192b51f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb9fbee65c14e2eb300fa86c9034dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d5a07512d00481f955b3c87c892770f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3ae9078b6af43cda8ddbc57e619ab82",
              "IPY_MODEL_b1fd15489f9641eb9e256be00c680370",
              "IPY_MODEL_b77b64a217f64fe38792cf7dfbdf06e9"
            ],
            "layout": "IPY_MODEL_63536c34a61344b99536d0f29191a823"
          }
        },
        "5db9b537c624470584b643aa37e9ddfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3cf5bf63d304c97a42cce7d034b3345",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8e51e52c43d46aca03975e59453c648",
            "value": 1
          }
        },
        "5f164c6d87544c718588913312260173": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf821fca3c6947cd96cb48dcc1c07873",
            "placeholder": "​",
            "style": "IPY_MODEL_a3e55e1af1c74facb9d9aba0d91c3a1a",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "5fa461376eeb4c3a96c2f29168e8b91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d8fe37a98e44828070a3e520e0ab39",
            "placeholder": "​",
            "style": "IPY_MODEL_d54507794f40428fbb052757d79d8eb9",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "5fa9840537ad4d3e8765feb6dfe82b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75605b0830494d88b730aad04bfd1388",
            "placeholder": "​",
            "style": "IPY_MODEL_c814793272e24febb3d1eed1161fc4e9",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "5fd5db257dce49e3b1f241ef3ea9ad13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff44a0257114af28eb339785b543f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c243f7261cb64f72ab2e542fcc2201d6",
            "placeholder": "​",
            "style": "IPY_MODEL_f4e9a150cc814cad9fb4f25dc12c50ec",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "600ab214cab342ba987ffb7f1f96447e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60fabf94c96d4828aee35da5b83efe38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a64adecd8c4693ba79a01bc775579c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61be583f9d8a46a9bc1aa5999045b598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61e43b4243f6407e8c6a9caf9a82c5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26dc641655c242c788f321da2045a526",
            "placeholder": "​",
            "style": "IPY_MODEL_9ec4bd8dab764fb1b4789ac5cf13ef7f",
            "value": " 1/1 [00:00&lt;00:00, 102.43it/s]"
          }
        },
        "6213c97e6256433ab3bdb80668f90bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f8b469487242989b68a28d4a5b2a92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1954bd01c954f9ea3f4c4087d6cf72a",
            "value": 1
          }
        },
        "6259321f98884886b95e431a43896461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dceac5e3f804d46bffa43138937fa29",
              "IPY_MODEL_6213c97e6256433ab3bdb80668f90bb8",
              "IPY_MODEL_c61e8fe425934c44ada1746bd80e6c9a"
            ],
            "layout": "IPY_MODEL_dcb4090a99684c8ca7fcb3ae588fffd2"
          }
        },
        "62cbf39333ba4b7198fd62361e0511df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63494692fc354b04a8d269a0bb666a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_797c39d609fc489c98cfc992e43005d2",
              "IPY_MODEL_06d3176fc3184a09b97f89cb36a99c0c",
              "IPY_MODEL_1838634f5c0b4554a3dccb3fc889478c"
            ],
            "layout": "IPY_MODEL_08a18304fc1f4f1b8595381981d5006e"
          }
        },
        "63536c34a61344b99536d0f29191a823": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "63a39cd4cf2e4eeabb8621b06600456b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "646e19c5ca4a4035922a5f4dcf3a8b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c07b322a7ffc41c983099879e302e4a4",
            "placeholder": "​",
            "style": "IPY_MODEL_54db724c799d406c81fe4b5e9c23d8f8",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "6626124e4dcc4fc18a69154a2a47e1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6764d8d739484907886629b42ba4e3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "67c4f5be243b4ff69667a36649e564ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95af02a6f72430f94036d95f855f053",
            "placeholder": "​",
            "style": "IPY_MODEL_a02538b89fc94a8687e972e34de862c2",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "69d7d9944c764722bd3555eb7a055a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69ed4177475e4e86b6f79cf209441c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aaae3a447384f41aa05b2bbdeeda43a",
            "placeholder": "​",
            "style": "IPY_MODEL_a21ec122a4ca4a62ba0633a8b70b4bea",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "6a30be8b77df4ad0aa32af1bf67ff5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd6ffd0e51624bb9b50741a3270c799a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_330e130fcd7947828ae247ad6f57939c",
            "value": 1
          }
        },
        "6aca17b7da9c414b9fc1f60a5c1b0c90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1430f2047243f68b55802312cea44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dbf54ba20614cab8469d8f6dc08b10f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6deaf7be1e8e45648f151fdc6048bcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e42d5c165a644eebe8399e9e9053b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6edd5e812a744663800139af707923dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8d54cd4279c4248917ffbc6615aabc5",
              "IPY_MODEL_0efabcaa90f248fda543b46c76977ba3",
              "IPY_MODEL_da957921a1fc49cbbc2c97de54119436"
            ],
            "layout": "IPY_MODEL_27679796363742db811e5539149a3b81"
          }
        },
        "6fb4a408966b4a4ba31a6e1319827ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "6fdc77b6b0814d04a2d1e2cbc66f06f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "7136946b70bf4718a17a70a88631b136": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7211dc11c5654e198a30a93a5f7e8cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828b69e1cc3c4182b2ecc06c1aba71c0",
            "placeholder": "​",
            "style": "IPY_MODEL_03ec87dec3f945abb70e865657139d99",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "725ce44d7b6d4c3eb2db9afc15ba43c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ae7a272e28437fb8df1fad199843c5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5985885d001b4ddfb650b5a83fae62aa",
            "value": 1
          }
        },
        "730e40e695bf4a49b8baa703627980b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734fb725e3e346269a277b2e1e1110a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54a454f89eae4132934dd16975e282c4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49ebec869eda402eb08ca11c8ffb6110",
            "value": 1
          }
        },
        "7351c01db076435f91cc08b5d6ca5ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "742b84f46b1d49d5b4b670de816061fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "749c5eaefa1843919661b84f40fc57aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caeedf4048d74ef08a94e036e61196d2",
            "placeholder": "​",
            "style": "IPY_MODEL_efb5354d8e1b4b518c800ac79ed92aba",
            "value": " 1/1 [00:00&lt;00:00, 24.79it/s]"
          }
        },
        "75605b0830494d88b730aad04bfd1388": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c4e3a8d14c4ddabae2f8f8e2e58e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76a23162de3247e880e28af6ce3522c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76b593bed29948898776d16bb92198c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76dfc5e3bce24d18858c5b6105926169": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7715a83e0bf54c7ba69c139366c0b5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f164c6d87544c718588913312260173",
              "IPY_MODEL_eaf1fb87bc6f46eb973504035f262d8f",
              "IPY_MODEL_1fb34c34a3024169858017da48f50675"
            ],
            "layout": "IPY_MODEL_439badf400f444f6bd2f934a3d329e08"
          }
        },
        "7774e5a7ba6f459794dba792f587d09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47450da0f1b442be96063d203780ed11",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc4cf71ddbf148c382110e3a3c974c53",
            "value": 1
          }
        },
        "784b93aa7a714cdf8920153b4e02be64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "797c39d609fc489c98cfc992e43005d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7974f94d49d48e6963d0d66e18b4e3e",
            "placeholder": "​",
            "style": "IPY_MODEL_4dc0c3788f10444eb1a088d3c813973b",
            "value": "Epoch 999: 100%"
          }
        },
        "7bfafc935af9491e9f897adb8ec90b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c828918797d470b92b6d27454e27659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ca13cc2e0864ea1954c1e3a0a0e1f38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb44a2904db4e2f93600c0481548bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df14cda66d4410aafb03c3dd82dfeac",
            "placeholder": "​",
            "style": "IPY_MODEL_f851de7d640b4b318f41a0f4bcea1e26",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "7d7d4d0aeb324aa8a8498dbcda28494d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7df6f389645f4c51bae24425a554e937": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2a96d723bb458291a82d06991be8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec02028674641c1ae444c4ae1b49af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f54ef2c798b47efafe1b36e54f05fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f8db368217e4023aa98ea90257cee2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbafce3eb5c64fd8baad140fc1a7a907",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_600ab214cab342ba987ffb7f1f96447e",
            "value": 1
          }
        },
        "7fc36ba62d0a4b329308438b5f7cd956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808601e8d8bb418a862546fb12c20d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80d2456c79254c64ae52ec228835ede5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_585b588e976f492aba8f9a4ec36195ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f3f595794bb4df2b098c48a91abebdb",
            "value": 1
          }
        },
        "80e6c8d964d147169f17bea79e8ed11e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828b69e1cc3c4182b2ecc06c1aba71c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d5478a31f846819368c15e6a8ac16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb76150cad04b76bf0851c198a23c71",
            "placeholder": "​",
            "style": "IPY_MODEL_e307566bdcf34df395ae9c8ac690f623",
            "value": " 1/1 [00:00&lt;00:00, 68.52it/s]"
          }
        },
        "83052c10943f40eca294160d2c0a74e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdb8ff8f88694cbeb2b0dc926f80cbfa",
              "IPY_MODEL_53118e1332d340a2846eb4f43cdcc651",
              "IPY_MODEL_866cbf66d95d40f981c6f16d64fdc2ee"
            ],
            "layout": "IPY_MODEL_0f4579a3222c404b8ceea69844f904fb"
          }
        },
        "8367cfedbfc648df8b3b0627c14332a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8398dc3c32584a689d5101da34bce8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "862584a872794d3b8cdae90781030b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d66d6340086471a9f883963a9d636be",
            "placeholder": "​",
            "style": "IPY_MODEL_69d7d9944c764722bd3555eb7a055a60",
            "value": " 1/1 [00:00&lt;00:00, 31.01it/s]"
          }
        },
        "866cbf66d95d40f981c6f16d64fdc2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6626124e4dcc4fc18a69154a2a47e1ce",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d1010e3f534c64ac9fd6eb009a2b69",
            "value": " 1/1 [00:00&lt;00:00,  4.11it/s]"
          }
        },
        "86898c8037dd444d9ae70d1ac948abf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a7bf938b9094a8289b0f918a632c2ae",
              "IPY_MODEL_b6a236757b7f46c7ba3ae9eae27d2454",
              "IPY_MODEL_93c55be65eff41b786c7b48c3da35a5c"
            ],
            "layout": "IPY_MODEL_9f896233b1b24abc95508b5cdeb445a9"
          }
        },
        "86fccb9d34d04290b636b9ffa424f951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f29d27e054945f39dd56de5d4ee289d",
            "placeholder": "​",
            "style": "IPY_MODEL_480316054bdd4de6ac8ce41fd1f8878c",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "884e4b212b94415e8a1edf40889cc3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea1e5528647e4368b691506a588fd3d7",
              "IPY_MODEL_7774e5a7ba6f459794dba792f587d09b",
              "IPY_MODEL_4f64956bac0a4adeaf906099a0d4967d"
            ],
            "layout": "IPY_MODEL_6fb4a408966b4a4ba31a6e1319827ba5"
          }
        },
        "89fde10ce594480480f6183b430f96a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1904736262054fb99e553e74814a568e",
              "IPY_MODEL_3c875707602d4a83a624eed3be821145",
              "IPY_MODEL_a308d819a7664282a58d0e65654e7b40"
            ],
            "layout": "IPY_MODEL_ff977f2ee76447d998775909ac5315ad"
          }
        },
        "89ff8fbb64e84600baea748215525e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8aaae3a447384f41aa05b2bbdeeda43a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aff5a3bb541412c9f5d8ee25e3897ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb514b7b7894c28b5a4eb10717700d1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed82fe31a434473c999108f174559351",
            "value": 1
          }
        },
        "8c51aa9adba54dc892ad27b4a28fcbb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c84716f10bf44d2a8851b36b2bda630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d87d95890854bbc90db37b2e8733152",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6deaf7be1e8e45648f151fdc6048bcfe",
            "value": 1
          }
        },
        "8cadf25f287a42a48dccd939c398da98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "8d10ca5cf9984c77af16d7c4102bda66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c13e2c8213bd421c80c98d8f647cd743",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6da8637f6c34f12ab896f092e76dd58",
            "value": 1
          }
        },
        "8e3326f74d10465b970a87b0d0bbd343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e6ab6d506b44556a7167a8d9e1fb4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f71c0d756bd646c892bb1b8db854191c",
              "IPY_MODEL_c41680fda2f446eca453c748a382fde5",
              "IPY_MODEL_ba9b59151532432d8013ad6b6bc9a49d"
            ],
            "layout": "IPY_MODEL_9403863cd9324593a344c1795a05f332"
          }
        },
        "8e6f19c4db344495bfcf9fad1047447c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f29d27e054945f39dd56de5d4ee289d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f507054eb4243d5b6a720de750ef5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8f5a04f6779345d9ad0fdba6973ed396": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fca995a7d1c44c6a7c00537b38a89df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15d9f560f4a4439b5844f988144efae",
            "placeholder": "​",
            "style": "IPY_MODEL_9710008f90d24d0abbec776c40f0d911",
            "value": " 1/1 [00:00&lt;00:00, 134.27it/s]"
          }
        },
        "900d57413de0498389f1353184a1ddd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "901e6d1d2572496e8291a15db6a9841a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c628ed35b264f88b15b51595f07cac8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f5a04f6779345d9ad0fdba6973ed396",
            "value": 1
          }
        },
        "905a1a2bb5ff4a81aace76ad18c4e624": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ac560e7ae74b8ebc656a778d68a355": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910d27c8e79345559a55cc198a3ca627": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925ab74e6da74e67b4a2e0e990aef422": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "93042eaa33404375ac99b95ee0e7f549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7b3545c608247309e28eede5b9b5f17",
              "IPY_MODEL_7f8db368217e4023aa98ea90257cee2b",
              "IPY_MODEL_862584a872794d3b8cdae90781030b27"
            ],
            "layout": "IPY_MODEL_1a22c48c7e4e4fbba1799998ef1f6269"
          }
        },
        "93718e94a846405ab6b7da0c7ec8d402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47abe7a16d3451bbe367da4c3c1beb0",
            "placeholder": "​",
            "style": "IPY_MODEL_1afd6a8292d44193bebf7e2c30e07ad5",
            "value": " 1/1 [00:00&lt;00:00, 97.79it/s]"
          }
        },
        "93c55be65eff41b786c7b48c3da35a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d846d1029ff47848f6a07f39b237edf",
            "placeholder": "​",
            "style": "IPY_MODEL_5cb9fbee65c14e2eb300fa86c9034dc5",
            "value": " 1/1 [00:00&lt;00:00, 24.76it/s]"
          }
        },
        "9403863cd9324593a344c1795a05f332": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "942f0383a4f54dd3807a13b77ccbe6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "943ed872d8c942eca0e38ed2f94c0e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "944b2f39224d4f19b737dce9f8534026": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94ecb5285f8b4daa858a36548d17ce24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af07c5909cd34da988508e3da4690d79",
              "IPY_MODEL_8c84716f10bf44d2a8851b36b2bda630",
              "IPY_MODEL_2b5859bae48b4d29807d6fb6db116164"
            ],
            "layout": "IPY_MODEL_f2b0553f5aee4c14a88609a3c9bbae29"
          }
        },
        "9530810832cf413a8d3059b7dd834b99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96cfb0c9664641b685c7c20774d0c5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11bc24de762a4b4f958bd664c4457abf",
              "IPY_MODEL_3fa3871e5a9540f1aed3676a452e52be",
              "IPY_MODEL_2d4a4728476744da9381dd9c03673ac2"
            ],
            "layout": "IPY_MODEL_4c1d64ce5d294b75a252224e7c84ed90"
          }
        },
        "9710008f90d24d0abbec776c40f0d911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98e610b376ba492b84b7038375737854": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991c0a26bb5e4ec3b9e1dd55d717a264": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "996b2692601143ff84db735baf1c52c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_089e2a876b604830b09cf574e1c15058",
              "IPY_MODEL_8aff5a3bb541412c9f5d8ee25e3897ea",
              "IPY_MODEL_feb39a00e9634d2e8a62a922523994e7"
            ],
            "layout": "IPY_MODEL_1810e9efc4d74f1eae286129cb485115"
          }
        },
        "99e86865a30f472f86faf1f10c5d2453": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_424879471988468395f4b3c436a2d38d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9b6c25fb19443e4903cc809b0e61c2b",
            "value": 1
          }
        },
        "99ff65c9c98545c397294c2e68954402": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a27ee8a202e4bb2afd31a6692020ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43de3ff5f5f04af491d2d16bad0d4a47",
            "placeholder": "​",
            "style": "IPY_MODEL_0243f6e217064362890ad570a2e2d3e9",
            "value": " 1/1 [00:00&lt;00:00, 63.65it/s]"
          }
        },
        "9a2eeaa58dd24a05b7d609e3bb1a2bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d4d2d17d7f94a64838fec097db7e257",
              "IPY_MODEL_e0935d347bb84a1a9eddca2921d0b3a2",
              "IPY_MODEL_a0d240e52e524414aa1c99c11b38cab5"
            ],
            "layout": "IPY_MODEL_fabf2d3dbf604530ac03b345eed2aa17"
          }
        },
        "9a688c6040e340e8912a5b98b3f8a082": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fa461376eeb4c3a96c2f29168e8b91e",
              "IPY_MODEL_18267b0f10d047dea212da683cb60122",
              "IPY_MODEL_d1c9bf3606da4b00af7e68f45375c9ea"
            ],
            "layout": "IPY_MODEL_cef40e6ce6104b7d98c15de106a6db8b"
          }
        },
        "9b6b4ca2b8f34eb0975e0481116f78ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220028e6fa83441eb886e50753b99ce3",
            "placeholder": "​",
            "style": "IPY_MODEL_d9dc446f73614c2eb831ec0a761f939e",
            "value": " 1/1 [00:00&lt;00:00, 97.97it/s]"
          }
        },
        "9ba221c0cc47458fa428d83976bcb28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c5ea2f30d37428183c790f5dd66d5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d66d6340086471a9f883963a9d636be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dd5107d5bef415ab1b20ce33bbbb684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e02565c94b1463b88039d3cdea2ea46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c51aa9adba54dc892ad27b4a28fcbb3",
            "placeholder": "​",
            "style": "IPY_MODEL_c34714fc159d4c05bf8d950e661ec8ca",
            "value": " 1/1 [00:00&lt;00:00, 100.31it/s]"
          }
        },
        "9ec4bd8dab764fb1b4789ac5cf13ef7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ed17e6eafcc4988b579c958ddf7089b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f896233b1b24abc95508b5cdeb445a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "a02538b89fc94a8687e972e34de862c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a05948a8c7164921a6f7b54c61809d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b1830e6109429faf422115ba502e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0d240e52e524414aa1c99c11b38cab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfd92eb62d241f28978cbe0ec9c1e6e",
            "placeholder": "​",
            "style": "IPY_MODEL_e97d782bdfeb440491448bf3f224f71d",
            "value": " 1/1 [00:00&lt;00:00, 20.64it/s]"
          }
        },
        "a0ff3998b9f743179e1d69b2f4069f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a27d834d1394d0197d5cca2f7455a71",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd5107d5bef415ab1b20ce33bbbb684",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "a21ec122a4ca4a62ba0633a8b70b4bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2cfe707ac1b458eb2fab8e5dcfce656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a308d819a7664282a58d0e65654e7b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df6f389645f4c51bae24425a554e937",
            "placeholder": "​",
            "style": "IPY_MODEL_fe64ee2f2dfa4868b2dc37532f9e3e01",
            "value": " 1/1 [00:00&lt;00:00,  3.82it/s, v_num=8, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.06e+5]"
          }
        },
        "a3ae553d48004c2ca3d8c4c22557bce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09f3466c17d6452696052e90117446cc",
            "placeholder": "​",
            "style": "IPY_MODEL_b0824bbe5edd423f8f07edc44bf17ed3",
            "value": " 1/1 [00:00&lt;00:00, 100.07it/s]"
          }
        },
        "a3e55e1af1c74facb9d9aba0d91c3a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a40057fe9eca49e292489bf26a34fc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_905a1a2bb5ff4a81aace76ad18c4e624",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a45efbaa1c4564a6ef6b99f1f761fd",
            "value": " 1/1 [00:00&lt;00:00, 23.89it/s]"
          }
        },
        "a5c7375f105246ebb6082ae087c7abd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60c8547772f4dac819436e0d7dd9b54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6438971840d44b1906122c69019d69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fd5db257dce49e3b1f241ef3ea9ad13",
            "placeholder": "​",
            "style": "IPY_MODEL_ac4b0544b2264fb18ad8f39e1cd6cae5",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "a6a17a042ccc4587a6762cd409719539": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a767ae701f4c41f0ae0c54b07359b685": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a09645618d489e91e8cc9f378f5711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_369d1e19491d435d80576b423ffb2f10",
              "IPY_MODEL_b76660900afe497f8939f5fb38585888",
              "IPY_MODEL_dc30dbabe8b3423c9344824a45582176"
            ],
            "layout": "IPY_MODEL_f92e035cd1dd4e56933f628f76dfd7d9"
          }
        },
        "a8072c4d95444ddfa631c7da81cdcae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2921b4e0b0cf426ea272e72e287bcec4",
              "IPY_MODEL_80d2456c79254c64ae52ec228835ede5",
              "IPY_MODEL_5909522787004abca779581282006e7b"
            ],
            "layout": "IPY_MODEL_991c0a26bb5e4ec3b9e1dd55d717a264"
          }
        },
        "a8e51e52c43d46aca03975e59453c648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9247581c195466eb939cb63d9815a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "ab93933f7a844dbbabdbfc83c739042b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab9ef85eba744c26a74d843735647d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac276a1b8ad34a3f92d4b8d2a282ae9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac4b0544b2264fb18ad8f39e1cd6cae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acfd92eb62d241f28978cbe0ec9c1e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af07c5909cd34da988508e3da4690d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def05d4afa6543f0a7a98d9aaa6a13f4",
            "placeholder": "​",
            "style": "IPY_MODEL_59f8a2b5e30e4788bc8a1ca8dc173f7c",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "af72acd7bfe24c93b18231d223eb169b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0824bbe5edd423f8f07edc44bf17ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0a21911fbc044878bd2921bba0dd38b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15631e4b5a243c7a146b89db317046a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06459e421d064d71887b77cd3a08ac47",
            "placeholder": "​",
            "style": "IPY_MODEL_4e53e62f358541ecb670674aa8722686",
            "value": "Epoch 999: 100%"
          }
        },
        "b1fd15489f9641eb9e256be00c680370": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b10a8a343de4707b701b235b12cdf03",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8398dc3c32584a689d5101da34bce8bf",
            "value": 1
          }
        },
        "b37bfb9315204c5aa9d0117c12558818": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fc9b122eb1045d3be60f091414d8aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_9c5ea2f30d37428183c790f5dd66d5d9",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "b3a1f7ba909c414a8812912f27323fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3a9998617d943558dd8ae1ca0307b80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3cf5bf63d304c97a42cce7d034b3345": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4c4a79fb0c942ccbd5fad79795616f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f88fd6543de54e049d7dc34204f860ed",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7351c01db076435f91cc08b5d6ca5ed0",
            "value": 1
          }
        },
        "b4cbe703a5324064988166f521bb95c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b558589adcc34a29ae2e56626f245ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68ff467f8c444f9b588713eacd6b7ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69e0a7e36114aea8e37d95b52d11959": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a236757b7f46c7ba3ae9eae27d2454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a7671f093c1412db740ee2f6c45ce17",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbe73cbbe27641f284f54e159a188b9f",
            "value": 1
          }
        },
        "b6ae7a272e28437fb8df1fad199843c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6da8637f6c34f12ab896f092e76dd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7071d1d108743a88a5a2f5b499ad907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b15631e4b5a243c7a146b89db317046a",
              "IPY_MODEL_725ce44d7b6d4c3eb2db9afc15ba43c2",
              "IPY_MODEL_35ae544d591a4b6a9514c9f77678a382"
            ],
            "layout": "IPY_MODEL_8f507054eb4243d5b6a720de750ef5d5"
          }
        },
        "b72cec6baa8547fb9b8eab9d475d7959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_234ccc43194344109b9d67a6d0cfb054",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_742b84f46b1d49d5b4b670de816061fe",
            "value": 1
          }
        },
        "b76660900afe497f8939f5fb38585888": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45cdd59829a34c5b9b330358747ac571",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ad70785c37e41eca3e039f140eb9662",
            "value": 1
          }
        },
        "b77b64a217f64fe38792cf7dfbdf06e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784b93aa7a714cdf8920153b4e02be64",
            "placeholder": "​",
            "style": "IPY_MODEL_b3a1f7ba909c414a8812912f27323fef",
            "value": " 1/1 [00:00&lt;00:00, 81.29it/s]"
          }
        },
        "b7ea4c80e99c4c3e8853158efc1507af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9148c9fc52a425aa33b534c60b7aefc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9deb334bf524c6faa5bf064a4e9fe93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86fccb9d34d04290b636b9ffa424f951",
              "IPY_MODEL_061e647c50a24bc08357c69de8f09354",
              "IPY_MODEL_9a27ee8a202e4bb2afd31a6692020ffc"
            ],
            "layout": "IPY_MODEL_0cbfde68abe64cc98bd2f1a7b297bd32"
          }
        },
        "b9e8caec156942269c3b22259ff0b310": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9b59151532432d8013ad6b6bc9a49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2a96d723bb458291a82d06991be8fb",
            "placeholder": "​",
            "style": "IPY_MODEL_c1f09f7a8d014f2182046e0ad2b97a9d",
            "value": " 1/1 [00:00&lt;00:00, 23.85it/s]"
          }
        },
        "bc4cf71ddbf148c382110e3a3c974c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bca14345673c42cd9397081c1395497a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ac560e7ae74b8ebc656a778d68a355",
            "placeholder": "​",
            "style": "IPY_MODEL_edb2c71856b8430e8b3f17502762e41d",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "bd78a12011f2488c89904dbf3ce7ad52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b68ff467f8c444f9b588713eacd6b7ec",
            "placeholder": "​",
            "style": "IPY_MODEL_2fbe924419fb45688951bbc25c182e6b",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "bde38cecf5b9413792be89ef1628ca64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf63b6a2692e4c29b975354b7e9645fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf821fca3c6947cd96cb48dcc1c07873": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdf750c48cd4dfcaa211d60446b3d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c07b322a7ffc41c983099879e302e4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13e2c8213bd421c80c98d8f647cd743": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1954bd01c954f9ea3f4c4087d6cf72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1a825e9a1c7458fa32d5e6f6345646d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1f09f7a8d014f2182046e0ad2b97a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c243f7261cb64f72ab2e542fcc2201d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34714fc159d4c05bf8d950e661ec8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3c0f129be1244758a542eaafd792b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c41680fda2f446eca453c748a382fde5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef63e5226ed14c909186ff0e9bf57813",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c828918797d470b92b6d27454e27659",
            "value": 1
          }
        },
        "c4794f0316094b31964f49c4199c690b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47abe7a16d3451bbe367da4c3c1beb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b6f13e10884b6bb85ccd10f8ef2725": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c598fb294fa3454faeff04e8e5a1c1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60d681f07fa4cef9c4d98982d6c3363": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c61e8fe425934c44ada1746bd80e6c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0a1c89884594605b70943fb7c9b6f81",
            "placeholder": "​",
            "style": "IPY_MODEL_51b23169f4a943a8a02292646ed5a92f",
            "value": " 1/1 [00:00&lt;00:00, 107.26it/s]"
          }
        },
        "c7292b7c981b41478109befb78b9503f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7a45efbaa1c4564a6ef6b99f1f761fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7d1010e3f534c64ac9fd6eb009a2b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c814793272e24febb3d1eed1161fc4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c89569f61eab4f6993f48dba53473b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c8d54cd4279c4248917ffbc6615aabc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a9998617d943558dd8ae1ca0307b80",
            "placeholder": "​",
            "style": "IPY_MODEL_c9ba12a351754d92b8259f16e1d46a21",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "c948a5237ac74651a9307569a05c3c95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ba12a351754d92b8259f16e1d46a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9d8fe37a98e44828070a3e520e0ab39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8b3c07531e4644851247c2d19d5828": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caeedf4048d74ef08a94e036e61196d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbaa8ef204a4fbe9098842ef7717ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6f19c4db344495bfcf9fad1047447c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62cbf39333ba4b7198fd62361e0511df",
            "value": 1
          }
        },
        "cd8e4da88dc14e468be8481024c07780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e3a4adefd2d4a63ab7c4f46e01e9e9f",
            "placeholder": "​",
            "style": "IPY_MODEL_af72acd7bfe24c93b18231d223eb169b",
            "value": " 1/1 [00:00&lt;00:00, 102.90it/s]"
          }
        },
        "ce12a43e1023423586a6d9331c658781": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb76150cad04b76bf0851c198a23c71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef40e6ce6104b7d98c15de106a6db8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "d00f667624584c39820e44c45547d000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0850cd4fc1e45f68d3c900f88733b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1bb9d9efae94b45943752acbb036b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aca17b7da9c414b9fc1f60a5c1b0c90",
            "placeholder": "​",
            "style": "IPY_MODEL_6e42d5c165a644eebe8399e9e9053b20",
            "value": " 1/1 [00:00&lt;00:00, 68.11it/s]"
          }
        },
        "d1c9bf3606da4b00af7e68f45375c9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244b08b3a47c4e799e4a4e72a5587031",
            "placeholder": "​",
            "style": "IPY_MODEL_2832d58105744a9db3c91b114ec27ead",
            "value": " 1/1 [00:00&lt;00:00, 23.61it/s]"
          }
        },
        "d3b055d443384b7a954eb0404a0aa354": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d54507794f40428fbb052757d79d8eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d58801668ea74c6c87774e1dd348362d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe53fca4332444a49d08f88141ba7911",
            "placeholder": "​",
            "style": "IPY_MODEL_7ec02028674641c1ae444c4ae1b49af5",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "d6bfe2f318dc4f02a9bc1c677bfa0ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b3545c608247309e28eede5b9b5f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_730e40e695bf4a49b8baa703627980b1",
            "placeholder": "​",
            "style": "IPY_MODEL_d0850cd4fc1e45f68d3c900f88733b8d",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "d80299d5e9ab4b3b9b52a4452cc5fc12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9dc446f73614c2eb831ec0a761f939e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da957921a1fc49cbbc2c97de54119436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60c8547772f4dac819436e0d7dd9b54",
            "placeholder": "​",
            "style": "IPY_MODEL_3d572eb78c3b4bfe9c2cdd19bb2bb0bb",
            "value": " 1/1 [00:00&lt;00:00, 77.42it/s]"
          }
        },
        "dbafce3eb5c64fd8baad140fc1a7a907": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc30dbabe8b3423c9344824a45582176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf63b6a2692e4c29b975354b7e9645fd",
            "placeholder": "​",
            "style": "IPY_MODEL_7f54ef2c798b47efafe1b36e54f05fb2",
            "value": " 1/1 [00:00&lt;00:00, 83.69it/s]"
          }
        },
        "dc3a3853768f4172a4c907c5e66ff278": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb4090a99684c8ca7fcb3ae588fffd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "dd188090396e478fb97c13c794003085": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de02f0211cde4193827e0f21501365af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4cbe703a5324064988166f521bb95c3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d7d4d0aeb324aa8a8498dbcda28494d",
            "value": 1
          }
        },
        "de3cbd9cf06746a88fd1096bbc790313": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de8127e5af5446f0a41340f79a9f4093": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "def05d4afa6543f0a7a98d9aaa6a13f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0935d347bb84a1a9eddca2921d0b3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca13cc2e0864ea1954c1e3a0a0e1f38",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd188090396e478fb97c13c794003085",
            "value": 1
          }
        },
        "e0a1c89884594605b70943fb7c9b6f81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a7649d328343d5ab8ad921ef22f621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e15d9f560f4a4439b5844f988144efae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1de86e5a1ed41f981fa01ba3e131d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c7375f105246ebb6082ae087c7abd3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26717562be6c41cda806e5ca45b67e05",
            "value": 1
          }
        },
        "e307566bdcf34df395ae9c8ac690f623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3292a4360654913a995b32cc5618b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fa9840537ad4d3e8765feb6dfe82b6c",
              "IPY_MODEL_14df87c7082d4ae490c2439473cfe2f2",
              "IPY_MODEL_8fca995a7d1c44c6a7c00537b38a89df"
            ],
            "layout": "IPY_MODEL_8cadf25f287a42a48dccd939c398da98"
          }
        },
        "e74ddcf88c2442109405e57a799884f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ff44a0257114af28eb339785b543f7f",
              "IPY_MODEL_8d10ca5cf9984c77af16d7c4102bda66",
              "IPY_MODEL_0392aed543b445bcb66b90a2577a29e9"
            ],
            "layout": "IPY_MODEL_a9247581c195466eb939cb63d9815a9d"
          }
        },
        "e87970266d334b84836d87d528eb3d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9155b59d10741bcb764ed18fad52ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "e95af02a6f72430f94036d95f855f053": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97d782bdfeb440491448bf3f224f71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9cf9e7d360d47219535e5d6220f9697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea1e5528647e4368b691506a588fd3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e8caec156942269c3b22259ff0b310",
            "placeholder": "​",
            "style": "IPY_MODEL_7136946b70bf4718a17a70a88631b136",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "eaa88f098e044ebfb37eaa0e69500b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c94829601346e1b2882afddfcf44eb",
            "placeholder": "​",
            "style": "IPY_MODEL_61a64adecd8c4693ba79a01bc775579c",
            "value": " 1/1 [00:00&lt;00:00, 121.80it/s]"
          }
        },
        "eaf1fb87bc6f46eb973504035f262d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee99e8e0e55441599e6d5b520ca38d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca8b3c07531e4644851247c2d19d5828",
            "value": 1
          }
        },
        "ed82fe31a434473c999108f174559351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edb2c71856b8430e8b3f17502762e41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef59f0614c334de388d1dbfb5a78ad40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "ef63e5226ed14c909186ff0e9bf57813": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb5354d8e1b4b518c800ac79ed92aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efc0e32ff44f41eda8971273b8a59905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f09978559b214939aa9f9023e92c4a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0ff3998b9f743179e1d69b2f4069f70",
              "IPY_MODEL_f7018ff10b7e4d219db4a5d92beabac7",
              "IPY_MODEL_01c0258d0be244f59ac78a4b52a40ce9"
            ],
            "layout": "IPY_MODEL_925ab74e6da74e67b4a2e0e990aef422"
          }
        },
        "f235ed60fb024bb28d474e0844de6dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cca7fd00604480da1f7472a0336f10d",
              "IPY_MODEL_b4c4a79fb0c942ccbd5fad79795616f4",
              "IPY_MODEL_9e02565c94b1463b88039d3cdea2ea46"
            ],
            "layout": "IPY_MODEL_468faca8d58e417696ac24a8d01289bf"
          }
        },
        "f2b0553f5aee4c14a88609a3c9bbae29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f30674e2ae4f450995c7da77a4db8cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "f3ae9078b6af43cda8ddbc57e619ab82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a05948a8c7164921a6f7b54c61809d3c",
            "placeholder": "​",
            "style": "IPY_MODEL_315aed6536ae418093ec5f8f9deb95b4",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "f475abd6e69343fab625f4cd9ce4cf51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4dbfa859f0b4923bf768d01eb1483dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "f4e9a150cc814cad9fb4f25dc12c50ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62ea21bec114fad99a0973514658c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b69e0a7e36114aea8e37d95b52d11959",
            "placeholder": "​",
            "style": "IPY_MODEL_942f0383a4f54dd3807a13b77ccbe6d6",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "f6a1bd38861c4e3ea5bb0735fad458b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69ed4177475e4e86b6f79cf209441c33",
              "IPY_MODEL_6a30be8b77df4ad0aa32af1bf67ff5c1",
              "IPY_MODEL_fb27d7c4fb4b4eeea890790487947930"
            ],
            "layout": "IPY_MODEL_6764d8d739484907886629b42ba4e3bf"
          }
        },
        "f7018ff10b7e4d219db4a5d92beabac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05f87bf5978c4a08826e92a58fd81602",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efc0e32ff44f41eda8971273b8a59905",
            "value": 1
          }
        },
        "f71c0d756bd646c892bb1b8db854191c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2cfe707ac1b458eb2fab8e5dcfce656",
            "placeholder": "​",
            "style": "IPY_MODEL_c3c0f129be1244758a542eaafd792b3b",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "f7974f94d49d48e6963d0d66e18b4e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f851de7d640b4b318f41a0f4bcea1e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f88fd6543de54e049d7dc34204f860ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f903862487d64139805e0dfbe52ca145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92e035cd1dd4e56933f628f76dfd7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "f9b6c25fb19443e4903cc809b0e61c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fabf2d3dbf604530ac03b345eed2aa17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "fb27d7c4fb4b4eeea890790487947930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd09370a659741648d135fda8e0e0321",
            "placeholder": "​",
            "style": "IPY_MODEL_1edc3b3e658b4bbe85e2ed2ad28493fa",
            "value": " 1/1 [00:00&lt;00:00, 76.03it/s]"
          }
        },
        "fb9032148b5a42479ce2b15cc7e43115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cb44a2904db4e2f93600c0481548bb9",
              "IPY_MODEL_5db9b537c624470584b643aa37e9ddfa",
              "IPY_MODEL_61e43b4243f6407e8c6a9caf9a82c5ec"
            ],
            "layout": "IPY_MODEL_5721536c88b7442790eb3ccea33208b8"
          }
        },
        "fbe73cbbe27641f284f54e159a188b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc19db9f545b4f85ac249946c39305df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd09370a659741648d135fda8e0e0321": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd6ffd0e51624bb9b50741a3270c799a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb8ff8f88694cbeb2b0dc926f80cbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60fabf94c96d4828aee35da5b83efe38",
            "placeholder": "​",
            "style": "IPY_MODEL_61be583f9d8a46a9bc1aa5999045b598",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "fdcaf8601ac74fbf967567c94b401f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe53fca4332444a49d08f88141ba7911": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe64ee2f2dfa4868b2dc37532f9e3e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb39a00e9634d2e8a62a922523994e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c948a5237ac74651a9307569a05c3c95",
            "placeholder": "​",
            "style": "IPY_MODEL_75c4e3a8d14c4ddabae2f8f8e2e58e38",
            "value": " 1/1 [00:00&lt;00:00, 83.99it/s]"
          }
        },
        "ff977f2ee76447d998775909ac5315ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
