{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71368,"databundleVersionId":7804651,"sourceType":"competition"},{"sourceId":7860646,"sourceType":"datasetVersion","datasetId":4611100},{"sourceId":7862222,"sourceType":"datasetVersion","datasetId":4612229}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T15:15:23.554112Z","iopub.execute_input":"2024-03-16T15:15:23.554371Z","iopub.status.idle":"2024-03-16T15:15:24.524762Z","shell.execute_reply.started":"2024-03-16T15:15:23.554348Z","shell.execute_reply":"2024-03-16T15:15:24.523608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fair-esm","metadata":{"execution":{"iopub.status.busy":"2024-03-18T04:52:16.731722Z","iopub.execute_input":"2024-03-18T04:52:16.732364Z","iopub.status.idle":"2024-03-18T04:52:28.883590Z","shell.execute_reply.started":"2024-03-18T04:52:16.732330Z","shell.execute_reply":"2024-03-18T04:52:28.882453Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fair-esm in /opt/conda/lib/python3.10/site-packages (2.0.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nfrom Bio import SeqIO\nimport esm\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport pandas as pd\nimport random\n\n# import os.path\n# os.chdir(\"/kaggle/working\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T04:52:28.885503Z","iopub.execute_input":"2024-03-18T04:52:28.885813Z","iopub.status.idle":"2024-03-18T04:52:28.892107Z","shell.execute_reply.started":"2024-03-18T04:52:28.885787Z","shell.execute_reply":"2024-03-18T04:52:28.891106Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-18T04:52:28.893267Z","iopub.execute_input":"2024-03-18T04:52:28.893579Z","iopub.status.idle":"2024-03-18T04:52:28.907921Z","shell.execute_reply.started":"2024-03-18T04:52:28.893550Z","shell.execute_reply":"2024-03-18T04:52:28.906977Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class ProteinSequenceDataset(Dataset):\n    def __init__(self, fasta_file, arg_dict, alphabet, max_samples_per_class=1000):\n        self.alphabet = alphabet\n        self.sequences, self.labels, self.ids= self.load_sequences(fasta_file, arg_dict, max_samples_per_class)\n\n    def encode_sequence(self, sequence, alphabet):\n        tokens = alphabet.encode(sequence)\n        return torch.tensor(tokens, dtype=torch.long)\n    \n    def load_sequences(self, fasta_file, arg_dict, max_samples_per_class):\n        temp_sequences = {label: [] for label in arg_dict.values()}  # Initialize with integers\n        sequences, labels, ids = [], [], []\n        \n        for record in SeqIO.parse(fasta_file, \"fasta\"):\n            if 'FEATURES' in record.description:\n                label = record.description.split('|')[3]\n                label_idx = arg_dict.get(label, arg_dict['nonarg'])\n            else:\n                label_idx = arg_dict['nonarg']\n\n            seq_encoded = self.encode_sequence(str(record.seq), self.alphabet)\n            temp_sequences[label_idx].append((seq_encoded, label_idx, record.id))\n        \n        for label_idx, items in temp_sequences.items():\n            if max_samples_per_class is not None and len(items) > max_samples_per_class:\n                items = random.sample(items, max_samples_per_class)\n            for seq_encoded, label_idx, record_id in items:\n                sequences.append(seq_encoded)\n                labels.append(label_idx)\n                ids.append(record_id)\n\n        return sequences, labels, ids\n    \n    def one_hot_encode(self, sequence):\n        aa_to_int = {aa: i for i, aa in enumerate('ARNDCEQGHILKMFPSTWYV')}\n        one_hot = torch.zeros(len(sequence), 20)  # 20 amino acids\n        for i, aa in enumerate(sequence):\n            if aa in aa_to_int:\n                one_hot[i, aa_to_int[aa]] = 1.0\n        return one_hot\n    \n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        return self.sequences[idx], self.labels[idx], self.ids[idx]\n\narg_dict = {\n    'aminoglycoside': 0, 'macrolide-lincosamide-streptogramin': 1, 'polymyxin': 2,\n    'fosfomycin': 3, 'trimethoprim': 4, 'bacitracin': 5, 'quinolone': 6, 'multidrug': 7,\n    'chloramphenicol': 8, 'tetracycline': 9, 'rifampin': 10, 'beta_lactam': 11,\n    'sulfonamide': 12, 'glycopeptide': 13, 'nonarg': 14\n}\n\nfrom torch.nn.utils.rnn import pad_sequence\n# dealing with sequences of different lengths\ndef collate_batch(batch):\n    sequences, labels, ids = zip(*batch)\n    # pad sequences to have the same length\n    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n    labels = torch.LongTensor(labels)\n    return sequences_padded, labels, ids\n","metadata":{"execution":{"iopub.status.busy":"2024-03-18T04:52:03.460379Z","iopub.execute_input":"2024-03-18T04:52:03.460644Z","iopub.status.idle":"2024-03-18T04:52:03.477901Z","shell.execute_reply.started":"2024-03-18T04:52:03.460621Z","shell.execute_reply":"2024-03-18T04:52:03.477034Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class ESMClassifier(nn.Module):\n    def __init__(self, esm_model, num_classes):\n        super().__init__()\n        self.esm_model = esm_model\n        self.classifier = nn.Linear(320, num_classes)\n\n    def forward(self, x):\n        results = self.esm_model(x, repr_layers=[6])\n        representations = results[\"representations\"][6]\n        pooled_representations = representations.mean(dim=1)\n        return self.classifier(pooled_representations)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:18:06.797382Z","iopub.execute_input":"2024-03-16T21:18:06.797914Z","iopub.status.idle":"2024-03-16T21:18:06.811693Z","shell.execute_reply.started":"2024-03-16T21:18:06.797882Z","shell.execute_reply":"2024-03-16T21:18:06.810927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(classifier, train_loader, val_loader, criterion, optimizer, num_epochs):\n    best_val_f1 = -1\n    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n        classifier.train()\n        total_loss = 0\n        for sequences, labels, _ in train_loader:\n\n            sequences, labels = sequences.to(device), labels.to(device)\n\n            predictions = classifier(sequences)\n            loss = criterion(predictions, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        val_f1 = evaluate_model(classifier, val_loader)\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            torch.save(classifier.state_dict(), 'model.pth')\n        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}, Val F1: {val_f1}')\n\n\ndef evaluate_model(classifier, data_loader):\n    classifier.eval()\n    all_predictions = []\n    all_targets = []\n    with torch.no_grad():\n        for sequences, labels, _ in data_loader:\n            sequences, labels = sequences.to(device), labels.to(device)\n            outputs = classifier(sequences)\n            _, predicted = torch.max(outputs.data, 1)\n            all_predictions.extend(predicted.cpu().numpy())\n            all_targets.extend(labels.cpu().numpy())\n\n    f1 = f1_score(all_targets, all_predictions, average='macro')\n#     print('F1 Score:', f1)\n    return f1\n\ndef generate_predictions_and_save(classifier, test_loader, file_path='submission.csv'):\n    classifier.eval()\n    sequence_ids = []\n    predictions = []\n    with torch.no_grad():\n        for sequences, labels, ids in test_loader:\n            print(len(sequences))\n            sequences = sequences.to(device)\n            outputs = classifier(sequences)\n            _, predicted = torch.max(outputs.data, 1)\n            predictions.extend(predicted.cpu().numpy())\n            sequence_ids.extend(ids)\n\n    df = pd.DataFrame({'id': sequence_ids, 'label': predictions})\n    df.to_csv(file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T23:47:44.873180Z","iopub.execute_input":"2024-03-16T23:47:44.873625Z","iopub.status.idle":"2024-03-16T23:47:44.890808Z","shell.execute_reply.started":"2024-03-16T23:47:44.873586Z","shell.execute_reply":"2024-03-16T23:47:44.889560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_path = \"/kaggle/input/model-pth/model.pth\"\nmodel_path = \"/kaggle/input/model/model.pth\"\nesm_path = \"/kaggle/input/esm2-pretrained/esm2_t6_8M_UR50D.pt\"\ndata_path = \"/kaggle/input/aist4010-spring2024-a2/data\"\nnum_epochs = 15\nlr=0.0000005\nbatch_size = 4\n\nmodel, alphabet = esm.pretrained.load_model_and_alphabet(esm_path)\nmodel.to(device)\nmodel.eval()\n\ntrain_dataset = ProteinSequenceDataset(data_path+'/train.fasta', arg_dict, alphabet)\nval_dataset = ProteinSequenceDataset(data_path+'/val.fasta', arg_dict, alphabet, max_samples_per_class = None)\ntest_dataset = ProteinSequenceDataset(data_path+'/test.fasta', arg_dict, alphabet, max_samples_per_class = None)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n\nclassifier = ESMClassifier(model, len(arg_dict))\nclassifier = classifier.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(classifier.parameters(), lr=lr)\nclassifier.load_state_dict(torch.load(model_path))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:18:06.828327Z","iopub.execute_input":"2024-03-16T21:18:06.829013Z","iopub.status.idle":"2024-03-16T21:20:20.070509Z","shell.execute_reply.started":"2024-03-16T21:18:06.828981Z","shell.execute_reply":"2024-03-16T21:20:20.069588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# train_model(classifier, train_loader, val_loader, criterion, optimizer, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:20:20.071547Z","iopub.execute_input":"2024-03-16T21:20:20.071946Z","iopub.status.idle":"2024-03-16T22:02:02.676772Z","shell.execute_reply.started":"2024-03-16T21:20:20.071922Z","shell.execute_reply":"2024-03-16T22:02:02.675835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classifier.load_state_dict(torch.load(\"/kaggle/working/model.pth\"))\n# generate_predictions_and_save(classifier, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T23:47:48.399043Z","iopub.execute_input":"2024-03-16T23:47:48.399924Z","iopub.status.idle":"2024-03-16T23:47:56.041605Z","shell.execute_reply.started":"2024-03-16T23:47:48.399891Z","shell.execute_reply":"2024-03-16T23:47:56.040200Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LORA (Microsoft)","metadata":{}},{"cell_type":"code","source":"!pip install loralib","metadata":{"execution":{"iopub.status.busy":"2024-03-18T04:52:29.661217Z","iopub.execute_input":"2024-03-18T04:52:29.662134Z","iopub.status.idle":"2024-03-18T04:52:41.781095Z","shell.execute_reply.started":"2024-03-18T04:52:29.662099Z","shell.execute_reply":"2024-03-18T04:52:41.779966Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: loralib in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import loralib as lora\n\nclass ESMClassifier(nn.Module):\n    def __init__(self, esm_model, num_classes, lora_config=None):\n        super().__init__()\n        self.esm_model = esm_model\n        if lora_config:\n            self.classifier = lora.Linear(320, # esm2_t6_8M_UR50D Embedding Dim: 320 \n                                          num_classes, \n                                          r=lora_config['r'], \n                                          lora_alpha=lora_config['lora_alpha'], \n                                          lora_dropout=lora_config['lora_dropout'])\n        else:\n            self.classifier = nn.Linear(esm_model.classifier.in_features, num_classes)\n\n\n    def forward(self, x):\n        results = self.esm_model(x, repr_layers=[6]) #esm2_t6_8M_UR50D layers = 6\n        representations = results[\"representations\"][6]\n        pooled_representations = representations.mean(dim=1)\n        return self.classifier(pooled_representations)\n    \n\n# model_path = \"/kaggle/input/model-pth/model.pth\"\nmodel_path = \"/kaggle/input/model/model.pth\"\nmodel_path = \"/kaggle/working/model_base_lora.pth\"\nesm_path = \"/kaggle/input/esm2-pretrained/esm2_t6_8M_UR50D.pt\"\ndata_path = \"/kaggle/input/aist4010-spring2024-a2/data\"\n\nbatch_size = 10\n\nmodel, alphabet = esm.pretrained.load_model_and_alphabet(esm_path)\nmodel.to(device)\nmodel.eval()\n\ntrain_dataset = ProteinSequenceDataset(data_path+'/train.fasta', arg_dict, alphabet)\nval_dataset = ProteinSequenceDataset(data_path+'/val.fasta', arg_dict, alphabet, max_samples_per_class = None)\ntest_dataset = ProteinSequenceDataset(data_path+'/test.fasta', arg_dict, alphabet, max_samples_per_class = None)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-18T06:43:07.965388Z","iopub.execute_input":"2024-03-18T06:43:07.965980Z","iopub.status.idle":"2024-03-18T06:45:17.022921Z","shell.execute_reply.started":"2024-03-18T06:43:07.965947Z","shell.execute_reply":"2024-03-18T06:45:17.022124Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_path = \"/kaggle/input/model/model.pth\"\nmodel_path = \"/kaggle/working/model_base_lora.pth\"\n\nlora_config = {\n    'r': 8,\n    'lora_alpha': 24,\n    'lora_dropout': 0.5,\n}\nnum_epochs = 100\nlr=0.0001\n\n\n\nclassifier = ESMClassifier(model, len(arg_dict), lora_config=lora_config)\nclassifier = classifier.to(device)\nclassifier.load_state_dict(torch.load(model_path), strict=False)\n\nlora.mark_only_lora_as_trainable(classifier)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(classifier.parameters(), lr=lr)\n\n\n\ndef train_model(classifier, train_loader, val_loader, criterion, optimizer, num_epochs):\n    best_val_f1 = -1\n    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n        classifier.train()\n        total_loss = 0\n        for sequences, labels, _ in train_loader:\n\n            sequences, labels = sequences.to(device), labels.to(device)\n\n            predictions = classifier(sequences)\n            loss = criterion(predictions, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        val_f1 = evaluate_model(classifier, val_loader)\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            torch.save(classifier.state_dict(), 'model_base_lora.pth')\n            torch.save(lora.lora_state_dict(classifier), 'lora_model.pth')\n\n        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}, Val F1: {val_f1}')\n\n\ndef evaluate_model(classifier, data_loader):\n    classifier.eval()\n    all_predictions = []\n    all_targets = []\n    with torch.no_grad():\n        for sequences, labels, _ in data_loader:\n            sequences, labels = sequences.to(device), labels.to(device)\n            outputs = classifier(sequences)\n            _, predicted = torch.max(outputs.data, 1)\n            all_predictions.extend(predicted.cpu().numpy())\n            all_targets.extend(labels.cpu().numpy())\n\n    f1 = f1_score(all_targets, all_predictions, average='macro')\n#     print('F1 Score:', f1)\n    return f1\n\ndef generate_predictions_and_save(classifier, test_loader, file_path='submission.csv'):\n    classifier.eval()\n    sequence_ids = []\n    predictions = []\n    with torch.no_grad():\n        for sequences, labels, ids in test_loader:\n            outputs = classifier(sequences)            sequences = sequences.to(device)\n\n            _, predicted = torch.max(outputs.data, 1)\n            predictions.extend(predicted.cpu().numpy())\n            sequence_ids.extend(ids)\n\n    df = pd.DataFrame({'id': sequence_ids, 'label': predictions})\n    df.to_csv(file_path, index=False)\n\ntrain_model(classifier, train_loader, val_loader, criterion, optimizer, num_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-18T09:37:37.736476Z","iopub.execute_input":"2024-03-18T09:37:37.737270Z","iopub.status.idle":"2024-03-18T12:28:13.703896Z","shell.execute_reply.started":"2024-03-18T09:37:37.737234Z","shell.execute_reply":"2024-03-18T12:28:13.702870Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Epochs:   1%|          | 1/100 [01:42<2:49:29, 102.73s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100, Loss: 0.012277000624962658, Val F1: 0.9221905176510666\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   2%|▏         | 2/100 [03:24<2:47:03, 102.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/100, Loss: 0.012562273693557422, Val F1: 0.9221304016881108\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   3%|▎         | 3/100 [05:06<2:45:12, 102.19s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/100, Loss: 0.01289036996037418, Val F1: 0.9221905176510666\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   4%|▍         | 4/100 [06:50<2:44:18, 102.70s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 4/100, Loss: 0.012414641327045122, Val F1: 0.9219109907984725\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   5%|▌         | 5/100 [08:32<2:42:35, 102.69s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/100, Loss: 0.013434155087072677, Val F1: 0.9222272579327081\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   6%|▌         | 6/100 [10:15<2:40:37, 102.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 6/100, Loss: 0.013200434092977598, Val F1: 0.9215113958036952\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   7%|▋         | 7/100 [11:57<2:38:47, 102.44s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 7/100, Loss: 0.01207172692654672, Val F1: 0.9215113958036952\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   8%|▊         | 8/100 [13:40<2:37:14, 102.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 8/100, Loss: 0.012812371591265286, Val F1: 0.9215113958036952\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   9%|▉         | 9/100 [15:22<2:35:13, 102.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 9/100, Loss: 0.013284417463232792, Val F1: 0.9215113958036952\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  10%|█         | 10/100 [17:05<2:33:47, 102.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 10/100, Loss: 0.012097589907341524, Val F1: 0.9215113958036952\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  11%|█         | 11/100 [18:47<2:31:53, 102.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 11/100, Loss: 0.011896885841086283, Val F1: 0.9215113958036952\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  12%|█▏        | 12/100 [20:29<2:30:13, 102.43s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 12/100, Loss: 0.011879707687608774, Val F1: 0.9219338078801218\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  13%|█▎        | 13/100 [22:12<2:28:38, 102.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 13/100, Loss: 0.011263226108590721, Val F1: 0.9216776570449633\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  14%|█▍        | 14/100 [23:54<2:26:41, 102.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 14/100, Loss: 0.011651009210867586, Val F1: 0.9216941092837148\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  15%|█▌        | 15/100 [25:35<2:24:39, 102.11s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 15/100, Loss: 0.01179824252917268, Val F1: 0.9214379642672147\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  16%|█▌        | 16/100 [27:18<2:23:13, 102.30s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 16/100, Loss: 0.0124485856200416, Val F1: 0.9214379642672147\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  17%|█▋        | 17/100 [29:00<2:21:10, 102.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 17/100, Loss: 0.011252952741382004, Val F1: 0.921657369002073\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  18%|█▊        | 18/100 [30:42<2:19:34, 102.13s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 18/100, Loss: 0.012499950084877285, Val F1: 0.9208645164866308\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  19%|█▉        | 19/100 [32:25<2:18:08, 102.33s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 19/100, Loss: 0.011343638738625511, Val F1: 0.9208645164866308\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  20%|██        | 20/100 [34:07<2:16:36, 102.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 20/100, Loss: 0.012664104955688479, Val F1: 0.9208645164866308\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  21%|██        | 21/100 [35:50<2:14:57, 102.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 21/100, Loss: 0.011194266792172412, Val F1: 0.9208645164866308\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  22%|██▏       | 22/100 [37:33<2:13:19, 102.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 22/100, Loss: 0.011402367388734498, Val F1: 0.9208645164866308\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  23%|██▎       | 23/100 [39:15<2:11:40, 102.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 23/100, Loss: 0.010914732113678261, Val F1: 0.9208645164866308\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  24%|██▍       | 24/100 [40:57<2:09:38, 102.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 24/100, Loss: 0.010730891258286423, Val F1: 0.9208645164866308\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  25%|██▌       | 25/100 [42:40<2:07:56, 102.35s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 25/100, Loss: 0.011022173255042324, Val F1: 0.9214379642672147\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  26%|██▌       | 26/100 [44:22<2:06:08, 102.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 26/100, Loss: 0.010910104393340394, Val F1: 0.9214379642672147\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  27%|██▋       | 27/100 [46:04<2:04:28, 102.30s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 27/100, Loss: 0.01066626511181258, Val F1: 0.9214379642672147\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  28%|██▊       | 28/100 [47:46<2:02:39, 102.22s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 28/100, Loss: 0.011257845715759848, Val F1: 0.9213759390033595\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  29%|██▉       | 29/100 [49:29<2:01:21, 102.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 29/100, Loss: 0.010336302508403861, Val F1: 0.9216216516002709\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  30%|███       | 30/100 [51:12<1:59:41, 102.59s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 30/100, Loss: 0.010975906499656579, Val F1: 0.9213778421494788\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  31%|███       | 31/100 [52:54<1:57:52, 102.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 31/100, Loss: 0.01073151461438173, Val F1: 0.9213778421494788\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  32%|███▏      | 32/100 [54:37<1:56:22, 102.68s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 32/100, Loss: 0.011143673089633174, Val F1: 0.9213158189660291\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  33%|███▎      | 33/100 [56:20<1:54:43, 102.74s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 33/100, Loss: 0.010526082381251623, Val F1: 0.9213158189660291\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  34%|███▍      | 34/100 [58:02<1:52:44, 102.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 34/100, Loss: 0.010792300185835975, Val F1: 0.9213759390033595\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  35%|███▌      | 35/100 [59:44<1:50:48, 102.29s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 35/100, Loss: 0.010503509177883239, Val F1: 0.9213759390033595\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  36%|███▌      | 36/100 [1:01:26<1:49:01, 102.21s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 36/100, Loss: 0.010109354796800219, Val F1: 0.9213759390033595\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  37%|███▋      | 37/100 [1:03:09<1:47:31, 102.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 37/100, Loss: 0.010394542480649537, Val F1: 0.9213759390033595\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  38%|███▊      | 38/100 [1:04:51<1:45:38, 102.23s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 38/100, Loss: 0.010607455388614687, Val F1: 0.9215596226007002\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  39%|███▉      | 39/100 [1:06:32<1:43:45, 102.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 39/100, Loss: 0.010193992775802874, Val F1: 0.9215596226007002\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  40%|████      | 40/100 [1:08:14<1:41:54, 101.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 40/100, Loss: 0.010242078234931295, Val F1: 0.9217557050772704\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  41%|████      | 41/100 [1:09:56<1:40:14, 101.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 41/100, Loss: 0.009993003764336756, Val F1: 0.9214395560743632\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  42%|████▏     | 42/100 [1:11:38<1:38:41, 102.09s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 42/100, Loss: 0.010483753648309183, Val F1: 0.9213976170998804\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  43%|████▎     | 43/100 [1:13:21<1:37:11, 102.31s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 43/100, Loss: 0.010395845744430513, Val F1: 0.9213158189660291\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  44%|████▍     | 44/100 [1:15:04<1:35:29, 102.31s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 44/100, Loss: 0.008700421391835763, Val F1: 0.9211181731632493\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  45%|████▌     | 45/100 [1:16:46<1:33:47, 102.32s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 45/100, Loss: 0.009813660850813031, Val F1: 0.9213759390033595\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  46%|████▌     | 46/100 [1:18:28<1:31:59, 102.22s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 46/100, Loss: 0.01065016960820802, Val F1: 0.9213158189660291\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  47%|████▋     | 47/100 [1:20:11<1:30:33, 102.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 47/100, Loss: 0.01047438340718681, Val F1: 0.9208533958029937\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  48%|████▊     | 48/100 [1:21:53<1:28:38, 102.27s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 48/100, Loss: 0.009656888948490679, Val F1: 0.9210586304243146\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  49%|████▉     | 49/100 [1:23:35<1:26:59, 102.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 49/100, Loss: 0.010688907426829016, Val F1: 0.9205447257261787\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  50%|█████     | 50/100 [1:25:17<1:25:03, 102.08s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 50/100, Loss: 0.009760272996180363, Val F1: 0.9209985040571131\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  51%|█████     | 51/100 [1:27:00<1:23:40, 102.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 51/100, Loss: 0.009010712064935379, Val F1: 0.9207038840805549\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  52%|█████▏    | 52/100 [1:28:43<1:22:01, 102.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 52/100, Loss: 0.010337941995127753, Val F1: 0.9206364691200898\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  53%|█████▎    | 53/100 [1:30:25<1:20:11, 102.37s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 53/100, Loss: 0.010209814292160732, Val F1: 0.9212099352131929\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  54%|█████▍    | 54/100 [1:32:07<1:18:24, 102.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 54/100, Loss: 0.010102340115868424, Val F1: 0.9208927335892819\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  55%|█████▌    | 55/100 [1:33:49<1:16:38, 102.18s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 55/100, Loss: 0.009510556539579352, Val F1: 0.9212865327111349\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  56%|█████▌    | 56/100 [1:35:31<1:14:55, 102.16s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 56/100, Loss: 0.010645029074990953, Val F1: 0.9207130479195695\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  57%|█████▋    | 57/100 [1:37:13<1:13:13, 102.17s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 57/100, Loss: 0.009025746468111306, Val F1: 0.9215303412911395\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  58%|█████▊    | 58/100 [1:38:55<1:11:33, 102.22s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 58/100, Loss: 0.010230999599861628, Val F1: 0.9215262041855203\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  59%|█████▉    | 59/100 [1:40:38<1:09:58, 102.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 59/100, Loss: 0.009587266726557624, Val F1: 0.9215262041855203\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  60%|██████    | 60/100 [1:42:20<1:08:12, 102.31s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 60/100, Loss: 0.01033689231404521, Val F1: 0.9216010119991281\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  61%|██████    | 61/100 [1:44:03<1:06:33, 102.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 61/100, Loss: 0.010112100492111437, Val F1: 0.9213463642588614\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  62%|██████▏   | 62/100 [1:45:46<1:05:02, 102.70s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 62/100, Loss: 0.009103906190870224, Val F1: 0.9215862663840375\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  63%|██████▎   | 63/100 [1:47:28<1:03:10, 102.43s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 63/100, Loss: 0.00915074746590313, Val F1: 0.921488760456003\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  64%|██████▍   | 64/100 [1:49:10<1:01:22, 102.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 64/100, Loss: 0.010656748462413853, Val F1: 0.9213463642588614\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  65%|██████▌   | 65/100 [1:50:53<59:44, 102.42s/it]  ","output_type":"stream"},{"name":"stdout","text":"Epoch 65/100, Loss: 0.008919025158774543, Val F1: 0.9215069870805218\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  66%|██████▌   | 66/100 [1:52:35<58:00, 102.35s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 66/100, Loss: 0.008821180070437846, Val F1: 0.9217297971483653\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  67%|██████▋   | 67/100 [1:54:17<56:13, 102.22s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 67/100, Loss: 0.008965617937198371, Val F1: 0.9215303412911395\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  68%|██████▊   | 68/100 [1:55:59<54:28, 102.15s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 68/100, Loss: 0.008509320152970835, Val F1: 0.9215832336585225\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  69%|██████▉   | 69/100 [1:57:42<52:53, 102.37s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 69/100, Loss: 0.009708903609687859, Val F1: 0.9215901730157892\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  70%|███████   | 70/100 [1:59:24<51:08, 102.27s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 70/100, Loss: 0.008816805760043164, Val F1: 0.9215832336585225\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  71%|███████   | 71/100 [2:01:07<49:31, 102.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 71/100, Loss: 0.009902316231327422, Val F1: 0.922044322076916\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  72%|███████▏  | 72/100 [2:02:49<47:47, 102.42s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 72/100, Loss: 0.009872863902620172, Val F1: 0.9215303412911395\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  73%|███████▎  | 73/100 [2:04:31<46:04, 102.38s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 73/100, Loss: 0.00909840039093594, Val F1: 0.9217208479476617\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  74%|███████▍  | 74/100 [2:06:13<44:18, 102.27s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 74/100, Loss: 0.008881969958584847, Val F1: 0.9224190641530805\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  75%|███████▌  | 75/100 [2:07:56<42:39, 102.39s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 75/100, Loss: 0.00872860574760787, Val F1: 0.9228484677113008\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  76%|███████▌  | 76/100 [2:09:38<40:53, 102.21s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 76/100, Loss: 0.00927003448247204, Val F1: 0.9227285421276685\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  77%|███████▋  | 77/100 [2:11:21<39:14, 102.38s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 77/100, Loss: 0.009005781797513636, Val F1: 0.922314373699883\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  78%|███████▊  | 78/100 [2:13:03<37:34, 102.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 78/100, Loss: 0.009470969152296775, Val F1: 0.922451308283155\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  79%|███████▉  | 79/100 [2:14:45<35:49, 102.36s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 79/100, Loss: 0.009939633148990155, Val F1: 0.922228248177037\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  80%|████████  | 80/100 [2:16:27<34:03, 102.17s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 80/100, Loss: 0.009079301700255773, Val F1: 0.9229441168130516\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  81%|████████  | 81/100 [2:18:09<32:20, 102.12s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 81/100, Loss: 0.00832529472549261, Val F1: 0.9218448265805209\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  82%|████████▏ | 82/100 [2:19:52<30:39, 102.20s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 82/100, Loss: 0.009717161127998529, Val F1: 0.9218448265805209\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  83%|████████▎ | 83/100 [2:21:34<28:57, 102.21s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 83/100, Loss: 0.009185779332435652, Val F1: 0.921961963784206\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  84%|████████▍ | 84/100 [2:23:16<27:15, 102.24s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 84/100, Loss: 0.0076057093554710315, Val F1: 0.9226894747168463\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  85%|████████▌ | 85/100 [2:24:58<25:34, 102.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 85/100, Loss: 0.008516726821867944, Val F1: 0.9220217955088558\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  86%|████████▌ | 86/100 [2:26:42<23:55, 102.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 86/100, Loss: 0.010977349707810636, Val F1: 0.9217159044488796\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  87%|████████▋ | 87/100 [2:28:24<22:13, 102.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 87/100, Loss: 0.009259428311785736, Val F1: 0.922228248177037\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  88%|████████▊ | 88/100 [2:30:07<20:30, 102.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 88/100, Loss: 0.009072073400002333, Val F1: 0.921922356764824\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  89%|████████▉ | 89/100 [2:31:49<18:46, 102.38s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 89/100, Loss: 0.008699435903325418, Val F1: 0.9222127489760574\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  90%|█████████ | 90/100 [2:33:31<17:02, 102.25s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 90/100, Loss: 0.008951067612206738, Val F1: 0.9226755820173608\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  91%|█████████ | 91/100 [2:35:14<15:23, 102.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 91/100, Loss: 0.008549899638170792, Val F1: 0.9224009144300017\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  92%|█████████▏| 92/100 [2:36:57<13:40, 102.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 92/100, Loss: 0.008108125143857243, Val F1: 0.9210460969804968\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  93%|█████████▎| 93/100 [2:38:39<11:56, 102.37s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 93/100, Loss: 0.00903947359158558, Val F1: 0.9214963584056058\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  94%|█████████▍| 94/100 [2:40:21<10:13, 102.29s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 94/100, Loss: 0.008478455372858736, Val F1: 0.9220356206830033\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  95%|█████████▌| 95/100 [2:42:03<08:31, 102.36s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 95/100, Loss: 0.00881819783419998, Val F1: 0.9226073739700162\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  96%|█████████▌| 96/100 [2:43:46<06:49, 102.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 96/100, Loss: 0.007937883095963062, Val F1: 0.9231350702802531\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  97%|█████████▋| 97/100 [2:45:29<05:07, 102.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 97/100, Loss: 0.007779528056546763, Val F1: 0.9226052980070071\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  98%|█████████▊| 98/100 [2:47:11<03:25, 102.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 98/100, Loss: 0.009874432329544248, Val F1: 0.9233211491619868\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  99%|█████████▉| 99/100 [2:48:54<01:42, 102.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 99/100, Loss: 0.008118097492718248, Val F1: 0.9226273980529996\n","output_type":"stream"},{"name":"stderr","text":"Epochs: 100%|██████████| 100/100 [2:50:35<00:00, 102.36s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 100/100, Loss: 0.0079377332543038, Val F1: 0.9217151394802078\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"\nclassifier.load_state_dict(torch.load('model_base_lora.pth'), strict=False)\nclassifier.load_state_dict(torch.load('lora_model.pth'), strict=False)\n\ngenerate_predictions_and_save(classifier, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T06:43:06.040495Z","iopub.status.idle":"2024-03-18T06:43:06.040888Z","shell.execute_reply.started":"2024-03-18T06:43:06.040693Z","shell.execute_reply":"2024-03-18T06:43:06.040708Z"},"trusted":true},"execution_count":null,"outputs":[]}]}